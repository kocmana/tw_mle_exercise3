{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MLE - Exercise 3 - Kaggle Competition\n",
    "## Andreas Kocman (se19m024)\n",
    "\n",
    "##Assignment\n",
    "This exercise is in the form of a Kaggle competition. A few quick details on Kaggle & the competition format:\n",
    "\n",
    "### Kaggle\n",
    "* Kaggle (https://en.wikipedia.org/wiki/Kaggle) is a platform that allows a competition for a certain data set. Participants submit their prediction on a test set, and will get automated scoring on their results, and will enter the leaderboard.\n",
    "* From Kaggle, you will be able to obtain a labelled training set, and an unlabelled test set.\n",
    "* You can submit multiple entries to Kaggle; for each entry, you need to provide details on how you achieved the results - which software and which version of the software, which operating system, which algorithms, and which parameter settings for these algorithms; further, any processing applied to the data before training/predicting. There is a specific \"description\" field when submitting, you should fill in this information there, and you also need to include this description and the actual submission file in your final submission to Moodle.\n",
    "* To submit to Kaggle, you need to create a specific submission file, which contains the predictions you obtain on the test set. Computing an aggregated evaluation criterion is done automatically by Kaggle\n",
    "* The format of your submission is rather simple - it is a comma-separated file, where the first column is the identifier of the item that you are predicting, and the second column is the class you are predicting for that item. The first line should include a header, and is should use the names provided in the training set. An example is below:\n",
    "```\n",
    "ID,class\n",
    "911366,B\n",
    "852781,B\n",
    "89524,B\n",
    "857438,B\n",
    "905686,B\n",
    "```\n",
    "* There is a limit of 7 submissions per day; finally, you also need to select your top 7 submissions to be counted in the competition\n",
    "* Before you submit, you should evaluate the classifiers \"locally\" on your training set, i.e. by splitting that again in a training & test set (or using cross validation), to select a number of fitting algorithms & parameters. Then re-train your best models on the full local training set, and generate the predictions for the test set.\n",
    "* Evaluation in Kaggle is split in two types of leaderboards - the private and public one. Here, the data is split into 50% / 50%, and as soon as you upload, you will know your results on one of these splits.\n",
    "* The final results will only be visible once the competition closes, and as it is computed on a different split, might be slightly different than what you see initially (e.g. this is similar to a training/test/validation split)\n",
    "* As it is a competition, there will be bonus points for the top 3 submissions.\n",
    "* As reproducible science is great, there will be additional bonus points for submissions that use a notebook within the Kaggle competition (note: this was / partially still is called a \"kernel\" inside the Kaggle competition; Kernel obviously was a confusing term here, as it basically refers to code being executed in the environment of Kaggle itself (e.g. a jupyter notebook, or also a python or R script), and they seem to have realized that, and renamed it). see https://www.kaggle.com/notebooks or https://www.kaggle.com/getting-started/44939. You can first work locally, and then port your code to the notebook version. In Kaggle, your notebook will initially be private. Please share it with me (mayer@ifs.tuwien.ac.at), at least, though. You can also make it public at the end of the competition, to show off :-)\n",
    "\n",
    "### Datasets\n",
    "We will use the following datasets:\n",
    "* Congressional Voting: a small dataset, a good entry point for your experiments (435 instances, 16 features)\n",
    "  * Kaggle page: https://www.kaggle.com/t/c04c953c596e48099d857129f53fcbdb\n",
    "* Amazon reviews: a dataset with many features (10k, extracted from text), but not that many instances (~800)\n",
    "  * Kaggle page: https://www.kaggle.com/t/0bd2ac297dc242478b5979d5ee772136\n",
    "\n",
    "### Submission\n",
    "The Kaggle competition will close on the day displayed in Kaggle. After that, you still have time to submit to Moodle. Your submission to Moodle shall contain:\n",
    "\n",
    "* A brief report, containing\n",
    "  * A description of the datasets, including a short analysis of the features.\n",
    "  * Details on the software you used for creating your solution\n",
    "  * The algorithms and parameters you tried\n",
    "  * The results you obtained on the locally split training/test set\n",
    "    * And a comparison to the results that you received on Kaggle - how large was the difference, did the rank of the classifiers change (i.e. the first on your training set, was it still the best on the test set on Kaggle?)\n",
    "* All the code needed to obtain your results\n",
    "* The solution files that you uploaded to Kaggle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Solution\n",
    "## Brief Description of Datasets\n",
    "\n",
    "### Congressional Voting\n",
    "#### Background\n",
    "The classification task relates to the prediction of voting behaviour in relation to opinions on certain political questions/topics.\n",
    "\n",
    "#### Dataset Features\n",
    "The dataset features boolean responses to 16 political topics or issues like allowing religious groups in schools of 219 people.\n",
    "Features are coded as 'y' and 'n' and are in most cases relatively evenly distributed.\n",
    "\n",
    "There missing data labeled as \"unknown\" and rather frequent. The author decided to treat this data as missing values in the strict sense and used multiple imputation to deal with the missing data. Alternatively, treating \"unknown\" as a separate valid response to these questions would also have been a valid approach, given the problem domain.\n",
    "\n",
    "The classes for this classification task is the voting behaviour of the respective persons, coded as \"democrat\" or \"republican\".\n",
    "\n",
    "For more details on the dataset features, see section \"Data Exploration - Congressional Vote\".\n",
    "\n",
    "### Amazon\n",
    "#### Background\n",
    "The classification task relates to language features of frequent authors of Amazon reviews.\n",
    "\n",
    "#### Dataset Features\n",
    "The dataset consists of 10 000 dimensions relating to language features with only 750 rows. The actual meaning of the data that can be used for prediction is unknown to the author.\n",
    "\n",
    "The fields are integer values which makes it likely that the fields represent frequencies or occurancies of specific language features.\n",
    "The distribution of these features are in most cases following a slightly skewed normal distribution (rechtssteile/linksschiefe Verteilung).\n",
    "\n",
    "There is no missing data. Frequency of non zero values in the latter dimensions (`V100` and above) increases, leading to highly sparse data for most dimensions.\n",
    "\n",
    "The classes for this classification task are the names of the authors of the reviews.\n",
    "Due to the high number of classes/authors and the limited number of data points, available data per class ranges only between 7 and 20 entries.\n",
    "\n",
    "For more details on the dataset features, see section \"Data Exploration - Amazon\".\n",
    "\n",
    "## Software used\n",
    "Stack:\n",
    "* Python\n",
    "* Jupyter\n",
    "* Scikit Learn\n",
    "* PyCharm\n",
    "* Kaggle Notebooks\n",
    "\n",
    "The solutions were calculated on Python with Scikit Learn using a mixture of local Jupyter Notebooks (using Pycharm) and the Kaggle Notebooks\n",
    "\n",
    "While the Kaggle Notebooks provided a surprisingly powerful environment for data analysis and calculation of predictions,\n",
    "frequent disconnections and errors when using the notebooks for longer periods of time made it necessary to also use Jupyter\n",
    "locally on PyCharm.\n",
    "\n",
    "## Approaches used\n",
    "Main Approaches (with five folds each):\n",
    "* kNN\n",
    "* Naive Bayes\n",
    "* Decision Tree\n",
    "* Perceptron\n",
    "* Logistic Regression Models\n",
    "* Supported Vector Machines\n",
    "\n",
    "For the specific combinations of parameters tried, please see the following chapters.\n",
    "The following describes in detail the approach used as well as the selection of classifiers and the preparation of the data submission, especially the section \"Calculation Functions\".\n",
    "\n",
    "## Obtained Results\n",
    "### Congressional Voting\n",
    "The best results were found for a Decision Tree closely followed by a SVM solution:\n",
    "```\n",
    "classifier        DecisionTreeClassifier(max_depth=1, min_sample...\n",
    "arguments                              max Depth: 1, min Samples: 2\n",
    "mean_accuracy                                               0.96797\n",
    "mean_precision                                             0.963363\n",
    "mean_recall                                                0.973789\n",
    "accuracy             m: 0.967970401691332 std: 0.023305252083176783\n",
    "precision           m: 0.9633625730994153 std: 0.025403888401415272\n",
    "recall                m: 0.9737891737891738 std: 0.0190606594685786\n",
    "Name: 15, dtype: object\n",
    "```\n",
    "Solutions for SVM were good, irrespective of kernels used, i.e.:\n",
    "```\n",
    "classifier        SVC(C=100, degree=1, gamma=0.001, kernel='poly')\n",
    "arguments                                  Kernel: poly, Degree: 1\n",
    "mean_accuracy                                              0.96797\n",
    "mean_precision                                            0.963363\n",
    "mean_recall                                               0.973789\n",
    "accuracy            m: 0.967970401691332 std: 0.023305252083176783\n",
    "precision          m: 0.9633625730994153 std: 0.025403888401415272\n",
    "recall               m: 0.9737891737891738 std: 0.0190606594685786\n",
    "Name: 0, dtype: object\n",
    "```\n",
    "The mean accuracy of both the SVM solution and the Decision Tree Classifiers were close to those yielded during submission:\n",
    "\n",
    "Both SVM and Decision Tree Classifier resulted in 0.95370 accuracy and hence failed to predict only a limited number of voting behaviour for the separate data set. Generalization was hence deemed good.\n",
    "This also aligns with the limited standard deviation of accuracy and precision results during the separate folds.\n",
    "\n",
    "One notable finding was that the Decision Tree classifier worked exceedingly well with max_depth=1, which means that responses to one question was sufficient to correctly assign 96% of people.\n",
    "\n",
    "For detailed results, please see the section \"Overall Results for Congressional Vote\"\n",
    "\n",
    "### Amazon\n",
    "The best results were found for Logistic Regression with balanced class weights:\n",
    "```\n",
    "classifier        LogisticRegression(class_weight='balanced', pe...\n",
    "arguments                                           newton-cg, none\n",
    "mean_accuracy                                              0.594667\n",
    "mean_precision                                             0.595733\n",
    "mean_recall                                                   0.576\n",
    "accuracy             m: 0.5946666666666667 std: 0.03194439613522914\n",
    "precision           m: 0.5957333333333332 std: 0.040680333502659864\n",
    "recall                             m: 0.576 std: 0.0309228430488243\n",
    "Name: 0, dtype: object\n",
    "```\n",
    "Due to the high number of dimensions categories combined with the relatively low number of data points per category, the result of only 59% accuracy is not surprising.\n",
    "\n",
    "SVMs with a polynomial kernel also yielded acceptable results (>50% accuracy).\n",
    "\n",
    "Interestingly, the variance of results as computed during the multiple folds was only limited. Variances were relatively low across the different approaches tried.\n",
    "\n",
    "Concurrently, the results yielded after the upload of Keggle were close to the ones yielded during local test (62,66%).\n",
    "\n",
    "For detailed results, please see the section \"Overall Results for Amazon\"\n",
    "\n",
    "### Helper Functions for Solution and Data Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# global Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#sk learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#Data reporting\n",
    "from IPython.display import display\n",
    "\n",
    "# Global definitions:\n",
    "overall_results_vote = []\n",
    "overall_results_amazon = []\n",
    "averaging_approach = 'macro'\n",
    "zero_division_approach = 0\n",
    "number_of_folds = 5\n",
    "scoring = {'Accuracy': make_scorer(accuracy_score),\n",
    "            'Precision': make_scorer(precision_score, average=averaging_approach, zero_division=zero_division_approach),\n",
    "            'Recall': make_scorer(recall_score, average=averaging_approach, zero_division=zero_division_approach)}\n",
    "\n",
    "# Helper functions\n",
    "def parse_k_fold_results(results):\n",
    "    return \"m: \" + str(np.average(results)) + \" std: \" + str(np.std(results))\n",
    "\n",
    "def parse_argument_tuple_as_string(argumentsTuple):\n",
    "    return \"max Depth: \" + str(argumentsTuple[0])  + \\\n",
    "           \", min Samples: \" + str(argumentsTuple[1])\n",
    "\n",
    "def calculate_results_holdout(classifier_used, X_train, X_test, y_train, y_test):\n",
    "    classifier_used.fit(X_train, y_train)\n",
    "\n",
    "    # predict the test set on our trained classifier\n",
    "    y_test_predicted = classifier_used.predict(X_test)\n",
    "\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    recall=metrics.recall_score(y_test, y_test_predicted)\n",
    "    precision = metrics.precision_score(y_test, y_test_predicted)\n",
    "\n",
    "    return pd.Series({\n",
    "            'classifier': str(classifier_used),\n",
    "            'arguments': \"\",\n",
    "            'accuracy':acc,\n",
    "            'precision':precision,\n",
    "            'recall':recall\n",
    "        })\n",
    "\n",
    "def calculate_results_cross_validate(classifier_used, description_used, data, target):\n",
    "   scores = cross_validate(classifier_used, data, target,\n",
    "                                scoring = scoring,\n",
    "                                cv = number_of_folds,\n",
    "                                error_score = 0)\n",
    "\n",
    "   return pd.Series({\n",
    "            'classifier': str(classifier_used),\n",
    "            'arguments': description_used,\n",
    "            'mean_accuracy': np.average(scores.get('test_Accuracy')),\n",
    "            'mean_precision': np.average(scores.get('test_Precision')),\n",
    "            'mean_recall': np.average(scores.get('test_Recall')),\n",
    "            'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "            'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "            'recall':parse_k_fold_results(scores.get('test_Recall'))\n",
    "        })\n",
    "\n",
    "def print_results(array, column_for_max, ascending=False):\n",
    "    df = pd.DataFrame(array)\n",
    "    df = df.sort_values(by=[column_for_max], ascending=False)\n",
    "    display('Results', df)\n",
    "\n",
    "    best = df.iloc[df[column_for_max].argmax()]\n",
    "    display(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculation Functions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### k-NN Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "def calculate_knn(data, target):\n",
    "    knn_results = []\n",
    "\n",
    "    n_neighbors = range(1,10,1)\n",
    "\n",
    "    for n in n_neighbors:\n",
    "        knn_classifier = neighbors.KNeighborsClassifier(n)\n",
    "        description = \"N = \" + str(n)\n",
    "        result = calculate_results_cross_validate(knn_classifier,\n",
    "                                                  description,\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        knn_results.append(result)\n",
    "    return knn_results\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bayes Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "def calculate_bayes(data, target):\n",
    "    bayes_results = []\n",
    "\n",
    "    alphas = np.arange(0.1,5,1)\n",
    "\n",
    "    for alpha in alphas:\n",
    "        classifier = naive_bayes.CategoricalNB(alpha = alpha)\n",
    "        description = \"Alpha = \" + str(alpha)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  description,\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        bayes_results.append(result)\n",
    "\n",
    "    return bayes_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Perceptron Calculation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def calculate_perceptron(data, target):\n",
    "    perceptron_results=[]\n",
    "    classifier = linear_model.Perceptron()\n",
    "    description = \"No additional args.\"\n",
    "    result = calculate_results_cross_validate(classifier,\n",
    "                                              description,\n",
    "                                              data,\n",
    "                                              target)\n",
    "    perceptron_results.append(result)\n",
    "    return perceptron_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Decision Tree Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import itertools\n",
    "\n",
    "def calculate_decision_tree(data, target):\n",
    "    # Parameters for the decision tree\n",
    "    max_depth_arguments = range(1, 10, 2)\n",
    "    min_samples_leaf_arguments = [2,20,50,100]\n",
    "    argumentTuples = list(itertools.product(max_depth_arguments,\n",
    "                                            min_samples_leaf_arguments))\n",
    "    decision_tree_results = []\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        max_depth = argumentTuple[0]\n",
    "        min_samples_leaf = argumentTuple[1]\n",
    "\n",
    "        classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                 max_depth = max_depth,\n",
    "                                                 min_samples_leaf = min_samples_leaf,\n",
    "                                                 splitter = 'best')\n",
    "        #result = calculate_results_holdout(classifier, X_train, X_test, y_train, y_test)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  parse_argument_tuple_as_string(argumentTuple),\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        decision_tree_results.append(result)\n",
    "    return decision_tree_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def calculate_logistic_regression(data, target):\n",
    "    penalty = [\"none\", \"l2\"]#, \"l1\", \"elasticnet\"]\n",
    "    class_weight = [\"balanced\"]\n",
    "    solvers = [\"newton-cg\"]#, \"lbfgs\", \"liblinear\"]\n",
    "\n",
    "    argumentTuples = list(itertools.product(solvers, penalty, class_weight))\n",
    "\n",
    "    regression_results = []\n",
    "\n",
    "    for tuple in argumentTuples:\n",
    "        solver = tuple[0]\n",
    "        penalty = tuple[1]\n",
    "        class_weight = tuple[2]\n",
    "        classifier = linear_model.LogisticRegression(solver = solver, class_weight = class_weight, penalty = penalty)\n",
    "\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  solver + \", \" + penalty,\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        regression_results.append(result)\n",
    "    return regression_results\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import itertools\n",
    "\n",
    "def calculate_svm(data, target):\n",
    "    kernels = [\"poly\", \"rbf\"]#{\"linear\", \"poly\", \"sigmoid\", \"rbf\"}\n",
    "    gamma = [0.001, \"scale\", \"auto\"]\n",
    "    c = [100]\n",
    "    degree = [1]#range(1, 10, 1)\n",
    "\n",
    "    argumentTuples = list(itertools.product(kernels,\n",
    "                                            gamma,\n",
    "                                            c,\n",
    "                                            degree))\n",
    "    svm_results = []\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        kernel = argumentTuple[0]\n",
    "        gamma = argumentTuple[1]\n",
    "        c = argumentTuple[2]\n",
    "        degree = argumentTuple[3]\n",
    "\n",
    "        classifier = svm.SVC(kernel = kernel, gamma = gamma, C = c, degree = degree)\n",
    "\n",
    "        #result = calculate_results_holdout(classifier, X_train, X_test, y_train, y_test)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  \"Kernel: \" + kernel + \", Degree: \" + str(degree),\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        svm_results.append(result)\n",
    "    return svm_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congressional Voting\n",
    "\n",
    "### Preparation of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Original Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID       class handicapped-infants water-project-cost-sharing  \\\n0    213    democrat                   n                          n   \n1     94    democrat                   y                          n   \n2    188    democrat                   y                          n   \n3     61    democrat                   y                          y   \n4    184    democrat                 NaN                        NaN   \n..   ...         ...                 ...                        ...   \n213  250    democrat                   y                          n   \n214   26    democrat                   y                          n   \n215  110    democrat                   y                        NaN   \n216   34  republican                   n                          y   \n217  314  republican                   n                          y   \n\n    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n0                                   y                    n               n   \n1                                   y                    n               n   \n2                                   y                    n               n   \n3                                   y                    n               n   \n4                                 NaN                  NaN             NaN   \n..                                ...                  ...             ...   \n213                                 y                    n               n   \n214                                 y                    n               n   \n215                                 y                    n               n   \n216                                 n                    y               y   \n217                                 y                    y               y   \n\n    religious-groups-in-schools anti-satellite-test-ban  \\\n0                             n                       y   \n1                             n                       y   \n2                             n                       y   \n3                           NaN                       y   \n4                           NaN                     NaN   \n..                          ...                     ...   \n213                           n                       y   \n214                           n                       y   \n215                           n                       y   \n216                           y                       n   \n217                           y                       n   \n\n    aid-to-nicaraguan-contras mx-missile immigration  \\\n0                           y          y           n   \n1                           n          y           y   \n2                           y          y           n   \n3                           y          y           y   \n4                         NaN          y         NaN   \n..                        ...        ...         ...   \n213                         y        NaN           n   \n214                         y          y           y   \n215                         y          y           n   \n216                         n          n           n   \n217                         n          n           y   \n\n    synfuels-crporation-cutback education-spending superfund-right-to-sue  \\\n0                             y                  n                      n   \n1                             y                  n                      n   \n2                             n                  n                      n   \n3                             n                  n                      n   \n4                           NaN                NaN                    NaN   \n..                          ...                ...                    ...   \n213                           y                  n                      n   \n214                           n                  n                      n   \n215                           n                  n                      n   \n216                           n                  y                      y   \n217                           n                  y                      y   \n\n    crime duty-free-exports export-administration-act-south-africa  \n0       n                 y                                      y  \n1       n                 y                                      y  \n2       n                 y                                    NaN  \n3       n                 y                                    NaN  \n4     NaN               NaN                                    NaN  \n..    ...               ...                                    ...  \n213     n                 y                                      y  \n214     n                 y                                      y  \n215     n                 y                                    NaN  \n216     y                 n                                      y  \n217     y                 n                                      y  \n\n[218 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>213</td>\n      <td>democrat</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>94</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>188</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>184</td>\n      <td>democrat</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>250</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>26</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>110</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>34</td>\n      <td>republican</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>314</td>\n      <td>republican</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n    </tr>\n  </tbody>\n</table>\n<p>218 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\sklearn\\impute\\_iterative.py:670: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Recoded Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID class handicapped-infants water-project-cost-sharing  \\\n0    213     2                   0                          0   \n1     94     2                   1                          0   \n2    188     2                   1                          0   \n3     61     2                   1                          1   \n4    184     2                   1                          0   \n..   ...   ...                 ...                        ...   \n213  250     2                   1                          0   \n214   26     2                   1                          0   \n215  110     2                   1                          0   \n216   34     3                   0                          1   \n217  314     3                   0                          1   \n\n    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n0                                   1                    0               0   \n1                                   1                    0               0   \n2                                   1                    0               0   \n3                                   1                    0               0   \n4                                   1                    0               0   \n..                                ...                  ...             ...   \n213                                 1                    0               0   \n214                                 1                    0               0   \n215                                 1                    0               0   \n216                                 0                    1               1   \n217                                 1                    1               1   \n\n    religious-groups-in-schools anti-satellite-test-ban  \\\n0                             0                       1   \n1                             0                       1   \n2                             0                       1   \n3                             0                       1   \n4                             0                       1   \n..                          ...                     ...   \n213                           0                       1   \n214                           0                       1   \n215                           0                       1   \n216                           1                       0   \n217                           1                       0   \n\n    aid-to-nicaraguan-contras mx-missile immigration  \\\n0                           1          1           0   \n1                           0          1           1   \n2                           1          1           0   \n3                           1          1           1   \n4                           1          1           1   \n..                        ...        ...         ...   \n213                         1          1           0   \n214                         1          1           1   \n215                         1          1           0   \n216                         0          0           0   \n217                         0          0           1   \n\n    synfuels-crporation-cutback education-spending superfund-right-to-sue  \\\n0                             1                  0                      0   \n1                             1                  0                      0   \n2                             0                  0                      0   \n3                             0                  0                      0   \n4                             0                  0                      0   \n..                          ...                ...                    ...   \n213                           1                  0                      0   \n214                           0                  0                      0   \n215                           0                  0                      0   \n216                           0                  1                      1   \n217                           0                  1                      1   \n\n    crime duty-free-exports export-administration-act-south-africa  \n0       0                 1                                      1  \n1       0                 1                                      1  \n2       0                 1                                      1  \n3       0                 1                                      1  \n4       0                 1                                      1  \n..    ...               ...                                    ...  \n213     0                 1                                      1  \n214     0                 1                                      1  \n215     0                 1                                      1  \n216     1                 0                                      1  \n217     1                 0                                      1  \n\n[218 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>213</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>94</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>188</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>184</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>250</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>26</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>110</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>34</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>314</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>218 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Data: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "    handicapped-infants water-project-cost-sharing  \\\n0                     0                          0   \n1                     1                          0   \n2                     1                          0   \n3                     1                          1   \n4                     1                          0   \n..                  ...                        ...   \n213                   1                          0   \n214                   1                          0   \n215                   1                          0   \n216                   0                          1   \n217                   0                          1   \n\n    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n0                                   1                    0               0   \n1                                   1                    0               0   \n2                                   1                    0               0   \n3                                   1                    0               0   \n4                                   1                    0               0   \n..                                ...                  ...             ...   \n213                                 1                    0               0   \n214                                 1                    0               0   \n215                                 1                    0               0   \n216                                 0                    1               1   \n217                                 1                    1               1   \n\n    religious-groups-in-schools anti-satellite-test-ban  \\\n0                             0                       1   \n1                             0                       1   \n2                             0                       1   \n3                             0                       1   \n4                             0                       1   \n..                          ...                     ...   \n213                           0                       1   \n214                           0                       1   \n215                           0                       1   \n216                           1                       0   \n217                           1                       0   \n\n    aid-to-nicaraguan-contras mx-missile immigration  \\\n0                           1          1           0   \n1                           0          1           1   \n2                           1          1           0   \n3                           1          1           1   \n4                           1          1           1   \n..                        ...        ...         ...   \n213                         1          1           0   \n214                         1          1           1   \n215                         1          1           0   \n216                         0          0           0   \n217                         0          0           1   \n\n    synfuels-crporation-cutback education-spending superfund-right-to-sue  \\\n0                             1                  0                      0   \n1                             1                  0                      0   \n2                             0                  0                      0   \n3                             0                  0                      0   \n4                             0                  0                      0   \n..                          ...                ...                    ...   \n213                           1                  0                      0   \n214                           0                  0                      0   \n215                           0                  0                      0   \n216                           0                  1                      1   \n217                           0                  1                      1   \n\n    crime duty-free-exports export-administration-act-south-africa  \n0       0                 1                                      1  \n1       0                 1                                      1  \n2       0                 1                                      1  \n3       0                 1                                      1  \n4       0                 1                                      1  \n..    ...               ...                                    ...  \n213     0                 1                                      1  \n214     0                 1                                      1  \n215     0                 1                                      1  \n216     1                 0                                      1  \n217     1                 0                                      1  \n\n[218 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>218 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Target: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0      2\n1      2\n2      2\n3      2\n4      2\n      ..\n213    2\n214    2\n215    2\n216    3\n217    3\nName: class, Length: 218, dtype: category\nCategories (2, int64): [2, 3]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Recode values for predicting variables\n",
    "def recode_voting_data(dataset):\n",
    "    dataset = dataset.replace('y', 1)\\\n",
    "        .replace('n', 0)\\\n",
    "        .replace('democrat', 2)\\\n",
    "        .replace('republican', 3)\n",
    "    dataset.loc[:, dataset.columns != \"ID\"] = dataset.loc[:, dataset.columns != \"ID\"].astype('category')\n",
    "    return pd.DataFrame(dataset, columns=dataset.columns)\n",
    "\n",
    "#Imput missing values\n",
    "def input_missing_values(data):\n",
    "    columns = data.columns\n",
    "    imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "    imp.fit(data.loc[:, data.columns != \"ID\"])\n",
    "    data.loc[:, data.columns != \"ID\"] = np.round(imp.transform(data.loc[:, data.columns != \"ID\"]))\n",
    "    data.loc[:, data.columns != \"ID\"] = data.loc[:, data.columns != \"ID\"].apply(lambda x: x.astype('int'))\n",
    "    data.loc[:, data.columns != \"ID\"] = data.loc[:, data.columns != \"ID\"].astype('category')\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "#Read Data\n",
    "votingDataLearnOriginal = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.lrn.csv\", na_values='unknown')\n",
    "votingDataSolutionExample = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.sol.ex.csv\", na_values='unknown')\n",
    "votingDataTest = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.tes.csv\", na_values='unknown')\n",
    "display(\"Original Data\", votingDataLearnOriginal)\n",
    "\n",
    "#Recode values\n",
    "votingDataLearn = recode_voting_data(votingDataLearnOriginal)\n",
    "votingDataLearn = input_missing_values(votingDataLearn)\n",
    "\n",
    "display(\"Recoded Data\", votingDataLearn)\n",
    "\n",
    "display(\"Data: \", votingDataLearn[votingDataLearn.columns[2:18]])\n",
    "display(\"Target: \", votingDataLearn[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Exploration - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "'Class Frequency'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "democrat      134\nrepublican     84\nName: class, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Data Frequencies'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID  class  handicapped-infants  water-project-cost-sharing  \\\n1    1.0    NaN                  NaN                         NaN   \n2    NaN  134.0                  NaN                         NaN   \n3    1.0   84.0                  NaN                         NaN   \n5    1.0    NaN                  NaN                         NaN   \n6    1.0    NaN                  NaN                         NaN   \n..   ...    ...                  ...                         ...   \n431  1.0    NaN                  NaN                         NaN   \n432  1.0    NaN                  NaN                         NaN   \n434  1.0    NaN                  NaN                         NaN   \nn    NaN    NaN                125.0                        95.0   \ny    NaN    NaN                 85.0                        97.0   \n\n     adoption-of-the-budget-resolution  physician-fee-freeze  el-salvador-aid  \\\n1                                  NaN                   NaN              NaN   \n2                                  NaN                   NaN              NaN   \n3                                  NaN                   NaN              NaN   \n5                                  NaN                   NaN              NaN   \n6                                  NaN                   NaN              NaN   \n..                                 ...                   ...              ...   \n431                                NaN                   NaN              NaN   \n432                                NaN                   NaN              NaN   \n434                                NaN                   NaN              NaN   \nn                                 80.0                 120.0            100.0   \ny                                128.0                  89.0            111.0   \n\n     religious-groups-in-schools  anti-satellite-test-ban  \\\n1                            NaN                      NaN   \n2                            NaN                      NaN   \n3                            NaN                      NaN   \n5                            NaN                      NaN   \n6                            NaN                      NaN   \n..                           ...                      ...   \n431                          NaN                      NaN   \n432                          NaN                      NaN   \n434                          NaN                      NaN   \nn                           66.0                     97.0   \ny                          144.0                    113.0   \n\n     aid-to-nicaraguan-contras  mx-missile  immigration  \\\n1                          NaN         NaN          NaN   \n2                          NaN         NaN          NaN   \n3                          NaN         NaN          NaN   \n5                          NaN         NaN          NaN   \n6                          NaN         NaN          NaN   \n..                         ...         ...          ...   \n431                        NaN         NaN          NaN   \n432                        NaN         NaN          NaN   \n434                        NaN         NaN          NaN   \nn                         91.0       107.0        107.0   \ny                        118.0       103.0        105.0   \n\n     synfuels-crporation-cutback  education-spending  superfund-right-to-sue  \\\n1                            NaN                 NaN                     NaN   \n2                            NaN                 NaN                     NaN   \n3                            NaN                 NaN                     NaN   \n5                            NaN                 NaN                     NaN   \n6                            NaN                 NaN                     NaN   \n..                           ...                 ...                     ...   \n431                          NaN                 NaN                     NaN   \n432                          NaN                 NaN                     NaN   \n434                          NaN                 NaN                     NaN   \nn                          134.0               117.0                    95.0   \ny                           68.0                84.0                   112.0   \n\n     crime  duty-free-exports  export-administration-act-south-africa  \n1      NaN                NaN                                     NaN  \n2      NaN                NaN                                     NaN  \n3      NaN                NaN                                     NaN  \n5      NaN                NaN                                     NaN  \n6      NaN                NaN                                     NaN  \n..     ...                ...                                     ...  \n431    NaN                NaN                                     NaN  \n432    NaN                NaN                                     NaN  \n434    NaN                NaN                                     NaN  \nn     85.0              117.0                                    41.0  \ny    126.0               91.0                                   122.0  \n\n[221 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>134.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>84.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>431</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>434</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>n</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>125.0</td>\n      <td>95.0</td>\n      <td>80.0</td>\n      <td>120.0</td>\n      <td>100.0</td>\n      <td>66.0</td>\n      <td>97.0</td>\n      <td>91.0</td>\n      <td>107.0</td>\n      <td>107.0</td>\n      <td>134.0</td>\n      <td>117.0</td>\n      <td>95.0</td>\n      <td>85.0</td>\n      <td>117.0</td>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>y</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>85.0</td>\n      <td>97.0</td>\n      <td>128.0</td>\n      <td>89.0</td>\n      <td>111.0</td>\n      <td>144.0</td>\n      <td>113.0</td>\n      <td>118.0</td>\n      <td>103.0</td>\n      <td>105.0</td>\n      <td>68.0</td>\n      <td>84.0</td>\n      <td>112.0</td>\n      <td>126.0</td>\n      <td>91.0</td>\n      <td>122.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>221 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "classFrequency = votingDataLearnOriginal['class'].value_counts()\n",
    "display(\"Class Frequency\", classFrequency)\n",
    "\n",
    "display(\"Data Frequencies\", votingDataLearn.apply(pd.value_counts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### k-NN - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                            classifier arguments  mean_accuracy  \\\n6  KNeighborsClassifier(n_neighbors=7)     N = 7       0.949789   \n7  KNeighborsClassifier(n_neighbors=8)     N = 8       0.949683   \n8  KNeighborsClassifier(n_neighbors=9)     N = 9       0.945243   \n0  KNeighborsClassifier(n_neighbors=1)     N = 1       0.945032   \n2  KNeighborsClassifier(n_neighbors=3)     N = 3       0.945032   \n4               KNeighborsClassifier()     N = 5       0.945032   \n1  KNeighborsClassifier(n_neighbors=2)     N = 2       0.944926   \n3  KNeighborsClassifier(n_neighbors=4)     N = 4       0.940381   \n5  KNeighborsClassifier(n_neighbors=6)     N = 6       0.935835   \n\n   mean_precision  mean_recall  \\\n6        0.946634     0.956796   \n7        0.946080     0.956796   \n8        0.942160     0.953092   \n0        0.942523     0.946331   \n2        0.941734     0.950913   \n4        0.941734     0.950913   \n1        0.945693     0.941606   \n3        0.937812     0.942485   \n5        0.934132     0.938781   \n\n                                          accuracy  \\\n6   m: 0.9497885835095138 std: 0.03633965972902396   \n7   m: 0.9496828752642706 std: 0.03925378581485785   \n8   m: 0.9452431289640592 std: 0.03687778755803422   \n0   m: 0.945031712473573 std: 0.034048886698533634   \n2   m: 0.945031712473573 std: 0.042524418215617005   \n4   m: 0.945031712473573 std: 0.042524418215617005   \n1   m: 0.9449260042283297 std: 0.03699848987727991   \n3  m: 0.9403805496828752 std: 0.027634973997320893   \n5  m: 0.9358350951374208 std: 0.033627186829120255   \n\n                                         precision  \\\n6   m: 0.9466340390488999 std: 0.03608620915053702   \n7   m: 0.9460797448165869 std: 0.03905530325409666   \n8  m: 0.9421603548383735 std: 0.037090417983209244   \n0   m: 0.9425226260094682 std: 0.03634869147380645   \n2   m: 0.9417338423530375 std: 0.04229555526924847   \n4   m: 0.9417338423530375 std: 0.04229555526924847   \n1   m: 0.9456933175569079 std: 0.04001026811690184   \n3   m: 0.937811566371938 std: 0.030278525504452966   \n5  m: 0.9341319126922842 std: 0.034844958450856264   \n\n                                            recall  \n6  m: 0.9567957097368863 std: 0.029626605680041794  \n7  m: 0.9567957097368863 std: 0.033352054331873056  \n8   m: 0.9530920060331824 std: 0.02978123723739161  \n0  m: 0.9463308614043908 std: 0.031909717382637634  \n2  m: 0.9509133567957099 std: 0.039255464764560155  \n4  m: 0.9509133567957099 std: 0.039255464764560155  \n1   m: 0.9416059158706218 std: 0.03451379175922509  \n3    m: 0.942484707558237 std: 0.02472620156914983  \n5  m: 0.9387810038545334 std: 0.028087583916356424  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>KNeighborsClassifier(n_neighbors=7)</td>\n      <td>N = 7</td>\n      <td>0.949789</td>\n      <td>0.946634</td>\n      <td>0.956796</td>\n      <td>m: 0.9497885835095138 std: 0.03633965972902396</td>\n      <td>m: 0.9466340390488999 std: 0.03608620915053702</td>\n      <td>m: 0.9567957097368863 std: 0.029626605680041794</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>KNeighborsClassifier(n_neighbors=8)</td>\n      <td>N = 8</td>\n      <td>0.949683</td>\n      <td>0.946080</td>\n      <td>0.956796</td>\n      <td>m: 0.9496828752642706 std: 0.03925378581485785</td>\n      <td>m: 0.9460797448165869 std: 0.03905530325409666</td>\n      <td>m: 0.9567957097368863 std: 0.033352054331873056</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>KNeighborsClassifier(n_neighbors=9)</td>\n      <td>N = 9</td>\n      <td>0.945243</td>\n      <td>0.942160</td>\n      <td>0.953092</td>\n      <td>m: 0.9452431289640592 std: 0.03687778755803422</td>\n      <td>m: 0.9421603548383735 std: 0.037090417983209244</td>\n      <td>m: 0.9530920060331824 std: 0.02978123723739161</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>KNeighborsClassifier(n_neighbors=1)</td>\n      <td>N = 1</td>\n      <td>0.945032</td>\n      <td>0.942523</td>\n      <td>0.946331</td>\n      <td>m: 0.945031712473573 std: 0.034048886698533634</td>\n      <td>m: 0.9425226260094682 std: 0.03634869147380645</td>\n      <td>m: 0.9463308614043908 std: 0.031909717382637634</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KNeighborsClassifier(n_neighbors=3)</td>\n      <td>N = 3</td>\n      <td>0.945032</td>\n      <td>0.941734</td>\n      <td>0.950913</td>\n      <td>m: 0.945031712473573 std: 0.042524418215617005</td>\n      <td>m: 0.9417338423530375 std: 0.04229555526924847</td>\n      <td>m: 0.9509133567957099 std: 0.039255464764560155</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNeighborsClassifier()</td>\n      <td>N = 5</td>\n      <td>0.945032</td>\n      <td>0.941734</td>\n      <td>0.950913</td>\n      <td>m: 0.945031712473573 std: 0.042524418215617005</td>\n      <td>m: 0.9417338423530375 std: 0.04229555526924847</td>\n      <td>m: 0.9509133567957099 std: 0.039255464764560155</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KNeighborsClassifier(n_neighbors=2)</td>\n      <td>N = 2</td>\n      <td>0.944926</td>\n      <td>0.945693</td>\n      <td>0.941606</td>\n      <td>m: 0.9449260042283297 std: 0.03699848987727991</td>\n      <td>m: 0.9456933175569079 std: 0.04001026811690184</td>\n      <td>m: 0.9416059158706218 std: 0.03451379175922509</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KNeighborsClassifier(n_neighbors=4)</td>\n      <td>N = 4</td>\n      <td>0.940381</td>\n      <td>0.937812</td>\n      <td>0.942485</td>\n      <td>m: 0.9403805496828752 std: 0.027634973997320893</td>\n      <td>m: 0.937811566371938 std: 0.030278525504452966</td>\n      <td>m: 0.942484707558237 std: 0.02472620156914983</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNeighborsClassifier(n_neighbors=6)</td>\n      <td>N = 6</td>\n      <td>0.935835</td>\n      <td>0.934132</td>\n      <td>0.938781</td>\n      <td>m: 0.9358350951374208 std: 0.033627186829120255</td>\n      <td>m: 0.9341319126922842 std: 0.034844958450856264</td>\n      <td>m: 0.9387810038545334 std: 0.028087583916356424</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                    KNeighborsClassifier(n_neighbors=7)\narguments                                                   N = 7\nmean_accuracy                                            0.949789\nmean_precision                                           0.946634\nmean_recall                                              0.956796\naccuracy           m: 0.9497885835095138 std: 0.03633965972902396\nprecision          m: 0.9466340390488999 std: 0.03608620915053702\nrecall            m: 0.9567957097368863 std: 0.029626605680041794\nName: 6, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_results_vote = calculate_knn(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                 votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(knn_results_vote)\n",
    "\n",
    "print_results(knn_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bayes - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                 classifier    arguments  mean_accuracy  mean_precision  \\\n3  CategoricalNB(alpha=3.1)  Alpha = 3.1       0.922304        0.918578   \n4  CategoricalNB(alpha=4.1)  Alpha = 4.1       0.922304        0.918578   \n2  CategoricalNB(alpha=2.1)  Alpha = 2.1       0.917759        0.914147   \n0  CategoricalNB(alpha=0.1)  Alpha = 0.1       0.917653        0.916001   \n1  CategoricalNB(alpha=1.1)  Alpha = 1.1       0.908562        0.905936   \n\n   mean_recall                                         accuracy  \\\n3     0.929706   m: 0.9223044397463003 std: 0.04195165926635185   \n4     0.929706   m: 0.9223044397463003 std: 0.04195165926635185   \n2     0.923824   m: 0.9177589852008456 std: 0.03936351367397849   \n0     0.919099  m: 0.9176532769556026 std: 0.036606812641491196   \n1     0.911691   m: 0.9085623678646935 std: 0.03759113618117659   \n\n                                         precision  \\\n3   m: 0.9185782390759508 std: 0.04469462645086833   \n4   m: 0.9185782390759508 std: 0.04469462645086833   \n2   m: 0.9141472899081595 std: 0.04267326106536261   \n0  m: 0.9160010673755272 std: 0.041199924531873135   \n1   m: 0.9059362018431694 std: 0.04263650611873664   \n\n                                           recall  \n3  m: 0.9297060918384448 std: 0.03623512490395484  \n4  m: 0.9297060918384448 std: 0.03623512490395484  \n2  m: 0.9238237388972683 std: 0.03255971857919237  \n0  m: 0.9190987933634993 std: 0.03090170389606902  \n1  m: 0.9116913859560919 std: 0.03226414499176202  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>CategoricalNB(alpha=3.1)</td>\n      <td>Alpha = 3.1</td>\n      <td>0.922304</td>\n      <td>0.918578</td>\n      <td>0.929706</td>\n      <td>m: 0.9223044397463003 std: 0.04195165926635185</td>\n      <td>m: 0.9185782390759508 std: 0.04469462645086833</td>\n      <td>m: 0.9297060918384448 std: 0.03623512490395484</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CategoricalNB(alpha=4.1)</td>\n      <td>Alpha = 4.1</td>\n      <td>0.922304</td>\n      <td>0.918578</td>\n      <td>0.929706</td>\n      <td>m: 0.9223044397463003 std: 0.04195165926635185</td>\n      <td>m: 0.9185782390759508 std: 0.04469462645086833</td>\n      <td>m: 0.9297060918384448 std: 0.03623512490395484</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CategoricalNB(alpha=2.1)</td>\n      <td>Alpha = 2.1</td>\n      <td>0.917759</td>\n      <td>0.914147</td>\n      <td>0.923824</td>\n      <td>m: 0.9177589852008456 std: 0.03936351367397849</td>\n      <td>m: 0.9141472899081595 std: 0.04267326106536261</td>\n      <td>m: 0.9238237388972683 std: 0.03255971857919237</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>CategoricalNB(alpha=0.1)</td>\n      <td>Alpha = 0.1</td>\n      <td>0.917653</td>\n      <td>0.916001</td>\n      <td>0.919099</td>\n      <td>m: 0.9176532769556026 std: 0.036606812641491196</td>\n      <td>m: 0.9160010673755272 std: 0.041199924531873135</td>\n      <td>m: 0.9190987933634993 std: 0.03090170389606902</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CategoricalNB(alpha=1.1)</td>\n      <td>Alpha = 1.1</td>\n      <td>0.908562</td>\n      <td>0.905936</td>\n      <td>0.911691</td>\n      <td>m: 0.9085623678646935 std: 0.03759113618117659</td>\n      <td>m: 0.9059362018431694 std: 0.04263650611873664</td>\n      <td>m: 0.9116913859560919 std: 0.03226414499176202</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                              CategoricalNB(alpha=3.1)\narguments                                            Alpha = 3.1\nmean_accuracy                                           0.922304\nmean_precision                                          0.918578\nmean_recall                                             0.929706\naccuracy          m: 0.9223044397463003 std: 0.04195165926635185\nprecision         m: 0.9185782390759508 std: 0.04469462645086833\nrecall            m: 0.9297060918384448 std: 0.03623512490395484\nName: 3, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bayes_results_vote = calculate_bayes(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                     votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(bayes_results_vote)\n",
    "\n",
    "print_results(bayes_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     classifier            arguments  mean_accuracy  mean_precision  \\\n0  Perceptron()  No additional args.       0.944715        0.948016   \n\n   mean_recall                                        accuracy  \\\n0     0.941238  m: 0.9447145877378436 std: 0.03746846609226435   \n\n                                        precision  \\\n0  m: 0.948015873015873 std: 0.035728392275797285   \n\n                                           recall  \n0  m: 0.9412382688117983 std: 0.04219766815473462  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Perceptron()</td>\n      <td>No additional args.</td>\n      <td>0.944715</td>\n      <td>0.948016</td>\n      <td>0.941238</td>\n      <td>m: 0.9447145877378436 std: 0.03746846609226435</td>\n      <td>m: 0.948015873015873 std: 0.035728392275797285</td>\n      <td>m: 0.9412382688117983 std: 0.04219766815473462</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                                          Perceptron()\narguments                                    No additional args.\nmean_accuracy                                           0.944715\nmean_precision                                          0.948016\nmean_recall                                             0.941238\naccuracy          m: 0.9447145877378436 std: 0.03746846609226435\nprecision         m: 0.948015873015873 std: 0.035728392275797285\nrecall            m: 0.9412382688117983 std: 0.04219766815473462\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perceptron_results_vote = calculate_perceptron(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                               votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(perceptron_results_vote)\n",
    "\n",
    "print_results(perceptron_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n0   DecisionTreeClassifier(max_depth=1, min_sample...   \n9   DecisionTreeClassifier(max_depth=5, min_sample...   \n18  DecisionTreeClassifier(max_depth=9, min_sample...   \n17  DecisionTreeClassifier(max_depth=9, min_sample...   \n14  DecisionTreeClassifier(max_depth=7, min_sample...   \n13  DecisionTreeClassifier(max_depth=7, min_sample...   \n1   DecisionTreeClassifier(max_depth=1, min_sample...   \n10  DecisionTreeClassifier(max_depth=5, min_sample...   \n6   DecisionTreeClassifier(max_depth=3, min_sample...   \n5   DecisionTreeClassifier(max_depth=3, min_sample...   \n2   DecisionTreeClassifier(max_depth=1, min_sample...   \n16  DecisionTreeClassifier(max_depth=9, min_sample...   \n12  DecisionTreeClassifier(max_depth=7, min_sample...   \n4   DecisionTreeClassifier(max_depth=3, min_sample...   \n8   DecisionTreeClassifier(max_depth=5, min_sample...   \n7   DecisionTreeClassifier(max_depth=3, min_sample...   \n11  DecisionTreeClassifier(max_depth=5, min_sample...   \n15  DecisionTreeClassifier(max_depth=7, min_sample...   \n3   DecisionTreeClassifier(max_depth=1, min_sample...   \n19  DecisionTreeClassifier(max_depth=9, min_sample...   \n\n                         arguments  mean_accuracy  mean_precision  \\\n0     max Depth: 1, min Samples: 2       0.967970        0.963363   \n9    max Depth: 5, min Samples: 20       0.967970        0.963363   \n18   max Depth: 9, min Samples: 50       0.967970        0.963363   \n17   max Depth: 9, min Samples: 20       0.967970        0.963363   \n14   max Depth: 7, min Samples: 50       0.967970        0.963363   \n13   max Depth: 7, min Samples: 20       0.967970        0.963363   \n1    max Depth: 1, min Samples: 20       0.967970        0.963363   \n10   max Depth: 5, min Samples: 50       0.967970        0.963363   \n6    max Depth: 3, min Samples: 50       0.967970        0.963363   \n5    max Depth: 3, min Samples: 20       0.967970        0.963363   \n2    max Depth: 1, min Samples: 50       0.967970        0.963363   \n16    max Depth: 9, min Samples: 2       0.963108        0.962291   \n12    max Depth: 7, min Samples: 2       0.954017        0.951846   \n4     max Depth: 3, min Samples: 2       0.954017        0.951803   \n8     max Depth: 5, min Samples: 2       0.949471        0.948274   \n7   max Depth: 3, min Samples: 100       0.614693        0.307347   \n11  max Depth: 5, min Samples: 100       0.614693        0.307347   \n15  max Depth: 7, min Samples: 100       0.614693        0.307347   \n3   max Depth: 1, min Samples: 100       0.614693        0.307347   \n19  max Depth: 9, min Samples: 100       0.614693        0.307347   \n\n    mean_recall                                         accuracy  \\\n0      0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n9      0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n18     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n17     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n14     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n13     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n1      0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n10     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n6      0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n5      0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n2      0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n16     0.961371  m: 0.9631078224101479 std: 0.043123781971146476   \n12     0.951785   m: 0.9540169133192389 std: 0.04396243122391554   \n4      0.953963   m: 0.9540169133192389 std: 0.04396243122391554   \n8      0.945902   m: 0.9494714587737842 std: 0.03996638495639161   \n7      0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n11     0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n15     0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n3      0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n19     0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n\n                                           precision  \\\n0    m: 0.9633625730994153 std: 0.025403888401415272   \n9    m: 0.9633625730994153 std: 0.025403888401415272   \n18   m: 0.9633625730994153 std: 0.025403888401415272   \n17   m: 0.9633625730994153 std: 0.025403888401415272   \n14   m: 0.9633625730994153 std: 0.025403888401415272   \n13   m: 0.9633625730994153 std: 0.025403888401415272   \n1    m: 0.9633625730994153 std: 0.025403888401415272   \n10   m: 0.9633625730994153 std: 0.025403888401415272   \n6    m: 0.9633625730994153 std: 0.025403888401415272   \n5    m: 0.9633625730994153 std: 0.025403888401415272   \n2    m: 0.9633625730994153 std: 0.025403888401415272   \n16    m: 0.9622911445279867 std: 0.04453377582464436   \n12    m: 0.9518455672867437 std: 0.04523974728680564   \n4     m: 0.9518028322440089 std: 0.04526497840274823   \n8     m: 0.9482741387153153 std: 0.04187714065061258   \n7   m: 0.3073467230443975 std: 0.0037336116305389825   \n11  m: 0.3073467230443975 std: 0.0037336116305389825   \n15  m: 0.3073467230443975 std: 0.0037336116305389825   \n3   m: 0.3073467230443975 std: 0.0037336116305389825   \n19  m: 0.3073467230443975 std: 0.0037336116305389825   \n\n                                             recall  \n0     m: 0.9737891737891738 std: 0.0190606594685786  \n9     m: 0.9737891737891738 std: 0.0190606594685786  \n18    m: 0.9737891737891738 std: 0.0190606594685786  \n17    m: 0.9737891737891738 std: 0.0190606594685786  \n14    m: 0.9737891737891738 std: 0.0190606594685786  \n13    m: 0.9737891737891738 std: 0.0190606594685786  \n1     m: 0.9737891737891738 std: 0.0190606594685786  \n10    m: 0.9737891737891738 std: 0.0190606594685786  \n6     m: 0.9737891737891738 std: 0.0190606594685786  \n5     m: 0.9737891737891738 std: 0.0190606594685786  \n2     m: 0.9737891737891738 std: 0.0190606594685786  \n16   m: 0.9613708731355789 std: 0.04653565125719753  \n12   m: 0.9517848164906988 std: 0.04720449784599202  \n4    m: 0.9539634657281717 std: 0.04655965367106959  \n8   m: 0.9459024635495223 std: 0.042419753280045526  \n7                                   m: 0.5 std: 0.0  \n11                                  m: 0.5 std: 0.0  \n15                                  m: 0.5 std: 0.0  \n3                                   m: 0.5 std: 0.0  \n19                                  m: 0.5 std: 0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 2</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 2</td>\n      <td>0.963108</td>\n      <td>0.962291</td>\n      <td>0.961371</td>\n      <td>m: 0.9631078224101479 std: 0.043123781971146476</td>\n      <td>m: 0.9622911445279867 std: 0.04453377582464436</td>\n      <td>m: 0.9613708731355789 std: 0.04653565125719753</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 2</td>\n      <td>0.954017</td>\n      <td>0.951846</td>\n      <td>0.951785</td>\n      <td>m: 0.9540169133192389 std: 0.04396243122391554</td>\n      <td>m: 0.9518455672867437 std: 0.04523974728680564</td>\n      <td>m: 0.9517848164906988 std: 0.04720449784599202</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 2</td>\n      <td>0.954017</td>\n      <td>0.951803</td>\n      <td>0.953963</td>\n      <td>m: 0.9540169133192389 std: 0.04396243122391554</td>\n      <td>m: 0.9518028322440089 std: 0.04526497840274823</td>\n      <td>m: 0.9539634657281717 std: 0.04655965367106959</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 2</td>\n      <td>0.949471</td>\n      <td>0.948274</td>\n      <td>0.945902</td>\n      <td>m: 0.9494714587737842 std: 0.03996638495639161</td>\n      <td>m: 0.9482741387153153 std: 0.04187714065061258</td>\n      <td>m: 0.9459024635495223 std: 0.042419753280045526</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        DecisionTreeClassifier(max_depth=1, min_sample...\narguments                              max Depth: 1, min Samples: 2\nmean_accuracy                                               0.96797\nmean_precision                                             0.963363\nmean_recall                                                0.973789\naccuracy             m: 0.967970401691332 std: 0.023305252083176783\nprecision           m: 0.9633625730994153 std: 0.025403888401415272\nrecall                m: 0.9737891737891738 std: 0.0190606594685786\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_results_vote = calculate_decision_tree(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                                     votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(decision_tree_results_vote)\n",
    "\n",
    "print_results(decision_tree_results_vote, \"mean_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                          classifier                arguments  \\\n0   SVC(C=100, degree=1, gamma=0.001, kernel='poly')  Kernel: poly, Degree: 1   \n3                  SVC(C=100, degree=1, gamma=0.001)   Kernel: rbf, Degree: 1   \n4                               SVC(C=100, degree=1)   Kernel: rbf, Degree: 1   \n2  SVC(C=100, degree=1, gamma='auto', kernel='poly')  Kernel: poly, Degree: 1   \n5                 SVC(C=100, degree=1, gamma='auto')   Kernel: rbf, Degree: 1   \n1                SVC(C=100, degree=1, kernel='poly')  Kernel: poly, Degree: 1   \n\n   mean_accuracy  mean_precision  mean_recall  \\\n0       0.967970        0.963363     0.973789   \n3       0.967970        0.963363     0.973789   \n4       0.953805        0.954492     0.951050   \n2       0.949260        0.950921     0.945167   \n5       0.949260        0.948937     0.947346   \n1       0.935518        0.940445     0.929331   \n\n                                         accuracy  \\\n0  m: 0.967970401691332 std: 0.023305252083176783   \n3  m: 0.967970401691332 std: 0.023305252083176783   \n4  m: 0.9538054968287526 std: 0.04396192286723881   \n2  m: 0.9492600422832981 std: 0.03994177338895591   \n5  m: 0.9492600422832981 std: 0.03994177338895591   \n1   m: 0.9355179704016914 std: 0.0398226965851031   \n\n                                         precision  \\\n0  m: 0.9633625730994153 std: 0.025403888401415272   \n3  m: 0.9633625730994153 std: 0.025403888401415272   \n4   m: 0.954492337164751 std: 0.045599206036925855   \n2   m: 0.9509209085933226 std: 0.04248827208564486   \n5   m: 0.9489367816091955 std: 0.04119591828266531   \n1  m: 0.9404447181171319 std: 0.042337481322026534   \n\n                                            recall  \n0    m: 0.9737891737891738 std: 0.0190606594685786  \n3    m: 0.9737891737891738 std: 0.0190606594685786  \n4   m: 0.951049522373052 std: 0.047040431203705595  \n2   m: 0.9451671694318753 std: 0.04213457606582847  \n5  m: 0.9473458186693481 std: 0.043647173124497826  \n1   m: 0.9293311127869952 std: 0.04199492314164729  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SVC(C=100, degree=1, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SVC(C=100, degree=1, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SVC(C=100, degree=1)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVC(C=100, degree=1, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.949260</td>\n      <td>0.950921</td>\n      <td>0.945167</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9509209085933226 std: 0.04248827208564486</td>\n      <td>m: 0.9451671694318753 std: 0.04213457606582847</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>SVC(C=100, degree=1, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.949260</td>\n      <td>0.948937</td>\n      <td>0.947346</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9489367816091955 std: 0.04119591828266531</td>\n      <td>m: 0.9473458186693481 std: 0.043647173124497826</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVC(C=100, degree=1, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.935518</td>\n      <td>0.940445</td>\n      <td>0.929331</td>\n      <td>m: 0.9355179704016914 std: 0.0398226965851031</td>\n      <td>m: 0.9404447181171319 std: 0.042337481322026534</td>\n      <td>m: 0.9293311127869952 std: 0.04199492314164729</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        SVC(C=100, degree=1, gamma=0.001, kernel='poly')\narguments                                  Kernel: poly, Degree: 1\nmean_accuracy                                              0.96797\nmean_precision                                            0.963363\nmean_recall                                               0.973789\naccuracy            m: 0.967970401691332 std: 0.023305252083176783\nprecision          m: 0.9633625730994153 std: 0.025403888401415272\nrecall               m: 0.9737891737891738 std: 0.0190606594685786\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_results_vote = calculate_svm(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                 votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(svm_results_vote)\n",
    "\n",
    "print_results(svm_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overall Results for Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n20  DecisionTreeClassifier(max_depth=3, min_sample...   \n25  DecisionTreeClassifier(max_depth=5, min_sample...   \n24  DecisionTreeClassifier(max_depth=5, min_sample...   \n38                  SVC(C=100, degree=1, gamma=0.001)   \n17  DecisionTreeClassifier(max_depth=1, min_sample...   \n35   SVC(C=100, degree=1, gamma=0.001, kernel='poly')   \n16  DecisionTreeClassifier(max_depth=1, min_sample...   \n15  DecisionTreeClassifier(max_depth=1, min_sample...   \n33  DecisionTreeClassifier(max_depth=9, min_sample...   \n32  DecisionTreeClassifier(max_depth=9, min_sample...   \n21  DecisionTreeClassifier(max_depth=3, min_sample...   \n29  DecisionTreeClassifier(max_depth=7, min_sample...   \n28  DecisionTreeClassifier(max_depth=7, min_sample...   \n31  DecisionTreeClassifier(max_depth=9, min_sample...   \n27  DecisionTreeClassifier(max_depth=7, min_sample...   \n19  DecisionTreeClassifier(max_depth=3, min_sample...   \n39                               SVC(C=100, degree=1)   \n6                 KNeighborsClassifier(n_neighbors=7)   \n7                 KNeighborsClassifier(n_neighbors=8)   \n23  DecisionTreeClassifier(max_depth=5, min_sample...   \n37  SVC(C=100, degree=1, gamma='auto', kernel='poly')   \n40                 SVC(C=100, degree=1, gamma='auto')   \n8                 KNeighborsClassifier(n_neighbors=9)   \n0                 KNeighborsClassifier(n_neighbors=1)   \n2                 KNeighborsClassifier(n_neighbors=3)   \n4                              KNeighborsClassifier()   \n1                 KNeighborsClassifier(n_neighbors=2)   \n14                                       Perceptron()   \n3                 KNeighborsClassifier(n_neighbors=4)   \n5                 KNeighborsClassifier(n_neighbors=6)   \n36                SVC(C=100, degree=1, kernel='poly')   \n13                           CategoricalNB(alpha=4.1)   \n12                           CategoricalNB(alpha=3.1)   \n11                           CategoricalNB(alpha=2.1)   \n9                            CategoricalNB(alpha=0.1)   \n10                           CategoricalNB(alpha=1.1)   \n34  DecisionTreeClassifier(max_depth=9, min_sample...   \n30  DecisionTreeClassifier(max_depth=7, min_sample...   \n26  DecisionTreeClassifier(max_depth=5, min_sample...   \n18  DecisionTreeClassifier(max_depth=1, min_sample...   \n22  DecisionTreeClassifier(max_depth=3, min_sample...   \n\n                         arguments  mean_accuracy  mean_precision  \\\n20   max Depth: 3, min Samples: 20       0.967970        0.963363   \n25   max Depth: 5, min Samples: 50       0.967970        0.963363   \n24   max Depth: 5, min Samples: 20       0.967970        0.963363   \n38          Kernel: rbf, Degree: 1       0.967970        0.963363   \n17   max Depth: 1, min Samples: 50       0.967970        0.963363   \n35         Kernel: poly, Degree: 1       0.967970        0.963363   \n16   max Depth: 1, min Samples: 20       0.967970        0.963363   \n15    max Depth: 1, min Samples: 2       0.967970        0.963363   \n33   max Depth: 9, min Samples: 50       0.967970        0.963363   \n32   max Depth: 9, min Samples: 20       0.967970        0.963363   \n21   max Depth: 3, min Samples: 50       0.967970        0.963363   \n29   max Depth: 7, min Samples: 50       0.967970        0.963363   \n28   max Depth: 7, min Samples: 20       0.967970        0.963363   \n31    max Depth: 9, min Samples: 2       0.963108        0.962291   \n27    max Depth: 7, min Samples: 2       0.954017        0.951846   \n19    max Depth: 3, min Samples: 2       0.954017        0.951803   \n39          Kernel: rbf, Degree: 1       0.953805        0.954492   \n6                            N = 7       0.949789        0.946634   \n7                            N = 8       0.949683        0.946080   \n23    max Depth: 5, min Samples: 2       0.949471        0.948274   \n37         Kernel: poly, Degree: 1       0.949260        0.950921   \n40          Kernel: rbf, Degree: 1       0.949260        0.948937   \n8                            N = 9       0.945243        0.942160   \n0                            N = 1       0.945032        0.942523   \n2                            N = 3       0.945032        0.941734   \n4                            N = 5       0.945032        0.941734   \n1                            N = 2       0.944926        0.945693   \n14             No additional args.       0.944715        0.948016   \n3                            N = 4       0.940381        0.937812   \n5                            N = 6       0.935835        0.934132   \n36         Kernel: poly, Degree: 1       0.935518        0.940445   \n13                     Alpha = 4.1       0.922304        0.918578   \n12                     Alpha = 3.1       0.922304        0.918578   \n11                     Alpha = 2.1       0.917759        0.914147   \n9                      Alpha = 0.1       0.917653        0.916001   \n10                     Alpha = 1.1       0.908562        0.905936   \n34  max Depth: 9, min Samples: 100       0.614693        0.307347   \n30  max Depth: 7, min Samples: 100       0.614693        0.307347   \n26  max Depth: 5, min Samples: 100       0.614693        0.307347   \n18  max Depth: 1, min Samples: 100       0.614693        0.307347   \n22  max Depth: 3, min Samples: 100       0.614693        0.307347   \n\n    mean_recall                                         accuracy  \\\n20     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n25     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n24     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n38     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n17     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n35     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n16     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n15     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n33     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n32     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n21     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n29     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n28     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n31     0.961371  m: 0.9631078224101479 std: 0.043123781971146476   \n27     0.951785   m: 0.9540169133192389 std: 0.04396243122391554   \n19     0.953963   m: 0.9540169133192389 std: 0.04396243122391554   \n39     0.951050   m: 0.9538054968287526 std: 0.04396192286723881   \n6      0.956796   m: 0.9497885835095138 std: 0.03633965972902396   \n7      0.956796   m: 0.9496828752642706 std: 0.03925378581485785   \n23     0.945902   m: 0.9494714587737842 std: 0.03996638495639161   \n37     0.945167   m: 0.9492600422832981 std: 0.03994177338895591   \n40     0.947346   m: 0.9492600422832981 std: 0.03994177338895591   \n8      0.953092   m: 0.9452431289640592 std: 0.03687778755803422   \n0      0.946331   m: 0.945031712473573 std: 0.034048886698533634   \n2      0.950913   m: 0.945031712473573 std: 0.042524418215617005   \n4      0.950913   m: 0.945031712473573 std: 0.042524418215617005   \n1      0.941606   m: 0.9449260042283297 std: 0.03699848987727991   \n14     0.941238   m: 0.9447145877378436 std: 0.03746846609226435   \n3      0.942485  m: 0.9403805496828752 std: 0.027634973997320893   \n5      0.938781  m: 0.9358350951374208 std: 0.033627186829120255   \n36     0.929331    m: 0.9355179704016914 std: 0.0398226965851031   \n13     0.929706   m: 0.9223044397463003 std: 0.04195165926635185   \n12     0.929706   m: 0.9223044397463003 std: 0.04195165926635185   \n11     0.923824   m: 0.9177589852008456 std: 0.03936351367397849   \n9      0.919099  m: 0.9176532769556026 std: 0.036606812641491196   \n10     0.911691   m: 0.9085623678646935 std: 0.03759113618117659   \n34     0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n30     0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n26     0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n18     0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n22     0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n\n                                           precision  \\\n20   m: 0.9633625730994153 std: 0.025403888401415272   \n25   m: 0.9633625730994153 std: 0.025403888401415272   \n24   m: 0.9633625730994153 std: 0.025403888401415272   \n38   m: 0.9633625730994153 std: 0.025403888401415272   \n17   m: 0.9633625730994153 std: 0.025403888401415272   \n35   m: 0.9633625730994153 std: 0.025403888401415272   \n16   m: 0.9633625730994153 std: 0.025403888401415272   \n15   m: 0.9633625730994153 std: 0.025403888401415272   \n33   m: 0.9633625730994153 std: 0.025403888401415272   \n32   m: 0.9633625730994153 std: 0.025403888401415272   \n21   m: 0.9633625730994153 std: 0.025403888401415272   \n29   m: 0.9633625730994153 std: 0.025403888401415272   \n28   m: 0.9633625730994153 std: 0.025403888401415272   \n31    m: 0.9622911445279867 std: 0.04453377582464436   \n27    m: 0.9518455672867437 std: 0.04523974728680564   \n19    m: 0.9518028322440089 std: 0.04526497840274823   \n39    m: 0.954492337164751 std: 0.045599206036925855   \n6     m: 0.9466340390488999 std: 0.03608620915053702   \n7     m: 0.9460797448165869 std: 0.03905530325409666   \n23    m: 0.9482741387153153 std: 0.04187714065061258   \n37    m: 0.9509209085933226 std: 0.04248827208564486   \n40    m: 0.9489367816091955 std: 0.04119591828266531   \n8    m: 0.9421603548383735 std: 0.037090417983209244   \n0     m: 0.9425226260094682 std: 0.03634869147380645   \n2     m: 0.9417338423530375 std: 0.04229555526924847   \n4     m: 0.9417338423530375 std: 0.04229555526924847   \n1     m: 0.9456933175569079 std: 0.04001026811690184   \n14    m: 0.948015873015873 std: 0.035728392275797285   \n3     m: 0.937811566371938 std: 0.030278525504452966   \n5    m: 0.9341319126922842 std: 0.034844958450856264   \n36   m: 0.9404447181171319 std: 0.042337481322026534   \n13    m: 0.9185782390759508 std: 0.04469462645086833   \n12    m: 0.9185782390759508 std: 0.04469462645086833   \n11    m: 0.9141472899081595 std: 0.04267326106536261   \n9    m: 0.9160010673755272 std: 0.041199924531873135   \n10    m: 0.9059362018431694 std: 0.04263650611873664   \n34  m: 0.3073467230443975 std: 0.0037336116305389825   \n30  m: 0.3073467230443975 std: 0.0037336116305389825   \n26  m: 0.3073467230443975 std: 0.0037336116305389825   \n18  m: 0.3073467230443975 std: 0.0037336116305389825   \n22  m: 0.3073467230443975 std: 0.0037336116305389825   \n\n                                             recall  \n20    m: 0.9737891737891738 std: 0.0190606594685786  \n25    m: 0.9737891737891738 std: 0.0190606594685786  \n24    m: 0.9737891737891738 std: 0.0190606594685786  \n38    m: 0.9737891737891738 std: 0.0190606594685786  \n17    m: 0.9737891737891738 std: 0.0190606594685786  \n35    m: 0.9737891737891738 std: 0.0190606594685786  \n16    m: 0.9737891737891738 std: 0.0190606594685786  \n15    m: 0.9737891737891738 std: 0.0190606594685786  \n33    m: 0.9737891737891738 std: 0.0190606594685786  \n32    m: 0.9737891737891738 std: 0.0190606594685786  \n21    m: 0.9737891737891738 std: 0.0190606594685786  \n29    m: 0.9737891737891738 std: 0.0190606594685786  \n28    m: 0.9737891737891738 std: 0.0190606594685786  \n31   m: 0.9613708731355789 std: 0.04653565125719753  \n27   m: 0.9517848164906988 std: 0.04720449784599202  \n19   m: 0.9539634657281717 std: 0.04655965367106959  \n39   m: 0.951049522373052 std: 0.047040431203705595  \n6   m: 0.9567957097368863 std: 0.029626605680041794  \n7   m: 0.9567957097368863 std: 0.033352054331873056  \n23  m: 0.9459024635495223 std: 0.042419753280045526  \n37   m: 0.9451671694318753 std: 0.04213457606582847  \n40  m: 0.9473458186693481 std: 0.043647173124497826  \n8    m: 0.9530920060331824 std: 0.02978123723739161  \n0   m: 0.9463308614043908 std: 0.031909717382637634  \n2   m: 0.9509133567957099 std: 0.039255464764560155  \n4   m: 0.9509133567957099 std: 0.039255464764560155  \n1    m: 0.9416059158706218 std: 0.03451379175922509  \n14   m: 0.9412382688117983 std: 0.04219766815473462  \n3     m: 0.942484707558237 std: 0.02472620156914983  \n5   m: 0.9387810038545334 std: 0.028087583916356424  \n36   m: 0.9293311127869952 std: 0.04199492314164729  \n13   m: 0.9297060918384448 std: 0.03623512490395484  \n12   m: 0.9297060918384448 std: 0.03623512490395484  \n11   m: 0.9238237388972683 std: 0.03255971857919237  \n9    m: 0.9190987933634993 std: 0.03090170389606902  \n10   m: 0.9116913859560919 std: 0.03226414499176202  \n34                                  m: 0.5 std: 0.0  \n30                                  m: 0.5 std: 0.0  \n26                                  m: 0.5 std: 0.0  \n18                                  m: 0.5 std: 0.0  \n22                                  m: 0.5 std: 0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>SVC(C=100, degree=1, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>SVC(C=100, degree=1, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 2</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 2</td>\n      <td>0.963108</td>\n      <td>0.962291</td>\n      <td>0.961371</td>\n      <td>m: 0.9631078224101479 std: 0.043123781971146476</td>\n      <td>m: 0.9622911445279867 std: 0.04453377582464436</td>\n      <td>m: 0.9613708731355789 std: 0.04653565125719753</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 2</td>\n      <td>0.954017</td>\n      <td>0.951846</td>\n      <td>0.951785</td>\n      <td>m: 0.9540169133192389 std: 0.04396243122391554</td>\n      <td>m: 0.9518455672867437 std: 0.04523974728680564</td>\n      <td>m: 0.9517848164906988 std: 0.04720449784599202</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 2</td>\n      <td>0.954017</td>\n      <td>0.951803</td>\n      <td>0.953963</td>\n      <td>m: 0.9540169133192389 std: 0.04396243122391554</td>\n      <td>m: 0.9518028322440089 std: 0.04526497840274823</td>\n      <td>m: 0.9539634657281717 std: 0.04655965367106959</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>SVC(C=100, degree=1)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>KNeighborsClassifier(n_neighbors=7)</td>\n      <td>N = 7</td>\n      <td>0.949789</td>\n      <td>0.946634</td>\n      <td>0.956796</td>\n      <td>m: 0.9497885835095138 std: 0.03633965972902396</td>\n      <td>m: 0.9466340390488999 std: 0.03608620915053702</td>\n      <td>m: 0.9567957097368863 std: 0.029626605680041794</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>KNeighborsClassifier(n_neighbors=8)</td>\n      <td>N = 8</td>\n      <td>0.949683</td>\n      <td>0.946080</td>\n      <td>0.956796</td>\n      <td>m: 0.9496828752642706 std: 0.03925378581485785</td>\n      <td>m: 0.9460797448165869 std: 0.03905530325409666</td>\n      <td>m: 0.9567957097368863 std: 0.033352054331873056</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 2</td>\n      <td>0.949471</td>\n      <td>0.948274</td>\n      <td>0.945902</td>\n      <td>m: 0.9494714587737842 std: 0.03996638495639161</td>\n      <td>m: 0.9482741387153153 std: 0.04187714065061258</td>\n      <td>m: 0.9459024635495223 std: 0.042419753280045526</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>SVC(C=100, degree=1, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.949260</td>\n      <td>0.950921</td>\n      <td>0.945167</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9509209085933226 std: 0.04248827208564486</td>\n      <td>m: 0.9451671694318753 std: 0.04213457606582847</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>SVC(C=100, degree=1, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.949260</td>\n      <td>0.948937</td>\n      <td>0.947346</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9489367816091955 std: 0.04119591828266531</td>\n      <td>m: 0.9473458186693481 std: 0.043647173124497826</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>KNeighborsClassifier(n_neighbors=9)</td>\n      <td>N = 9</td>\n      <td>0.945243</td>\n      <td>0.942160</td>\n      <td>0.953092</td>\n      <td>m: 0.9452431289640592 std: 0.03687778755803422</td>\n      <td>m: 0.9421603548383735 std: 0.037090417983209244</td>\n      <td>m: 0.9530920060331824 std: 0.02978123723739161</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>KNeighborsClassifier(n_neighbors=1)</td>\n      <td>N = 1</td>\n      <td>0.945032</td>\n      <td>0.942523</td>\n      <td>0.946331</td>\n      <td>m: 0.945031712473573 std: 0.034048886698533634</td>\n      <td>m: 0.9425226260094682 std: 0.03634869147380645</td>\n      <td>m: 0.9463308614043908 std: 0.031909717382637634</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KNeighborsClassifier(n_neighbors=3)</td>\n      <td>N = 3</td>\n      <td>0.945032</td>\n      <td>0.941734</td>\n      <td>0.950913</td>\n      <td>m: 0.945031712473573 std: 0.042524418215617005</td>\n      <td>m: 0.9417338423530375 std: 0.04229555526924847</td>\n      <td>m: 0.9509133567957099 std: 0.039255464764560155</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNeighborsClassifier()</td>\n      <td>N = 5</td>\n      <td>0.945032</td>\n      <td>0.941734</td>\n      <td>0.950913</td>\n      <td>m: 0.945031712473573 std: 0.042524418215617005</td>\n      <td>m: 0.9417338423530375 std: 0.04229555526924847</td>\n      <td>m: 0.9509133567957099 std: 0.039255464764560155</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KNeighborsClassifier(n_neighbors=2)</td>\n      <td>N = 2</td>\n      <td>0.944926</td>\n      <td>0.945693</td>\n      <td>0.941606</td>\n      <td>m: 0.9449260042283297 std: 0.03699848987727991</td>\n      <td>m: 0.9456933175569079 std: 0.04001026811690184</td>\n      <td>m: 0.9416059158706218 std: 0.03451379175922509</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Perceptron()</td>\n      <td>No additional args.</td>\n      <td>0.944715</td>\n      <td>0.948016</td>\n      <td>0.941238</td>\n      <td>m: 0.9447145877378436 std: 0.03746846609226435</td>\n      <td>m: 0.948015873015873 std: 0.035728392275797285</td>\n      <td>m: 0.9412382688117983 std: 0.04219766815473462</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KNeighborsClassifier(n_neighbors=4)</td>\n      <td>N = 4</td>\n      <td>0.940381</td>\n      <td>0.937812</td>\n      <td>0.942485</td>\n      <td>m: 0.9403805496828752 std: 0.027634973997320893</td>\n      <td>m: 0.937811566371938 std: 0.030278525504452966</td>\n      <td>m: 0.942484707558237 std: 0.02472620156914983</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNeighborsClassifier(n_neighbors=6)</td>\n      <td>N = 6</td>\n      <td>0.935835</td>\n      <td>0.934132</td>\n      <td>0.938781</td>\n      <td>m: 0.9358350951374208 std: 0.033627186829120255</td>\n      <td>m: 0.9341319126922842 std: 0.034844958450856264</td>\n      <td>m: 0.9387810038545334 std: 0.028087583916356424</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>SVC(C=100, degree=1, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.935518</td>\n      <td>0.940445</td>\n      <td>0.929331</td>\n      <td>m: 0.9355179704016914 std: 0.0398226965851031</td>\n      <td>m: 0.9404447181171319 std: 0.042337481322026534</td>\n      <td>m: 0.9293311127869952 std: 0.04199492314164729</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>CategoricalNB(alpha=4.1)</td>\n      <td>Alpha = 4.1</td>\n      <td>0.922304</td>\n      <td>0.918578</td>\n      <td>0.929706</td>\n      <td>m: 0.9223044397463003 std: 0.04195165926635185</td>\n      <td>m: 0.9185782390759508 std: 0.04469462645086833</td>\n      <td>m: 0.9297060918384448 std: 0.03623512490395484</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>CategoricalNB(alpha=3.1)</td>\n      <td>Alpha = 3.1</td>\n      <td>0.922304</td>\n      <td>0.918578</td>\n      <td>0.929706</td>\n      <td>m: 0.9223044397463003 std: 0.04195165926635185</td>\n      <td>m: 0.9185782390759508 std: 0.04469462645086833</td>\n      <td>m: 0.9297060918384448 std: 0.03623512490395484</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>CategoricalNB(alpha=2.1)</td>\n      <td>Alpha = 2.1</td>\n      <td>0.917759</td>\n      <td>0.914147</td>\n      <td>0.923824</td>\n      <td>m: 0.9177589852008456 std: 0.03936351367397849</td>\n      <td>m: 0.9141472899081595 std: 0.04267326106536261</td>\n      <td>m: 0.9238237388972683 std: 0.03255971857919237</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>CategoricalNB(alpha=0.1)</td>\n      <td>Alpha = 0.1</td>\n      <td>0.917653</td>\n      <td>0.916001</td>\n      <td>0.919099</td>\n      <td>m: 0.9176532769556026 std: 0.036606812641491196</td>\n      <td>m: 0.9160010673755272 std: 0.041199924531873135</td>\n      <td>m: 0.9190987933634993 std: 0.03090170389606902</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>CategoricalNB(alpha=1.1)</td>\n      <td>Alpha = 1.1</td>\n      <td>0.908562</td>\n      <td>0.905936</td>\n      <td>0.911691</td>\n      <td>m: 0.9085623678646935 std: 0.03759113618117659</td>\n      <td>m: 0.9059362018431694 std: 0.04263650611873664</td>\n      <td>m: 0.9116913859560919 std: 0.03226414499176202</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        DecisionTreeClassifier(max_depth=3, min_sample...\narguments                             max Depth: 3, min Samples: 20\nmean_accuracy                                               0.96797\nmean_precision                                             0.963363\nmean_recall                                                0.973789\naccuracy             m: 0.967970401691332 std: 0.023305252083176783\nprecision           m: 0.9633625730994153 std: 0.025403888401415272\nrecall                m: 0.9737891737891738 std: 0.0190606594685786\nName: 20, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_results(overall_results_vote, \"mean_accuracy\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train submission file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "'Finally recoded back: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID       class\n0     13    democrat\n1    393  republican\n2    163    democrat\n3     57  republican\n4    148    democrat\n..   ...         ...\n212  359    democrat\n213  128    democrat\n214   27    democrat\n215  119    democrat\n216  133  republican\n\n[217 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>393</td>\n      <td>republican</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>163</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>57</td>\n      <td>republican</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>148</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>359</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>128</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>27</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>119</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>133</td>\n      <td>republican</td>\n    </tr>\n  </tbody>\n</table>\n<p>217 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Required Imports\n",
    "from sklearn import svm\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Recode values for predicting variables\n",
    "def recode_voting_data(dataset):\n",
    "    dataset = dataset.replace('y', 1)\\\n",
    "        .replace('n', 0)\n",
    "    dataset[dataset.columns[1:18]] = dataset[dataset.columns[1:18]].astype('category')\n",
    "    return pd.DataFrame(dataset, columns=dataset.columns)\n",
    "\n",
    "#Imput missing values\n",
    "def input_missing_values(data, iterative_imputer):\n",
    "    columns = data.columns\n",
    "    data.loc[:, data.columns != \"ID\"] = np.round(imp.transform(data.loc[:, data.columns != \"ID\"]))\n",
    "    data.loc[:, data.columns != \"ID\"] = data.loc[:, data.columns != \"ID\"].apply(lambda x: x.astype('int'))\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "#Read Data\n",
    "votingDataLearn = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.lrn.csv\", na_values='unknown')\n",
    "votingDataTest = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.tes.csv\", na_values='unknown')\n",
    "\n",
    "#Extract target variable\n",
    "votingDataLearn = votingDataLearn.replace('democrat', 2)\\\n",
    "    .replace('republican', 3)\n",
    "\n",
    "y = votingDataLearn[\"class\"]\n",
    "X = pd.DataFrame(votingDataLearn.drop([\"ID\", \"class\"], axis=1))\n",
    "\n",
    "#Recode Variables\n",
    "X = recode_voting_data(X)\n",
    "votingDataTest = recode_voting_data(votingDataTest)\n",
    "\n",
    "#Input missing values\n",
    "imp = IterativeImputer(max_iter=50, random_state=0)\n",
    "combined_data = X.append(votingDataTest)\n",
    "imp.fit(combined_data.loc[:, combined_data.columns != \"ID\"])\n",
    "X = input_missing_values(X, imp)\n",
    "votingDataTest = input_missing_values(votingDataTest, imp)\n",
    "\n",
    "#Calculate Model\n",
    "classifier = svm.SVC(kernel = \"rbf\", gamma=0.001, C=100)\n",
    "#classifier = tree.DecisionTreeClassifier(max_depth=1)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "#Predict the Test Data\n",
    "votingDataTest[\"class\"] = classifier.predict(votingDataTest[votingDataTest.columns[1:18]])\n",
    "\n",
    "#Recode to required output\n",
    "votingDataTest[\"class\"].replace({2: \"democrat\", 3: \"republican\"}, inplace=True)\n",
    "display(\"Finally recoded back: \", votingDataTest[[\"ID\", \"class\"]])\n",
    "votingDataTest[[\"ID\", \"class\"]].to_csv(\"solution_voting.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Amazon\n",
    "\n",
    "### Preparation of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "'Original Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9992  V9993  V9994  V9995  \\\n0      0   9   5   5   9   7   0   8   7   1  ...      0      1      0      1   \n1      1  11   9  15  15   5  11  10   1   5  ...      0      0      0      0   \n2      2  11  10  13  12   6   5   0   3   1  ...      0      0      0      0   \n3      3  18   9   7   8   8   7  12   6   7  ...      0      1      0      0   \n4      4  11   7  10  11   4   5   1   8   4  ...      0      0      0      0   \n..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...    ...    ...    ...   \n745  745   5   5   8   2   8   0   5   1   2  ...      1      0      0      0   \n746  746  22  13   8  14   8  11   3   6   7  ...      6      0      2      0   \n747  747  10   3   5   5   7   1  14   2   6  ...      0      0      4      1   \n748  748   9  13   8   5  11   9   9   3   3  ...      0      0      0      1   \n749  749  12   5   8   4   7   5   0   3   4  ...      0      0      4      0   \n\n     V9996  V9997  V9998  V9999  V10000        Class  \n0        0      0      0      0       2        Power  \n1        0      0      0      0       0       Goonan  \n2        0      0      0      1       0      Merritt  \n3        0      1      0      0       1       Goonan  \n4        0      1      0      0       3         Corn  \n..     ...    ...    ...    ...     ...          ...  \n745      0      0      0      0       0      Chachra  \n746      0      2      0      0       0     Morrison  \n747      0      0      2      0       0      Sherwin  \n748      0      0      0      0       0  Blankenship  \n749      1      0      0      0       0     Davisson  \n\n[750 rows x 10002 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>9</td>\n      <td>7</td>\n      <td>0</td>\n      <td>8</td>\n      <td>7</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Power</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11</td>\n      <td>9</td>\n      <td>15</td>\n      <td>15</td>\n      <td>5</td>\n      <td>11</td>\n      <td>10</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>11</td>\n      <td>10</td>\n      <td>13</td>\n      <td>12</td>\n      <td>6</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Merritt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>18</td>\n      <td>9</td>\n      <td>7</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>12</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>11</td>\n      <td>7</td>\n      <td>10</td>\n      <td>11</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>8</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Corn</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>745</td>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Chachra</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>746</td>\n      <td>22</td>\n      <td>13</td>\n      <td>8</td>\n      <td>14</td>\n      <td>8</td>\n      <td>11</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Morrison</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>747</td>\n      <td>10</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1</td>\n      <td>14</td>\n      <td>2</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sherwin</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>748</td>\n      <td>9</td>\n      <td>13</td>\n      <td>8</td>\n      <td>5</td>\n      <td>11</td>\n      <td>9</td>\n      <td>9</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Blankenship</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>749</td>\n      <td>12</td>\n      <td>5</td>\n      <td>8</td>\n      <td>4</td>\n      <td>7</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Davisson</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10002 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Recoded Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9992  V9993  V9994  V9995  \\\n0      0   9   5   5   9   7   0   8   7   1  ...      0      1      0      1   \n1      1  11   9  15  15   5  11  10   1   5  ...      0      0      0      0   \n2      2  11  10  13  12   6   5   0   3   1  ...      0      0      0      0   \n3      3  18   9   7   8   8   7  12   6   7  ...      0      1      0      0   \n4      4  11   7  10  11   4   5   1   8   4  ...      0      0      0      0   \n..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...    ...    ...    ...   \n745  745   5   5   8   2   8   0   5   1   2  ...      1      0      0      0   \n746  746  22  13   8  14   8  11   3   6   7  ...      6      0      2      0   \n747  747  10   3   5   5   7   1  14   2   6  ...      0      0      4      1   \n748  748   9  13   8   5  11   9   9   3   3  ...      0      0      0      1   \n749  749  12   5   8   4   7   5   0   3   4  ...      0      0      4      0   \n\n     V9996  V9997  V9998  V9999  V10000        Class  \n0        0      0      0      0       2        Power  \n1        0      0      0      0       0       Goonan  \n2        0      0      0      1       0      Merritt  \n3        0      1      0      0       1       Goonan  \n4        0      1      0      0       3         Corn  \n..     ...    ...    ...    ...     ...          ...  \n745      0      0      0      0       0      Chachra  \n746      0      2      0      0       0     Morrison  \n747      0      0      2      0       0      Sherwin  \n748      0      0      0      0       0  Blankenship  \n749      1      0      0      0       0     Davisson  \n\n[750 rows x 10002 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>9</td>\n      <td>7</td>\n      <td>0</td>\n      <td>8</td>\n      <td>7</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Power</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11</td>\n      <td>9</td>\n      <td>15</td>\n      <td>15</td>\n      <td>5</td>\n      <td>11</td>\n      <td>10</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>11</td>\n      <td>10</td>\n      <td>13</td>\n      <td>12</td>\n      <td>6</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Merritt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>18</td>\n      <td>9</td>\n      <td>7</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>12</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>11</td>\n      <td>7</td>\n      <td>10</td>\n      <td>11</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>8</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Corn</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>745</td>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Chachra</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>746</td>\n      <td>22</td>\n      <td>13</td>\n      <td>8</td>\n      <td>14</td>\n      <td>8</td>\n      <td>11</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Morrison</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>747</td>\n      <td>10</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1</td>\n      <td>14</td>\n      <td>2</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sherwin</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>748</td>\n      <td>9</td>\n      <td>13</td>\n      <td>8</td>\n      <td>5</td>\n      <td>11</td>\n      <td>9</td>\n      <td>9</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Blankenship</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>749</td>\n      <td>12</td>\n      <td>5</td>\n      <td>8</td>\n      <td>4</td>\n      <td>7</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Davisson</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10002 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Data: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "           V1        V2        V3        V4        V5        V6        V7  \\\n0    0.022849  0.012694  0.012694  0.022849  0.017771  0.000000  0.020310   \n1    0.030256  0.024755  0.041258  0.041258  0.013753  0.030256  0.027505   \n2    0.028761  0.026146  0.033990  0.031376  0.015688  0.013073  0.000000   \n3    0.041891  0.020946  0.016291  0.018618  0.018618  0.016291  0.027927   \n4    0.028918  0.018402  0.026289  0.028918  0.010516  0.013145  0.002629   \n..        ...       ...       ...       ...       ...       ...       ...   \n745  0.026867  0.026867  0.042987  0.010747  0.042987  0.000000  0.026867   \n746  0.048706  0.028781  0.017711  0.030995  0.017711  0.024353  0.006642   \n747  0.026260  0.007878  0.013130  0.013130  0.018382  0.002626  0.036764   \n748  0.025152  0.036330  0.022357  0.013973  0.030741  0.025152  0.025152   \n749  0.036478  0.015199  0.024319  0.012159  0.021279  0.015199  0.000000   \n\n           V8        V9       V10  ...     V9991     V9992     V9993  \\\n0    0.017771  0.002539  0.012694  ...  0.000000  0.000000  0.002539   \n1    0.002751  0.013753  0.019254  ...  0.000000  0.000000  0.000000   \n2    0.007844  0.002615  0.002615  ...  0.002615  0.000000  0.000000   \n3    0.013964  0.016291  0.002327  ...  0.000000  0.000000  0.002327   \n4    0.021031  0.010516  0.010516  ...  0.000000  0.000000  0.000000   \n..        ...       ...       ...  ...       ...       ...       ...   \n745  0.005373  0.010747  0.016120  ...  0.000000  0.005373  0.000000   \n746  0.013284  0.015497  0.013284  ...  0.000000  0.013284  0.000000   \n747  0.005252  0.015756  0.002626  ...  0.000000  0.000000  0.000000   \n748  0.008384  0.008384  0.016768  ...  0.000000  0.000000  0.000000   \n749  0.009120  0.012159  0.012159  ...  0.000000  0.000000  0.000000   \n\n        V9994     V9995    V9996     V9997     V9998     V9999    V10000  \n0    0.000000  0.002539  0.00000  0.000000  0.000000  0.000000  0.005077  \n1    0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n2    0.000000  0.000000  0.00000  0.000000  0.000000  0.002615  0.000000  \n3    0.000000  0.000000  0.00000  0.002327  0.000000  0.000000  0.002327  \n4    0.000000  0.000000  0.00000  0.002629  0.000000  0.000000  0.007887  \n..        ...       ...      ...       ...       ...       ...       ...  \n745  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n746  0.004428  0.000000  0.00000  0.004428  0.000000  0.000000  0.000000  \n747  0.010504  0.002626  0.00000  0.000000  0.005252  0.000000  0.000000  \n748  0.000000  0.002795  0.00000  0.000000  0.000000  0.000000  0.000000  \n749  0.012159  0.000000  0.00304  0.000000  0.000000  0.000000  0.000000  \n\n[750 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.022849</td>\n      <td>0.012694</td>\n      <td>0.012694</td>\n      <td>0.022849</td>\n      <td>0.017771</td>\n      <td>0.000000</td>\n      <td>0.020310</td>\n      <td>0.017771</td>\n      <td>0.002539</td>\n      <td>0.012694</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002539</td>\n      <td>0.000000</td>\n      <td>0.002539</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005077</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.030256</td>\n      <td>0.024755</td>\n      <td>0.041258</td>\n      <td>0.041258</td>\n      <td>0.013753</td>\n      <td>0.030256</td>\n      <td>0.027505</td>\n      <td>0.002751</td>\n      <td>0.013753</td>\n      <td>0.019254</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.028761</td>\n      <td>0.026146</td>\n      <td>0.033990</td>\n      <td>0.031376</td>\n      <td>0.015688</td>\n      <td>0.013073</td>\n      <td>0.000000</td>\n      <td>0.007844</td>\n      <td>0.002615</td>\n      <td>0.002615</td>\n      <td>...</td>\n      <td>0.002615</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002615</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.041891</td>\n      <td>0.020946</td>\n      <td>0.016291</td>\n      <td>0.018618</td>\n      <td>0.018618</td>\n      <td>0.016291</td>\n      <td>0.027927</td>\n      <td>0.013964</td>\n      <td>0.016291</td>\n      <td>0.002327</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002327</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.002327</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002327</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.028918</td>\n      <td>0.018402</td>\n      <td>0.026289</td>\n      <td>0.028918</td>\n      <td>0.010516</td>\n      <td>0.013145</td>\n      <td>0.002629</td>\n      <td>0.021031</td>\n      <td>0.010516</td>\n      <td>0.010516</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.002629</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.007887</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>0.026867</td>\n      <td>0.026867</td>\n      <td>0.042987</td>\n      <td>0.010747</td>\n      <td>0.042987</td>\n      <td>0.000000</td>\n      <td>0.026867</td>\n      <td>0.005373</td>\n      <td>0.010747</td>\n      <td>0.016120</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.005373</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>0.048706</td>\n      <td>0.028781</td>\n      <td>0.017711</td>\n      <td>0.030995</td>\n      <td>0.017711</td>\n      <td>0.024353</td>\n      <td>0.006642</td>\n      <td>0.013284</td>\n      <td>0.015497</td>\n      <td>0.013284</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.013284</td>\n      <td>0.000000</td>\n      <td>0.004428</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.004428</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>0.026260</td>\n      <td>0.007878</td>\n      <td>0.013130</td>\n      <td>0.013130</td>\n      <td>0.018382</td>\n      <td>0.002626</td>\n      <td>0.036764</td>\n      <td>0.005252</td>\n      <td>0.015756</td>\n      <td>0.002626</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010504</td>\n      <td>0.002626</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.005252</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>0.025152</td>\n      <td>0.036330</td>\n      <td>0.022357</td>\n      <td>0.013973</td>\n      <td>0.030741</td>\n      <td>0.025152</td>\n      <td>0.025152</td>\n      <td>0.008384</td>\n      <td>0.008384</td>\n      <td>0.016768</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002795</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>0.036478</td>\n      <td>0.015199</td>\n      <td>0.024319</td>\n      <td>0.012159</td>\n      <td>0.021279</td>\n      <td>0.015199</td>\n      <td>0.000000</td>\n      <td>0.009120</td>\n      <td>0.012159</td>\n      <td>0.012159</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012159</td>\n      <td>0.000000</td>\n      <td>0.00304</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Target: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0            Power\n1           Goonan\n2          Merritt\n3           Goonan\n4             Corn\n          ...     \n745        Chachra\n746       Morrison\n747        Sherwin\n748    Blankenship\n749       Davisson\nName: Class, Length: 750, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "#Read Data\n",
    "amazonDataLearn = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.lrn.csv\")\n",
    "amazonDataSolutionExample = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.sol.ex.csv\")\n",
    "amazonDataTest = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.tes.csv\")\n",
    "display(\"Original Data\", amazonDataLearn)\n",
    "\n",
    "#Recode values\n",
    "#For One Hot Encoding of Class\n",
    "#amazonDataLearn = pd.concat([amazonDataLearn, pd.get_dummies(amazonDataLearn[\"Class\"], prefix='author_',drop_first=False)], axis=1)\n",
    "#amazonDataLearn.drop(['Class'],axis=1, inplace=True)\n",
    "#names_target = amazonDataLearn.loc[:, amazonDataLearn.columns.str.startswith('author_')]\n",
    "#amazonDataLearn[names_target.columns] = amazonDataLearn[names_target.columns].apply(lambda x: x.astype('category'))\n",
    "\n",
    "# For Label Encoding\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#le.fit(amazonDataLearn['Class'])\n",
    "#amazonDataLearn['Class'] = le.transform(amazonDataLearn['Class'])\n",
    "#amazonDataLearn['Class'] = amazonDataLearn['Class'].astype('category')\n",
    "\n",
    "names_data = amazonDataLearn.loc[:, amazonDataLearn.columns.str.startswith('V')]\n",
    "#amazonDataLearn[0:10000] = amazonDataLearn[0:10000].apply(lambda x: x.astype('int'))\n",
    "\n",
    "# Normalize data\n",
    "def normalize_values(data):\n",
    "    columns = data.columns\n",
    "    data = preprocessing.Normalizer().fit_transform(data)\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "display(\"Recoded Data\", amazonDataLearn)\n",
    "\n",
    "X_amazon = normalize_values(amazonDataLearn[names_data.columns])\n",
    "y_amazon = amazonDataLearn[\"Class\"]\n",
    "\n",
    "display(\"Data: \", X_amazon)\n",
    "display(\"Target: \", y_amazon)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Exploration - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "'Class Frequency'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Sherwin        20\nLovitt         19\nCutey          19\nBrody          19\nDavisson       18\nAgresti        18\nCalvinnme      18\nChachra        18\nPower          18\nBlankenship    17\nLawyeraau      17\nMark           17\nJanson         17\nMessick        17\nBrown          16\nMorrison       16\nJohnson        16\nMitchell       16\nRiley          16\nMerritt        16\nAuken          16\nWilson         16\nCorn           16\nWalters        16\nGrove          16\nComdet         15\nNeal           15\nMahlers2nd     15\nCholette       15\nGoonan         15\nVernon         14\nRobert         14\nKoenig         14\nMcKee          14\nEngineer       14\nShea           14\nCFH            13\nPeterson       13\nVision         13\nChandler       13\nAshbacher      13\nBukowsky       13\nTaylor         12\nNigam          12\nLee            12\nDent           11\nChell          11\nHarp           10\nHayes          10\nKolln           7\nName: Class, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Data Frequencies'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "              ID          V1          V2          V3          V4          V5  \\\ncount  750.00000  750.000000  750.000000  750.000000  750.000000  750.000000   \nmean   374.50000   11.781333    7.574667    6.846667    6.532000    6.205333   \nstd    216.65064    5.771823    3.624446    3.448915    3.888419    3.424248   \nmin      0.00000    0.000000    0.000000    0.000000    0.000000    0.000000   \n25%    187.25000    8.000000    5.000000    4.000000    4.000000    4.000000   \n50%    374.50000   11.000000    7.000000    7.000000    6.000000    6.000000   \n75%    561.75000   15.000000   10.000000    9.000000    9.000000    8.000000   \nmax    749.00000   32.000000   20.000000   20.000000   25.000000   24.000000   \n\n               V6          V7          V8          V9  ...       V9991  \\\ncount  750.000000  750.000000  750.000000  750.000000  ...  750.000000   \nmean     4.614667    4.074667    3.534667    2.969333  ...    0.192000   \nstd      2.832587    4.158383    2.298371    2.037792  ...    0.522334   \nmin      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n25%      3.000000    1.000000    2.000000    1.000000  ...    0.000000   \n50%      4.000000    3.000000    3.000000    3.000000  ...    0.000000   \n75%      6.000000    6.000000    5.000000    4.000000  ...    0.000000   \nmax     15.000000   20.000000   14.000000   11.000000  ...    4.000000   \n\n            V9992       V9993       V9994       V9995       V9996       V9997  \\\ncount  750.000000  750.000000  750.000000  750.000000  750.000000  750.000000   \nmean     0.198667    0.221333    0.176000    0.192000    0.212000    0.193333   \nstd      0.625876    0.533596    0.562239    0.493417    0.510624    0.466454   \nmin      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \nmax      6.000000    4.000000    7.000000    5.000000    4.000000    3.000000   \n\n            V9998       V9999      V10000  \ncount  750.000000  750.000000  750.000000  \nmean     0.226667    0.220000    0.201333  \nstd      0.533856    0.491177    0.540235  \nmin      0.000000    0.000000    0.000000  \n25%      0.000000    0.000000    0.000000  \n50%      0.000000    0.000000    0.000000  \n75%      0.000000    0.000000    0.000000  \nmax      5.000000    3.000000    4.000000  \n\n[8 rows x 10001 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>750.00000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>...</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>374.50000</td>\n      <td>11.781333</td>\n      <td>7.574667</td>\n      <td>6.846667</td>\n      <td>6.532000</td>\n      <td>6.205333</td>\n      <td>4.614667</td>\n      <td>4.074667</td>\n      <td>3.534667</td>\n      <td>2.969333</td>\n      <td>...</td>\n      <td>0.192000</td>\n      <td>0.198667</td>\n      <td>0.221333</td>\n      <td>0.176000</td>\n      <td>0.192000</td>\n      <td>0.212000</td>\n      <td>0.193333</td>\n      <td>0.226667</td>\n      <td>0.220000</td>\n      <td>0.201333</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>216.65064</td>\n      <td>5.771823</td>\n      <td>3.624446</td>\n      <td>3.448915</td>\n      <td>3.888419</td>\n      <td>3.424248</td>\n      <td>2.832587</td>\n      <td>4.158383</td>\n      <td>2.298371</td>\n      <td>2.037792</td>\n      <td>...</td>\n      <td>0.522334</td>\n      <td>0.625876</td>\n      <td>0.533596</td>\n      <td>0.562239</td>\n      <td>0.493417</td>\n      <td>0.510624</td>\n      <td>0.466454</td>\n      <td>0.533856</td>\n      <td>0.491177</td>\n      <td>0.540235</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>187.25000</td>\n      <td>8.000000</td>\n      <td>5.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>374.50000</td>\n      <td>11.000000</td>\n      <td>7.000000</td>\n      <td>7.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>561.75000</td>\n      <td>15.000000</td>\n      <td>10.000000</td>\n      <td>9.000000</td>\n      <td>9.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>5.000000</td>\n      <td>4.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>749.00000</td>\n      <td>32.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>25.000000</td>\n      <td>24.000000</td>\n      <td>15.000000</td>\n      <td>20.000000</td>\n      <td>14.000000</td>\n      <td>11.000000</td>\n      <td>...</td>\n      <td>4.000000</td>\n      <td>6.000000</td>\n      <td>4.000000</td>\n      <td>7.000000</td>\n      <td>5.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>5.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 10001 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classFrequency = amazonDataLearn['Class'].value_counts()\n",
    "display(\"Class Frequency\", classFrequency)\n",
    "\n",
    "display(\"Data Frequencies\", amazonDataLearn.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### k-NN Calculation - Amazon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                            classifier arguments  mean_accuracy  \\\n0  KNeighborsClassifier(n_neighbors=1)     N = 1       0.273333   \n6  KNeighborsClassifier(n_neighbors=7)     N = 7       0.253333   \n7  KNeighborsClassifier(n_neighbors=8)     N = 8       0.246667   \n4               KNeighborsClassifier()     N = 5       0.238667   \n5  KNeighborsClassifier(n_neighbors=6)     N = 6       0.237333   \n8  KNeighborsClassifier(n_neighbors=9)     N = 9       0.234667   \n2  KNeighborsClassifier(n_neighbors=3)     N = 3       0.229333   \n3  KNeighborsClassifier(n_neighbors=4)     N = 4       0.226667   \n1  KNeighborsClassifier(n_neighbors=2)     N = 2       0.221333   \n\n   mean_precision  mean_recall  \\\n0        0.279978     0.262333   \n6        0.280771     0.244000   \n7        0.266944     0.238333   \n4        0.260482     0.232333   \n5        0.256108     0.226667   \n8        0.249151     0.227667   \n2        0.244745     0.227000   \n3        0.250132     0.221333   \n1        0.224895     0.218667   \n\n                                           accuracy  \\\n0   m: 0.2733333333333333 std: 0.018378731669453627   \n6  m: 0.25333333333333335 std: 0.013333333333333327   \n7   m: 0.24666666666666665 std: 0.01632993161855452   \n4  m: 0.23866666666666667 std: 0.022070593809662472   \n5  m: 0.23733333333333334 std: 0.030579586509812573   \n8  m: 0.23466666666666666 std: 0.022469732728470294   \n2   m: 0.22933333333333333 std: 0.01768866554856214   \n3  m: 0.22666666666666666 std: 0.017384539747207068   \n1  m: 0.22133333333333333 std: 0.016546231527987804   \n\n                                          precision  \\\n0   m: 0.2799775335775336 std: 0.024564836359824562   \n6    m: 0.2807707117264662 std: 0.02619790566738083   \n7   m: 0.26694380717321897 std: 0.03690138309463883   \n4   m: 0.2604821920108877 std: 0.043216904898388454   \n5    m: 0.2561081249668206 std: 0.05422575028681419   \n8   m: 0.24915127694981914 std: 0.02777585327246395   \n2   m: 0.24474459037021967 std: 0.04298428983874409   \n3  m: 0.25013176185624697 std: 0.046394677392848166   \n1  m: 0.22489529914529913 std: 0.012649167661970356   \n\n                                             recall  \n0   m: 0.2623333333333333 std: 0.014087031072743617  \n6                m: 0.244 std: 0.009463379711052279  \n7  m: 0.23833333333333334 std: 0.012247448713915901  \n4  m: 0.23233333333333334 std: 0.017907168024751053  \n5  m: 0.22666666666666666 std: 0.026729093595639287  \n8  m: 0.22766666666666663 std: 0.023036203390894655  \n2                 m: 0.227 std: 0.01833030277982336  \n3   m: 0.22133333333333333 std: 0.01442990721460891  \n1   m: 0.21866666666666665 std: 0.01671326818229556  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KNeighborsClassifier(n_neighbors=1)</td>\n      <td>N = 1</td>\n      <td>0.273333</td>\n      <td>0.279978</td>\n      <td>0.262333</td>\n      <td>m: 0.2733333333333333 std: 0.018378731669453627</td>\n      <td>m: 0.2799775335775336 std: 0.024564836359824562</td>\n      <td>m: 0.2623333333333333 std: 0.014087031072743617</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>KNeighborsClassifier(n_neighbors=7)</td>\n      <td>N = 7</td>\n      <td>0.253333</td>\n      <td>0.280771</td>\n      <td>0.244000</td>\n      <td>m: 0.25333333333333335 std: 0.013333333333333327</td>\n      <td>m: 0.2807707117264662 std: 0.02619790566738083</td>\n      <td>m: 0.244 std: 0.009463379711052279</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>KNeighborsClassifier(n_neighbors=8)</td>\n      <td>N = 8</td>\n      <td>0.246667</td>\n      <td>0.266944</td>\n      <td>0.238333</td>\n      <td>m: 0.24666666666666665 std: 0.01632993161855452</td>\n      <td>m: 0.26694380717321897 std: 0.03690138309463883</td>\n      <td>m: 0.23833333333333334 std: 0.012247448713915901</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNeighborsClassifier()</td>\n      <td>N = 5</td>\n      <td>0.238667</td>\n      <td>0.260482</td>\n      <td>0.232333</td>\n      <td>m: 0.23866666666666667 std: 0.022070593809662472</td>\n      <td>m: 0.2604821920108877 std: 0.043216904898388454</td>\n      <td>m: 0.23233333333333334 std: 0.017907168024751053</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNeighborsClassifier(n_neighbors=6)</td>\n      <td>N = 6</td>\n      <td>0.237333</td>\n      <td>0.256108</td>\n      <td>0.226667</td>\n      <td>m: 0.23733333333333334 std: 0.030579586509812573</td>\n      <td>m: 0.2561081249668206 std: 0.05422575028681419</td>\n      <td>m: 0.22666666666666666 std: 0.026729093595639287</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>KNeighborsClassifier(n_neighbors=9)</td>\n      <td>N = 9</td>\n      <td>0.234667</td>\n      <td>0.249151</td>\n      <td>0.227667</td>\n      <td>m: 0.23466666666666666 std: 0.022469732728470294</td>\n      <td>m: 0.24915127694981914 std: 0.02777585327246395</td>\n      <td>m: 0.22766666666666663 std: 0.023036203390894655</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KNeighborsClassifier(n_neighbors=3)</td>\n      <td>N = 3</td>\n      <td>0.229333</td>\n      <td>0.244745</td>\n      <td>0.227000</td>\n      <td>m: 0.22933333333333333 std: 0.01768866554856214</td>\n      <td>m: 0.24474459037021967 std: 0.04298428983874409</td>\n      <td>m: 0.227 std: 0.01833030277982336</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KNeighborsClassifier(n_neighbors=4)</td>\n      <td>N = 4</td>\n      <td>0.226667</td>\n      <td>0.250132</td>\n      <td>0.221333</td>\n      <td>m: 0.22666666666666666 std: 0.017384539747207068</td>\n      <td>m: 0.25013176185624697 std: 0.046394677392848166</td>\n      <td>m: 0.22133333333333333 std: 0.01442990721460891</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KNeighborsClassifier(n_neighbors=2)</td>\n      <td>N = 2</td>\n      <td>0.221333</td>\n      <td>0.224895</td>\n      <td>0.218667</td>\n      <td>m: 0.22133333333333333 std: 0.016546231527987804</td>\n      <td>m: 0.22489529914529913 std: 0.012649167661970356</td>\n      <td>m: 0.21866666666666665 std: 0.01671326818229556</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                    KNeighborsClassifier(n_neighbors=1)\narguments                                                   N = 1\nmean_accuracy                                            0.273333\nmean_precision                                           0.279978\nmean_recall                                              0.262333\naccuracy          m: 0.2733333333333333 std: 0.018378731669453627\nprecision         m: 0.2799775335775336 std: 0.024564836359824562\nrecall            m: 0.2623333333333333 std: 0.014087031072743617\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_results_amazon = calculate_knn(X_amazon,\n",
    "                                   y_amazon)\n",
    "overall_results_amazon.extend(knn_results_amazon)\n",
    "\n",
    "print_results(knn_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     classifier            arguments  mean_accuracy  mean_precision  \\\n0  Perceptron()  No additional args.          0.224        0.228859   \n\n   mean_recall                                         accuracy  \\\n0        0.211  m: 0.22400000000000003 std: 0.07584780081774876   \n\n                                         precision  \\\n0  m: 0.22885949351343768 std: 0.08540867785826414   \n\n                             recall  \n0  m: 0.211 std: 0.0708958547605022  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Perceptron()</td>\n      <td>No additional args.</td>\n      <td>0.224</td>\n      <td>0.228859</td>\n      <td>0.211</td>\n      <td>m: 0.22400000000000003 std: 0.07584780081774876</td>\n      <td>m: 0.22885949351343768 std: 0.08540867785826414</td>\n      <td>m: 0.211 std: 0.0708958547605022</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                                           Perceptron()\narguments                                     No additional args.\nmean_accuracy                                               0.224\nmean_precision                                           0.228859\nmean_recall                                                 0.211\naccuracy          m: 0.22400000000000003 std: 0.07584780081774876\nprecision         m: 0.22885949351343768 std: 0.08540867785826414\nrecall                           m: 0.211 std: 0.0708958547605022\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perceptron_results_amazon = calculate_perceptron(X_amazon,\n",
    "                                                 y_amazon)\n",
    "overall_results_amazon.extend(perceptron_results_amazon)\n",
    "\n",
    "print_results(perceptron_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n17  DecisionTreeClassifier(max_depth=9, min_sample...   \n16  DecisionTreeClassifier(max_depth=9, min_sample...   \n13  DecisionTreeClassifier(max_depth=7, min_sample...   \n12  DecisionTreeClassifier(max_depth=7, min_sample...   \n10  DecisionTreeClassifier(max_depth=5, min_sample...   \n18  DecisionTreeClassifier(max_depth=9, min_sample...   \n14  DecisionTreeClassifier(max_depth=7, min_sample...   \n8   DecisionTreeClassifier(max_depth=5, min_sample...   \n9   DecisionTreeClassifier(max_depth=5, min_sample...   \n6   DecisionTreeClassifier(max_depth=3, min_sample...   \n4   DecisionTreeClassifier(max_depth=3, min_sample...   \n5   DecisionTreeClassifier(max_depth=3, min_sample...   \n15  DecisionTreeClassifier(max_depth=7, min_sample...   \n19  DecisionTreeClassifier(max_depth=9, min_sample...   \n11  DecisionTreeClassifier(max_depth=5, min_sample...   \n7   DecisionTreeClassifier(max_depth=3, min_sample...   \n3   DecisionTreeClassifier(max_depth=1, min_sample...   \n2   DecisionTreeClassifier(max_depth=1, min_sample...   \n0   DecisionTreeClassifier(max_depth=1, min_sample...   \n1   DecisionTreeClassifier(max_depth=1, min_sample...   \n\n                         arguments  mean_accuracy  mean_precision  \\\n17   max Depth: 9, min Samples: 20       0.218667        0.108363   \n16    max Depth: 9, min Samples: 2       0.193333        0.179502   \n13   max Depth: 7, min Samples: 20       0.185333        0.080513   \n12    max Depth: 7, min Samples: 2       0.162667        0.138934   \n10   max Depth: 5, min Samples: 50       0.141333        0.028388   \n18   max Depth: 9, min Samples: 50       0.141333        0.028742   \n14   max Depth: 7, min Samples: 50       0.141333        0.028388   \n8     max Depth: 5, min Samples: 2       0.130667        0.100538   \n9    max Depth: 5, min Samples: 20       0.118667        0.044594   \n6    max Depth: 3, min Samples: 50       0.093333        0.014105   \n4     max Depth: 3, min Samples: 2       0.086667        0.060512   \n5    max Depth: 3, min Samples: 20       0.080000        0.027623   \n15  max Depth: 7, min Samples: 100       0.076000        0.007133   \n19  max Depth: 9, min Samples: 100       0.076000        0.007133   \n11  max Depth: 5, min Samples: 100       0.076000        0.007133   \n7   max Depth: 3, min Samples: 100       0.076000        0.007133   \n3   max Depth: 1, min Samples: 100       0.044000        0.002378   \n2    max Depth: 1, min Samples: 50       0.044000        0.002378   \n0     max Depth: 1, min Samples: 2       0.044000        0.020490   \n1    max Depth: 1, min Samples: 20       0.038667        0.010735   \n\n    mean_recall                                           accuracy  \\\n17     0.205667    m: 0.2186666666666667 std: 0.029333333333333336   \n16     0.187333   m: 0.19333333333333333 std: 0.019321835661585917   \n13     0.171667   m: 0.18533333333333332 std: 0.028720878971384017   \n12     0.154000   m: 0.16266666666666665 std: 0.011623730516108462   \n10     0.132333    m: 0.1413333333333333 std: 0.025785439474418283   \n18     0.132333    m: 0.1413333333333333 std: 0.025785439474418283   \n14     0.132333    m: 0.1413333333333333 std: 0.025785439474418283   \n8      0.117667   m: 0.13066666666666665 std: 0.009977753031397182   \n9      0.107333   m: 0.11866666666666666 std: 0.025438378704451883   \n6      0.084667   m: 0.09333333333333334 std: 0.008432740427115679   \n4      0.079000  m: 0.08666666666666667 std: 0.0042163702135578395   \n5      0.070333   m: 0.07999999999999999 std: 0.011155467020454344   \n15     0.071333                 m: 0.076 std: 0.006798692684790382   \n19     0.071333                 m: 0.076 std: 0.006798692684790382   \n11     0.071333                 m: 0.076 std: 0.006798692684790382   \n7      0.071333                 m: 0.076 std: 0.006798692684790382   \n3      0.040000  m: 0.044000000000000004 std: 0.003265986323710...   \n2      0.040000  m: 0.044000000000000004 std: 0.003265986323710...   \n0      0.039000  m: 0.044000000000000004 std: 0.003265986323710...   \n1      0.033333  m: 0.03866666666666667 std: 0.0077746025264604016   \n\n                                            precision  \\\n17    m: 0.10836293694709254 std: 0.02134780928689491   \n16    m: 0.17950212117271375 std: 0.01389525887424085   \n13   m: 0.08051316840979736 std: 0.017252206912274543   \n12   m: 0.13893387608766306 std: 0.008391703456270121   \n10     m: 0.0283875660287425 std: 0.00586998092696385   \n18  m: 0.028741512735630387 std: 0.005716058018951...   \n14     m: 0.0283875660287425 std: 0.00586998092696385   \n8   m: 0.10053758088030536 std: 7.478836722239618e-05   \n9    m: 0.04459404364335801 std: 0.012487169533942029   \n6   m: 0.014105219748524134 std: 0.001445612402666...   \n4   m: 0.06051205673758866 std: 6.942877342380375e-05   \n5    m: 0.027622905875846416 std: 0.00937725192299915   \n15  m: 0.007133472684943909 std: 0.000861010467426...   \n19  m: 0.007133472684943909 std: 0.000861010467426...   \n11  m: 0.007133472684943909 std: 0.000861010467426...   \n7   m: 0.007133472684943909 std: 0.000861010467426...   \n3   m: 0.002377865968224286 std: 0.000207602854652...   \n2   m: 0.002377865968224286 std: 0.000207602854652...   \n0   m: 0.02048979591836735 std: 6.665278211654873e-05   \n1   m: 0.010734637964774951 std: 0.003902944563754...   \n\n                                               recall  \n17   m: 0.20566666666666666 std: 0.028138546120540387  \n16   m: 0.18733333333333332 std: 0.016519348924485148  \n13    m: 0.1716666666666667 std: 0.027345525735991593  \n12                 m: 0.154 std: 0.011575836902790229  \n10    m: 0.1323333333333333 std: 0.028256759270030317  \n18    m: 0.1323333333333333 std: 0.028256759270030317  \n14    m: 0.1323333333333333 std: 0.028256759270030317  \n8    m: 0.11766666666666666 std: 0.002905932629027114  \n9    m: 0.10733333333333332 std: 0.021255064755906487  \n6    m: 0.08466666666666667 std: 0.007774602526460402  \n4                 m: 0.079 std: 0.0020000000000000018  \n5    m: 0.07033333333333333 std: 0.010187137859957417  \n15   m: 0.07133333333333333 std: 0.007845734863959881  \n19   m: 0.07133333333333333 std: 0.007845734863959881  \n11   m: 0.07133333333333333 std: 0.007845734863959881  \n7    m: 0.07133333333333333 std: 0.007845734863959881  \n3                                    m: 0.04 std: 0.0  \n2                                    m: 0.04 std: 0.0  \n0                 m: 0.039 std: 0.0019999999999999987  \n1   m: 0.03333333333333334 std: 0.0064117946872237815  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 20</td>\n      <td>0.218667</td>\n      <td>0.108363</td>\n      <td>0.205667</td>\n      <td>m: 0.2186666666666667 std: 0.029333333333333336</td>\n      <td>m: 0.10836293694709254 std: 0.02134780928689491</td>\n      <td>m: 0.20566666666666666 std: 0.028138546120540387</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 2</td>\n      <td>0.193333</td>\n      <td>0.179502</td>\n      <td>0.187333</td>\n      <td>m: 0.19333333333333333 std: 0.019321835661585917</td>\n      <td>m: 0.17950212117271375 std: 0.01389525887424085</td>\n      <td>m: 0.18733333333333332 std: 0.016519348924485148</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 20</td>\n      <td>0.185333</td>\n      <td>0.080513</td>\n      <td>0.171667</td>\n      <td>m: 0.18533333333333332 std: 0.028720878971384017</td>\n      <td>m: 0.08051316840979736 std: 0.017252206912274543</td>\n      <td>m: 0.1716666666666667 std: 0.027345525735991593</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 2</td>\n      <td>0.162667</td>\n      <td>0.138934</td>\n      <td>0.154000</td>\n      <td>m: 0.16266666666666665 std: 0.011623730516108462</td>\n      <td>m: 0.13893387608766306 std: 0.008391703456270121</td>\n      <td>m: 0.154 std: 0.011575836902790229</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 50</td>\n      <td>0.141333</td>\n      <td>0.028388</td>\n      <td>0.132333</td>\n      <td>m: 0.1413333333333333 std: 0.025785439474418283</td>\n      <td>m: 0.0283875660287425 std: 0.00586998092696385</td>\n      <td>m: 0.1323333333333333 std: 0.028256759270030317</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 50</td>\n      <td>0.141333</td>\n      <td>0.028742</td>\n      <td>0.132333</td>\n      <td>m: 0.1413333333333333 std: 0.025785439474418283</td>\n      <td>m: 0.028741512735630387 std: 0.005716058018951...</td>\n      <td>m: 0.1323333333333333 std: 0.028256759270030317</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 50</td>\n      <td>0.141333</td>\n      <td>0.028388</td>\n      <td>0.132333</td>\n      <td>m: 0.1413333333333333 std: 0.025785439474418283</td>\n      <td>m: 0.0283875660287425 std: 0.00586998092696385</td>\n      <td>m: 0.1323333333333333 std: 0.028256759270030317</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 2</td>\n      <td>0.130667</td>\n      <td>0.100538</td>\n      <td>0.117667</td>\n      <td>m: 0.13066666666666665 std: 0.009977753031397182</td>\n      <td>m: 0.10053758088030536 std: 7.478836722239618e-05</td>\n      <td>m: 0.11766666666666666 std: 0.002905932629027114</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 20</td>\n      <td>0.118667</td>\n      <td>0.044594</td>\n      <td>0.107333</td>\n      <td>m: 0.11866666666666666 std: 0.025438378704451883</td>\n      <td>m: 0.04459404364335801 std: 0.012487169533942029</td>\n      <td>m: 0.10733333333333332 std: 0.021255064755906487</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 50</td>\n      <td>0.093333</td>\n      <td>0.014105</td>\n      <td>0.084667</td>\n      <td>m: 0.09333333333333334 std: 0.008432740427115679</td>\n      <td>m: 0.014105219748524134 std: 0.001445612402666...</td>\n      <td>m: 0.08466666666666667 std: 0.007774602526460402</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 2</td>\n      <td>0.086667</td>\n      <td>0.060512</td>\n      <td>0.079000</td>\n      <td>m: 0.08666666666666667 std: 0.0042163702135578395</td>\n      <td>m: 0.06051205673758866 std: 6.942877342380375e-05</td>\n      <td>m: 0.079 std: 0.0020000000000000018</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 20</td>\n      <td>0.080000</td>\n      <td>0.027623</td>\n      <td>0.070333</td>\n      <td>m: 0.07999999999999999 std: 0.011155467020454344</td>\n      <td>m: 0.027622905875846416 std: 0.00937725192299915</td>\n      <td>m: 0.07033333333333333 std: 0.010187137859957417</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 100</td>\n      <td>0.076000</td>\n      <td>0.007133</td>\n      <td>0.071333</td>\n      <td>m: 0.076 std: 0.006798692684790382</td>\n      <td>m: 0.007133472684943909 std: 0.000861010467426...</td>\n      <td>m: 0.07133333333333333 std: 0.007845734863959881</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 100</td>\n      <td>0.076000</td>\n      <td>0.007133</td>\n      <td>0.071333</td>\n      <td>m: 0.076 std: 0.006798692684790382</td>\n      <td>m: 0.007133472684943909 std: 0.000861010467426...</td>\n      <td>m: 0.07133333333333333 std: 0.007845734863959881</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 100</td>\n      <td>0.076000</td>\n      <td>0.007133</td>\n      <td>0.071333</td>\n      <td>m: 0.076 std: 0.006798692684790382</td>\n      <td>m: 0.007133472684943909 std: 0.000861010467426...</td>\n      <td>m: 0.07133333333333333 std: 0.007845734863959881</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 100</td>\n      <td>0.076000</td>\n      <td>0.007133</td>\n      <td>0.071333</td>\n      <td>m: 0.076 std: 0.006798692684790382</td>\n      <td>m: 0.007133472684943909 std: 0.000861010467426...</td>\n      <td>m: 0.07133333333333333 std: 0.007845734863959881</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 100</td>\n      <td>0.044000</td>\n      <td>0.002378</td>\n      <td>0.040000</td>\n      <td>m: 0.044000000000000004 std: 0.003265986323710...</td>\n      <td>m: 0.002377865968224286 std: 0.000207602854652...</td>\n      <td>m: 0.04 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 50</td>\n      <td>0.044000</td>\n      <td>0.002378</td>\n      <td>0.040000</td>\n      <td>m: 0.044000000000000004 std: 0.003265986323710...</td>\n      <td>m: 0.002377865968224286 std: 0.000207602854652...</td>\n      <td>m: 0.04 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 2</td>\n      <td>0.044000</td>\n      <td>0.020490</td>\n      <td>0.039000</td>\n      <td>m: 0.044000000000000004 std: 0.003265986323710...</td>\n      <td>m: 0.02048979591836735 std: 6.665278211654873e-05</td>\n      <td>m: 0.039 std: 0.0019999999999999987</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 20</td>\n      <td>0.038667</td>\n      <td>0.010735</td>\n      <td>0.033333</td>\n      <td>m: 0.03866666666666667 std: 0.0077746025264604016</td>\n      <td>m: 0.010734637964774951 std: 0.003902944563754...</td>\n      <td>m: 0.03333333333333334 std: 0.0064117946872237815</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        DecisionTreeClassifier(max_depth=9, min_sample...\narguments                             max Depth: 9, min Samples: 20\nmean_accuracy                                              0.218667\nmean_precision                                             0.108363\nmean_recall                                                0.205667\naccuracy            m: 0.2186666666666667 std: 0.029333333333333336\nprecision           m: 0.10836293694709254 std: 0.02134780928689491\nrecall             m: 0.20566666666666666 std: 0.028138546120540387\nName: 17, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_results_amazon = calculate_decision_tree(X_amazon,\n",
    "                                                       y_amazon)\n",
    "overall_results_amazon.extend(decision_tree_results_amazon)\n",
    "\n",
    "print_results(decision_tree_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                          classifier        arguments  \\\n0  LogisticRegression(class_weight='balanced', pe...  newton-cg, none   \n1  LogisticRegression(class_weight='balanced', so...    newton-cg, l2   \n\n   mean_accuracy  mean_precision  mean_recall  \\\n0       0.594667        0.595733        0.576   \n1       0.384000        0.397903        0.378   \n\n                                         accuracy  \\\n0  m: 0.5946666666666667 std: 0.03194439613522914   \n1               m: 0.384 std: 0.01372750685464934   \n\n                                         precision  \\\n0  m: 0.5957333333333332 std: 0.040680333502659864   \n1  m: 0.3979030769711884 std: 0.032755197789925236   \n\n                               recall  \n0    m: 0.576 std: 0.0309228430488243  \n1  m: 0.378 std: 0.019646882704388503  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LogisticRegression(class_weight='balanced', pe...</td>\n      <td>newton-cg, none</td>\n      <td>0.594667</td>\n      <td>0.595733</td>\n      <td>0.576</td>\n      <td>m: 0.5946666666666667 std: 0.03194439613522914</td>\n      <td>m: 0.5957333333333332 std: 0.040680333502659864</td>\n      <td>m: 0.576 std: 0.0309228430488243</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LogisticRegression(class_weight='balanced', so...</td>\n      <td>newton-cg, l2</td>\n      <td>0.384000</td>\n      <td>0.397903</td>\n      <td>0.378</td>\n      <td>m: 0.384 std: 0.01372750685464934</td>\n      <td>m: 0.3979030769711884 std: 0.032755197789925236</td>\n      <td>m: 0.378 std: 0.019646882704388503</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        LogisticRegression(class_weight='balanced', pe...\narguments                                           newton-cg, none\nmean_accuracy                                              0.594667\nmean_precision                                             0.595733\nmean_recall                                                   0.576\naccuracy             m: 0.5946666666666667 std: 0.03194439613522914\nprecision           m: 0.5957333333333332 std: 0.040680333502659864\nrecall                             m: 0.576 std: 0.0309228430488243\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regression_results_amazon = calculate_logistic_regression(X_amazon,\n",
    "                                                          y_amazon)\n",
    "overall_results_amazon.extend(regression_results_amazon)\n",
    "\n",
    "print_results(regression_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                          classifier                arguments  \\\n1                SVC(C=100, degree=1, kernel='poly')  Kernel: poly, Degree: 1   \n4                               SVC(C=100, degree=1)   Kernel: rbf, Degree: 1   \n0   SVC(C=100, degree=1, gamma=0.001, kernel='poly')  Kernel: poly, Degree: 1   \n2  SVC(C=100, degree=1, gamma='auto', kernel='poly')  Kernel: poly, Degree: 1   \n3                  SVC(C=100, degree=1, gamma=0.001)   Kernel: rbf, Degree: 1   \n5                 SVC(C=100, degree=1, gamma='auto')   Kernel: rbf, Degree: 1   \n\n   mean_accuracy  mean_precision  mean_recall  \\\n1       0.545333        0.549329     0.529000   \n4       0.542667        0.545523     0.528000   \n0       0.036000        0.001677     0.029333   \n2       0.036000        0.001677     0.029333   \n3       0.036000        0.001677     0.029333   \n5       0.036000        0.001677     0.029333   \n\n                                            accuracy  \\\n1    m: 0.5453333333333333 std: 0.023247461032216928   \n4    m: 0.5426666666666666 std: 0.027194770739161545   \n0  m: 0.036000000000000004 std: 0.013063945294843615   \n2  m: 0.036000000000000004 std: 0.013063945294843615   \n3  m: 0.036000000000000004 std: 0.013063945294843615   \n5  m: 0.036000000000000004 std: 0.013063945294843615   \n\n                                           precision  \\\n1      m: 0.5493285714285714 std: 0.0463797237541386   \n4     m: 0.5455225108225108 std: 0.04680865983429606   \n0  m: 0.0016769582648951883 std: 0.00170106346181...   \n2  m: 0.0016769582648951883 std: 0.00170106346181...   \n3  m: 0.0016769582648951883 std: 0.00170106346181...   \n5  m: 0.0016769582648951883 std: 0.00170106346181...   \n\n                                              recall  \n1                 m: 0.529 std: 0.026886593106767716  \n4    m: 0.5279999999999999 std: 0.030099833886584826  \n0  m: 0.029333333333333333 std: 0.013063945294843615  \n2  m: 0.029333333333333333 std: 0.013063945294843615  \n3  m: 0.029333333333333333 std: 0.013063945294843615  \n5  m: 0.029333333333333333 std: 0.013063945294843615  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>SVC(C=100, degree=1, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.545333</td>\n      <td>0.549329</td>\n      <td>0.529000</td>\n      <td>m: 0.5453333333333333 std: 0.023247461032216928</td>\n      <td>m: 0.5493285714285714 std: 0.0463797237541386</td>\n      <td>m: 0.529 std: 0.026886593106767716</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SVC(C=100, degree=1)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.542667</td>\n      <td>0.545523</td>\n      <td>0.528000</td>\n      <td>m: 0.5426666666666666 std: 0.027194770739161545</td>\n      <td>m: 0.5455225108225108 std: 0.04680865983429606</td>\n      <td>m: 0.5279999999999999 std: 0.030099833886584826</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>SVC(C=100, degree=1, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.036000</td>\n      <td>0.001677</td>\n      <td>0.029333</td>\n      <td>m: 0.036000000000000004 std: 0.013063945294843615</td>\n      <td>m: 0.0016769582648951883 std: 0.00170106346181...</td>\n      <td>m: 0.029333333333333333 std: 0.013063945294843615</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVC(C=100, degree=1, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.036000</td>\n      <td>0.001677</td>\n      <td>0.029333</td>\n      <td>m: 0.036000000000000004 std: 0.013063945294843615</td>\n      <td>m: 0.0016769582648951883 std: 0.00170106346181...</td>\n      <td>m: 0.029333333333333333 std: 0.013063945294843615</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SVC(C=100, degree=1, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.036000</td>\n      <td>0.001677</td>\n      <td>0.029333</td>\n      <td>m: 0.036000000000000004 std: 0.013063945294843615</td>\n      <td>m: 0.0016769582648951883 std: 0.00170106346181...</td>\n      <td>m: 0.029333333333333333 std: 0.013063945294843615</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>SVC(C=100, degree=1, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.036000</td>\n      <td>0.001677</td>\n      <td>0.029333</td>\n      <td>m: 0.036000000000000004 std: 0.013063945294843615</td>\n      <td>m: 0.0016769582648951883 std: 0.00170106346181...</td>\n      <td>m: 0.029333333333333333 std: 0.013063945294843615</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                    SVC(C=100, degree=1, kernel='poly')\narguments                                 Kernel: poly, Degree: 1\nmean_accuracy                                            0.545333\nmean_precision                                           0.549329\nmean_recall                                                 0.529\naccuracy          m: 0.5453333333333333 std: 0.023247461032216928\nprecision           m: 0.5493285714285714 std: 0.0463797237541386\nrecall                         m: 0.529 std: 0.026886593106767716\nName: 1, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_results_amazon = calculate_svm(X_amazon,\n",
    "                                   y_amazon)\n",
    "overall_results_amazon.extend(svm_results_amazon)\n",
    "\n",
    "print_results(svm_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overall Results for Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n30  LogisticRegression(class_weight='balanced', pe...   \n33                SVC(C=100, degree=1, kernel='poly')   \n36                               SVC(C=100, degree=1)   \n31  LogisticRegression(class_weight='balanced', so...   \n0                 KNeighborsClassifier(n_neighbors=1)   \n6                 KNeighborsClassifier(n_neighbors=7)   \n7                 KNeighborsClassifier(n_neighbors=8)   \n4                              KNeighborsClassifier()   \n5                 KNeighborsClassifier(n_neighbors=6)   \n8                 KNeighborsClassifier(n_neighbors=9)   \n2                 KNeighborsClassifier(n_neighbors=3)   \n3                 KNeighborsClassifier(n_neighbors=4)   \n9                                        Perceptron()   \n1                 KNeighborsClassifier(n_neighbors=2)   \n27  DecisionTreeClassifier(max_depth=9, min_sample...   \n26  DecisionTreeClassifier(max_depth=9, min_sample...   \n23  DecisionTreeClassifier(max_depth=7, min_sample...   \n22  DecisionTreeClassifier(max_depth=7, min_sample...   \n28  DecisionTreeClassifier(max_depth=9, min_sample...   \n24  DecisionTreeClassifier(max_depth=7, min_sample...   \n20  DecisionTreeClassifier(max_depth=5, min_sample...   \n18  DecisionTreeClassifier(max_depth=5, min_sample...   \n19  DecisionTreeClassifier(max_depth=5, min_sample...   \n16  DecisionTreeClassifier(max_depth=3, min_sample...   \n14  DecisionTreeClassifier(max_depth=3, min_sample...   \n15  DecisionTreeClassifier(max_depth=3, min_sample...   \n21  DecisionTreeClassifier(max_depth=5, min_sample...   \n17  DecisionTreeClassifier(max_depth=3, min_sample...   \n25  DecisionTreeClassifier(max_depth=7, min_sample...   \n29  DecisionTreeClassifier(max_depth=9, min_sample...   \n13  DecisionTreeClassifier(max_depth=1, min_sample...   \n12  DecisionTreeClassifier(max_depth=1, min_sample...   \n10  DecisionTreeClassifier(max_depth=1, min_sample...   \n11  DecisionTreeClassifier(max_depth=1, min_sample...   \n32   SVC(C=100, degree=1, gamma=0.001, kernel='poly')   \n34  SVC(C=100, degree=1, gamma='auto', kernel='poly')   \n35                  SVC(C=100, degree=1, gamma=0.001)   \n37                 SVC(C=100, degree=1, gamma='auto')   \n\n                         arguments  mean_accuracy  mean_precision  \\\n30                 newton-cg, none       0.594667        0.595733   \n33         Kernel: poly, Degree: 1       0.545333        0.549329   \n36          Kernel: rbf, Degree: 1       0.542667        0.545523   \n31                   newton-cg, l2       0.384000        0.397903   \n0                            N = 1       0.273333        0.279978   \n6                            N = 7       0.253333        0.280771   \n7                            N = 8       0.246667        0.266944   \n4                            N = 5       0.238667        0.260482   \n5                            N = 6       0.237333        0.256108   \n8                            N = 9       0.234667        0.249151   \n2                            N = 3       0.229333        0.244745   \n3                            N = 4       0.226667        0.250132   \n9              No additional args.       0.224000        0.228859   \n1                            N = 2       0.221333        0.224895   \n27   max Depth: 9, min Samples: 20       0.218667        0.108363   \n26    max Depth: 9, min Samples: 2       0.193333        0.179502   \n23   max Depth: 7, min Samples: 20       0.185333        0.080513   \n22    max Depth: 7, min Samples: 2       0.162667        0.138934   \n28   max Depth: 9, min Samples: 50       0.141333        0.028742   \n24   max Depth: 7, min Samples: 50       0.141333        0.028388   \n20   max Depth: 5, min Samples: 50       0.141333        0.028388   \n18    max Depth: 5, min Samples: 2       0.130667        0.100538   \n19   max Depth: 5, min Samples: 20       0.118667        0.044594   \n16   max Depth: 3, min Samples: 50       0.093333        0.014105   \n14    max Depth: 3, min Samples: 2       0.086667        0.060512   \n15   max Depth: 3, min Samples: 20       0.080000        0.027623   \n21  max Depth: 5, min Samples: 100       0.076000        0.007133   \n17  max Depth: 3, min Samples: 100       0.076000        0.007133   \n25  max Depth: 7, min Samples: 100       0.076000        0.007133   \n29  max Depth: 9, min Samples: 100       0.076000        0.007133   \n13  max Depth: 1, min Samples: 100       0.044000        0.002378   \n12   max Depth: 1, min Samples: 50       0.044000        0.002378   \n10    max Depth: 1, min Samples: 2       0.044000        0.020490   \n11   max Depth: 1, min Samples: 20       0.038667        0.010735   \n32         Kernel: poly, Degree: 1       0.036000        0.001677   \n34         Kernel: poly, Degree: 1       0.036000        0.001677   \n35          Kernel: rbf, Degree: 1       0.036000        0.001677   \n37          Kernel: rbf, Degree: 1       0.036000        0.001677   \n\n    mean_recall                                           accuracy  \\\n30     0.576000     m: 0.5946666666666667 std: 0.03194439613522914   \n33     0.529000    m: 0.5453333333333333 std: 0.023247461032216928   \n36     0.528000    m: 0.5426666666666666 std: 0.027194770739161545   \n31     0.378000                  m: 0.384 std: 0.01372750685464934   \n0      0.262333    m: 0.2733333333333333 std: 0.018378731669453627   \n6      0.244000   m: 0.25333333333333335 std: 0.013333333333333327   \n7      0.238333    m: 0.24666666666666665 std: 0.01632993161855452   \n4      0.232333   m: 0.23866666666666667 std: 0.022070593809662472   \n5      0.226667   m: 0.23733333333333334 std: 0.030579586509812573   \n8      0.227667   m: 0.23466666666666666 std: 0.022469732728470294   \n2      0.227000    m: 0.22933333333333333 std: 0.01768866554856214   \n3      0.221333   m: 0.22666666666666666 std: 0.017384539747207068   \n9      0.211000    m: 0.22400000000000003 std: 0.07584780081774876   \n1      0.218667   m: 0.22133333333333333 std: 0.016546231527987804   \n27     0.205667    m: 0.2186666666666667 std: 0.029333333333333336   \n26     0.187333   m: 0.19333333333333333 std: 0.019321835661585917   \n23     0.171667   m: 0.18533333333333332 std: 0.028720878971384017   \n22     0.154000   m: 0.16266666666666665 std: 0.011623730516108462   \n28     0.132333    m: 0.1413333333333333 std: 0.025785439474418283   \n24     0.132333    m: 0.1413333333333333 std: 0.025785439474418283   \n20     0.132333    m: 0.1413333333333333 std: 0.025785439474418283   \n18     0.117667   m: 0.13066666666666665 std: 0.009977753031397182   \n19     0.107333   m: 0.11866666666666666 std: 0.025438378704451883   \n16     0.084667   m: 0.09333333333333334 std: 0.008432740427115679   \n14     0.079000  m: 0.08666666666666667 std: 0.0042163702135578395   \n15     0.070333   m: 0.07999999999999999 std: 0.011155467020454344   \n21     0.071333                 m: 0.076 std: 0.006798692684790382   \n17     0.071333                 m: 0.076 std: 0.006798692684790382   \n25     0.071333                 m: 0.076 std: 0.006798692684790382   \n29     0.071333                 m: 0.076 std: 0.006798692684790382   \n13     0.040000  m: 0.044000000000000004 std: 0.003265986323710...   \n12     0.040000  m: 0.044000000000000004 std: 0.003265986323710...   \n10     0.039000  m: 0.044000000000000004 std: 0.003265986323710...   \n11     0.033333  m: 0.03866666666666667 std: 0.0077746025264604016   \n32     0.029333  m: 0.036000000000000004 std: 0.013063945294843615   \n34     0.029333  m: 0.036000000000000004 std: 0.013063945294843615   \n35     0.029333  m: 0.036000000000000004 std: 0.013063945294843615   \n37     0.029333  m: 0.036000000000000004 std: 0.013063945294843615   \n\n                                            precision  \\\n30    m: 0.5957333333333332 std: 0.040680333502659864   \n33      m: 0.5493285714285714 std: 0.0463797237541386   \n36     m: 0.5455225108225108 std: 0.04680865983429606   \n31    m: 0.3979030769711884 std: 0.032755197789925236   \n0     m: 0.2799775335775336 std: 0.024564836359824562   \n6      m: 0.2807707117264662 std: 0.02619790566738083   \n7     m: 0.26694380717321897 std: 0.03690138309463883   \n4     m: 0.2604821920108877 std: 0.043216904898388454   \n5      m: 0.2561081249668206 std: 0.05422575028681419   \n8     m: 0.24915127694981914 std: 0.02777585327246395   \n2     m: 0.24474459037021967 std: 0.04298428983874409   \n3    m: 0.25013176185624697 std: 0.046394677392848166   \n9     m: 0.22885949351343768 std: 0.08540867785826414   \n1    m: 0.22489529914529913 std: 0.012649167661970356   \n27    m: 0.10836293694709254 std: 0.02134780928689491   \n26    m: 0.17950212117271375 std: 0.01389525887424085   \n23   m: 0.08051316840979736 std: 0.017252206912274543   \n22   m: 0.13893387608766306 std: 0.008391703456270121   \n28  m: 0.028741512735630387 std: 0.005716058018951...   \n24     m: 0.0283875660287425 std: 0.00586998092696385   \n20     m: 0.0283875660287425 std: 0.00586998092696385   \n18  m: 0.10053758088030536 std: 7.478836722239618e-05   \n19   m: 0.04459404364335801 std: 0.012487169533942029   \n16  m: 0.014105219748524134 std: 0.001445612402666...   \n14  m: 0.06051205673758866 std: 6.942877342380375e-05   \n15   m: 0.027622905875846416 std: 0.00937725192299915   \n21  m: 0.007133472684943909 std: 0.000861010467426...   \n17  m: 0.007133472684943909 std: 0.000861010467426...   \n25  m: 0.007133472684943909 std: 0.000861010467426...   \n29  m: 0.007133472684943909 std: 0.000861010467426...   \n13  m: 0.002377865968224286 std: 0.000207602854652...   \n12  m: 0.002377865968224286 std: 0.000207602854652...   \n10  m: 0.02048979591836735 std: 6.665278211654873e-05   \n11  m: 0.010734637964774951 std: 0.003902944563754...   \n32  m: 0.0016769582648951883 std: 0.00170106346181...   \n34  m: 0.0016769582648951883 std: 0.00170106346181...   \n35  m: 0.0016769582648951883 std: 0.00170106346181...   \n37  m: 0.0016769582648951883 std: 0.00170106346181...   \n\n                                               recall  \n30                   m: 0.576 std: 0.0309228430488243  \n33                 m: 0.529 std: 0.026886593106767716  \n36    m: 0.5279999999999999 std: 0.030099833886584826  \n31                 m: 0.378 std: 0.019646882704388503  \n0     m: 0.2623333333333333 std: 0.014087031072743617  \n6                  m: 0.244 std: 0.009463379711052279  \n7    m: 0.23833333333333334 std: 0.012247448713915901  \n4    m: 0.23233333333333334 std: 0.017907168024751053  \n5    m: 0.22666666666666666 std: 0.026729093595639287  \n8    m: 0.22766666666666663 std: 0.023036203390894655  \n2                   m: 0.227 std: 0.01833030277982336  \n3     m: 0.22133333333333333 std: 0.01442990721460891  \n9                    m: 0.211 std: 0.0708958547605022  \n1     m: 0.21866666666666665 std: 0.01671326818229556  \n27   m: 0.20566666666666666 std: 0.028138546120540387  \n26   m: 0.18733333333333332 std: 0.016519348924485148  \n23    m: 0.1716666666666667 std: 0.027345525735991593  \n22                 m: 0.154 std: 0.011575836902790229  \n28    m: 0.1323333333333333 std: 0.028256759270030317  \n24    m: 0.1323333333333333 std: 0.028256759270030317  \n20    m: 0.1323333333333333 std: 0.028256759270030317  \n18   m: 0.11766666666666666 std: 0.002905932629027114  \n19   m: 0.10733333333333332 std: 0.021255064755906487  \n16   m: 0.08466666666666667 std: 0.007774602526460402  \n14                m: 0.079 std: 0.0020000000000000018  \n15   m: 0.07033333333333333 std: 0.010187137859957417  \n21   m: 0.07133333333333333 std: 0.007845734863959881  \n17   m: 0.07133333333333333 std: 0.007845734863959881  \n25   m: 0.07133333333333333 std: 0.007845734863959881  \n29   m: 0.07133333333333333 std: 0.007845734863959881  \n13                                   m: 0.04 std: 0.0  \n12                                   m: 0.04 std: 0.0  \n10                m: 0.039 std: 0.0019999999999999987  \n11  m: 0.03333333333333334 std: 0.0064117946872237815  \n32  m: 0.029333333333333333 std: 0.013063945294843615  \n34  m: 0.029333333333333333 std: 0.013063945294843615  \n35  m: 0.029333333333333333 std: 0.013063945294843615  \n37  m: 0.029333333333333333 std: 0.013063945294843615  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30</th>\n      <td>LogisticRegression(class_weight='balanced', pe...</td>\n      <td>newton-cg, none</td>\n      <td>0.594667</td>\n      <td>0.595733</td>\n      <td>0.576000</td>\n      <td>m: 0.5946666666666667 std: 0.03194439613522914</td>\n      <td>m: 0.5957333333333332 std: 0.040680333502659864</td>\n      <td>m: 0.576 std: 0.0309228430488243</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>SVC(C=100, degree=1, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.545333</td>\n      <td>0.549329</td>\n      <td>0.529000</td>\n      <td>m: 0.5453333333333333 std: 0.023247461032216928</td>\n      <td>m: 0.5493285714285714 std: 0.0463797237541386</td>\n      <td>m: 0.529 std: 0.026886593106767716</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>SVC(C=100, degree=1)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.542667</td>\n      <td>0.545523</td>\n      <td>0.528000</td>\n      <td>m: 0.5426666666666666 std: 0.027194770739161545</td>\n      <td>m: 0.5455225108225108 std: 0.04680865983429606</td>\n      <td>m: 0.5279999999999999 std: 0.030099833886584826</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>LogisticRegression(class_weight='balanced', so...</td>\n      <td>newton-cg, l2</td>\n      <td>0.384000</td>\n      <td>0.397903</td>\n      <td>0.378000</td>\n      <td>m: 0.384 std: 0.01372750685464934</td>\n      <td>m: 0.3979030769711884 std: 0.032755197789925236</td>\n      <td>m: 0.378 std: 0.019646882704388503</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>KNeighborsClassifier(n_neighbors=1)</td>\n      <td>N = 1</td>\n      <td>0.273333</td>\n      <td>0.279978</td>\n      <td>0.262333</td>\n      <td>m: 0.2733333333333333 std: 0.018378731669453627</td>\n      <td>m: 0.2799775335775336 std: 0.024564836359824562</td>\n      <td>m: 0.2623333333333333 std: 0.014087031072743617</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>KNeighborsClassifier(n_neighbors=7)</td>\n      <td>N = 7</td>\n      <td>0.253333</td>\n      <td>0.280771</td>\n      <td>0.244000</td>\n      <td>m: 0.25333333333333335 std: 0.013333333333333327</td>\n      <td>m: 0.2807707117264662 std: 0.02619790566738083</td>\n      <td>m: 0.244 std: 0.009463379711052279</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>KNeighborsClassifier(n_neighbors=8)</td>\n      <td>N = 8</td>\n      <td>0.246667</td>\n      <td>0.266944</td>\n      <td>0.238333</td>\n      <td>m: 0.24666666666666665 std: 0.01632993161855452</td>\n      <td>m: 0.26694380717321897 std: 0.03690138309463883</td>\n      <td>m: 0.23833333333333334 std: 0.012247448713915901</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNeighborsClassifier()</td>\n      <td>N = 5</td>\n      <td>0.238667</td>\n      <td>0.260482</td>\n      <td>0.232333</td>\n      <td>m: 0.23866666666666667 std: 0.022070593809662472</td>\n      <td>m: 0.2604821920108877 std: 0.043216904898388454</td>\n      <td>m: 0.23233333333333334 std: 0.017907168024751053</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNeighborsClassifier(n_neighbors=6)</td>\n      <td>N = 6</td>\n      <td>0.237333</td>\n      <td>0.256108</td>\n      <td>0.226667</td>\n      <td>m: 0.23733333333333334 std: 0.030579586509812573</td>\n      <td>m: 0.2561081249668206 std: 0.05422575028681419</td>\n      <td>m: 0.22666666666666666 std: 0.026729093595639287</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>KNeighborsClassifier(n_neighbors=9)</td>\n      <td>N = 9</td>\n      <td>0.234667</td>\n      <td>0.249151</td>\n      <td>0.227667</td>\n      <td>m: 0.23466666666666666 std: 0.022469732728470294</td>\n      <td>m: 0.24915127694981914 std: 0.02777585327246395</td>\n      <td>m: 0.22766666666666663 std: 0.023036203390894655</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KNeighborsClassifier(n_neighbors=3)</td>\n      <td>N = 3</td>\n      <td>0.229333</td>\n      <td>0.244745</td>\n      <td>0.227000</td>\n      <td>m: 0.22933333333333333 std: 0.01768866554856214</td>\n      <td>m: 0.24474459037021967 std: 0.04298428983874409</td>\n      <td>m: 0.227 std: 0.01833030277982336</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KNeighborsClassifier(n_neighbors=4)</td>\n      <td>N = 4</td>\n      <td>0.226667</td>\n      <td>0.250132</td>\n      <td>0.221333</td>\n      <td>m: 0.22666666666666666 std: 0.017384539747207068</td>\n      <td>m: 0.25013176185624697 std: 0.046394677392848166</td>\n      <td>m: 0.22133333333333333 std: 0.01442990721460891</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Perceptron()</td>\n      <td>No additional args.</td>\n      <td>0.224000</td>\n      <td>0.228859</td>\n      <td>0.211000</td>\n      <td>m: 0.22400000000000003 std: 0.07584780081774876</td>\n      <td>m: 0.22885949351343768 std: 0.08540867785826414</td>\n      <td>m: 0.211 std: 0.0708958547605022</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KNeighborsClassifier(n_neighbors=2)</td>\n      <td>N = 2</td>\n      <td>0.221333</td>\n      <td>0.224895</td>\n      <td>0.218667</td>\n      <td>m: 0.22133333333333333 std: 0.016546231527987804</td>\n      <td>m: 0.22489529914529913 std: 0.012649167661970356</td>\n      <td>m: 0.21866666666666665 std: 0.01671326818229556</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 20</td>\n      <td>0.218667</td>\n      <td>0.108363</td>\n      <td>0.205667</td>\n      <td>m: 0.2186666666666667 std: 0.029333333333333336</td>\n      <td>m: 0.10836293694709254 std: 0.02134780928689491</td>\n      <td>m: 0.20566666666666666 std: 0.028138546120540387</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 2</td>\n      <td>0.193333</td>\n      <td>0.179502</td>\n      <td>0.187333</td>\n      <td>m: 0.19333333333333333 std: 0.019321835661585917</td>\n      <td>m: 0.17950212117271375 std: 0.01389525887424085</td>\n      <td>m: 0.18733333333333332 std: 0.016519348924485148</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 20</td>\n      <td>0.185333</td>\n      <td>0.080513</td>\n      <td>0.171667</td>\n      <td>m: 0.18533333333333332 std: 0.028720878971384017</td>\n      <td>m: 0.08051316840979736 std: 0.017252206912274543</td>\n      <td>m: 0.1716666666666667 std: 0.027345525735991593</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 2</td>\n      <td>0.162667</td>\n      <td>0.138934</td>\n      <td>0.154000</td>\n      <td>m: 0.16266666666666665 std: 0.011623730516108462</td>\n      <td>m: 0.13893387608766306 std: 0.008391703456270121</td>\n      <td>m: 0.154 std: 0.011575836902790229</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 50</td>\n      <td>0.141333</td>\n      <td>0.028742</td>\n      <td>0.132333</td>\n      <td>m: 0.1413333333333333 std: 0.025785439474418283</td>\n      <td>m: 0.028741512735630387 std: 0.005716058018951...</td>\n      <td>m: 0.1323333333333333 std: 0.028256759270030317</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 50</td>\n      <td>0.141333</td>\n      <td>0.028388</td>\n      <td>0.132333</td>\n      <td>m: 0.1413333333333333 std: 0.025785439474418283</td>\n      <td>m: 0.0283875660287425 std: 0.00586998092696385</td>\n      <td>m: 0.1323333333333333 std: 0.028256759270030317</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 50</td>\n      <td>0.141333</td>\n      <td>0.028388</td>\n      <td>0.132333</td>\n      <td>m: 0.1413333333333333 std: 0.025785439474418283</td>\n      <td>m: 0.0283875660287425 std: 0.00586998092696385</td>\n      <td>m: 0.1323333333333333 std: 0.028256759270030317</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 2</td>\n      <td>0.130667</td>\n      <td>0.100538</td>\n      <td>0.117667</td>\n      <td>m: 0.13066666666666665 std: 0.009977753031397182</td>\n      <td>m: 0.10053758088030536 std: 7.478836722239618e-05</td>\n      <td>m: 0.11766666666666666 std: 0.002905932629027114</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 20</td>\n      <td>0.118667</td>\n      <td>0.044594</td>\n      <td>0.107333</td>\n      <td>m: 0.11866666666666666 std: 0.025438378704451883</td>\n      <td>m: 0.04459404364335801 std: 0.012487169533942029</td>\n      <td>m: 0.10733333333333332 std: 0.021255064755906487</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 50</td>\n      <td>0.093333</td>\n      <td>0.014105</td>\n      <td>0.084667</td>\n      <td>m: 0.09333333333333334 std: 0.008432740427115679</td>\n      <td>m: 0.014105219748524134 std: 0.001445612402666...</td>\n      <td>m: 0.08466666666666667 std: 0.007774602526460402</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 2</td>\n      <td>0.086667</td>\n      <td>0.060512</td>\n      <td>0.079000</td>\n      <td>m: 0.08666666666666667 std: 0.0042163702135578395</td>\n      <td>m: 0.06051205673758866 std: 6.942877342380375e-05</td>\n      <td>m: 0.079 std: 0.0020000000000000018</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 20</td>\n      <td>0.080000</td>\n      <td>0.027623</td>\n      <td>0.070333</td>\n      <td>m: 0.07999999999999999 std: 0.011155467020454344</td>\n      <td>m: 0.027622905875846416 std: 0.00937725192299915</td>\n      <td>m: 0.07033333333333333 std: 0.010187137859957417</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 100</td>\n      <td>0.076000</td>\n      <td>0.007133</td>\n      <td>0.071333</td>\n      <td>m: 0.076 std: 0.006798692684790382</td>\n      <td>m: 0.007133472684943909 std: 0.000861010467426...</td>\n      <td>m: 0.07133333333333333 std: 0.007845734863959881</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 100</td>\n      <td>0.076000</td>\n      <td>0.007133</td>\n      <td>0.071333</td>\n      <td>m: 0.076 std: 0.006798692684790382</td>\n      <td>m: 0.007133472684943909 std: 0.000861010467426...</td>\n      <td>m: 0.07133333333333333 std: 0.007845734863959881</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 100</td>\n      <td>0.076000</td>\n      <td>0.007133</td>\n      <td>0.071333</td>\n      <td>m: 0.076 std: 0.006798692684790382</td>\n      <td>m: 0.007133472684943909 std: 0.000861010467426...</td>\n      <td>m: 0.07133333333333333 std: 0.007845734863959881</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 100</td>\n      <td>0.076000</td>\n      <td>0.007133</td>\n      <td>0.071333</td>\n      <td>m: 0.076 std: 0.006798692684790382</td>\n      <td>m: 0.007133472684943909 std: 0.000861010467426...</td>\n      <td>m: 0.07133333333333333 std: 0.007845734863959881</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 100</td>\n      <td>0.044000</td>\n      <td>0.002378</td>\n      <td>0.040000</td>\n      <td>m: 0.044000000000000004 std: 0.003265986323710...</td>\n      <td>m: 0.002377865968224286 std: 0.000207602854652...</td>\n      <td>m: 0.04 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 50</td>\n      <td>0.044000</td>\n      <td>0.002378</td>\n      <td>0.040000</td>\n      <td>m: 0.044000000000000004 std: 0.003265986323710...</td>\n      <td>m: 0.002377865968224286 std: 0.000207602854652...</td>\n      <td>m: 0.04 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 2</td>\n      <td>0.044000</td>\n      <td>0.020490</td>\n      <td>0.039000</td>\n      <td>m: 0.044000000000000004 std: 0.003265986323710...</td>\n      <td>m: 0.02048979591836735 std: 6.665278211654873e-05</td>\n      <td>m: 0.039 std: 0.0019999999999999987</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 20</td>\n      <td>0.038667</td>\n      <td>0.010735</td>\n      <td>0.033333</td>\n      <td>m: 0.03866666666666667 std: 0.0077746025264604016</td>\n      <td>m: 0.010734637964774951 std: 0.003902944563754...</td>\n      <td>m: 0.03333333333333334 std: 0.0064117946872237815</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>SVC(C=100, degree=1, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.036000</td>\n      <td>0.001677</td>\n      <td>0.029333</td>\n      <td>m: 0.036000000000000004 std: 0.013063945294843615</td>\n      <td>m: 0.0016769582648951883 std: 0.00170106346181...</td>\n      <td>m: 0.029333333333333333 std: 0.013063945294843615</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>SVC(C=100, degree=1, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.036000</td>\n      <td>0.001677</td>\n      <td>0.029333</td>\n      <td>m: 0.036000000000000004 std: 0.013063945294843615</td>\n      <td>m: 0.0016769582648951883 std: 0.00170106346181...</td>\n      <td>m: 0.029333333333333333 std: 0.013063945294843615</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>SVC(C=100, degree=1, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.036000</td>\n      <td>0.001677</td>\n      <td>0.029333</td>\n      <td>m: 0.036000000000000004 std: 0.013063945294843615</td>\n      <td>m: 0.0016769582648951883 std: 0.00170106346181...</td>\n      <td>m: 0.029333333333333333 std: 0.013063945294843615</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>SVC(C=100, degree=1, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.036000</td>\n      <td>0.001677</td>\n      <td>0.029333</td>\n      <td>m: 0.036000000000000004 std: 0.013063945294843615</td>\n      <td>m: 0.0016769582648951883 std: 0.00170106346181...</td>\n      <td>m: 0.029333333333333333 std: 0.013063945294843615</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        LogisticRegression(class_weight='balanced', pe...\narguments                                           newton-cg, none\nmean_accuracy                                              0.594667\nmean_precision                                             0.595733\nmean_recall                                                   0.576\naccuracy             m: 0.5946666666666667 std: 0.03194439613522914\nprecision           m: 0.5957333333333332 std: 0.040680333502659864\nrecall                             m: 0.576 std: 0.0309228430488243\nName: 30, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_results(overall_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "'Recoded Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9992  V9993  V9994  V9995  \\\n0      0   9   5   5   9   7   0   8   7   1  ...      0      1      0      1   \n1      1  11   9  15  15   5  11  10   1   5  ...      0      0      0      0   \n2      2  11  10  13  12   6   5   0   3   1  ...      0      0      0      0   \n3      3  18   9   7   8   8   7  12   6   7  ...      0      1      0      0   \n4      4  11   7  10  11   4   5   1   8   4  ...      0      0      0      0   \n..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...    ...    ...    ...   \n745  745   5   5   8   2   8   0   5   1   2  ...      1      0      0      0   \n746  746  22  13   8  14   8  11   3   6   7  ...      6      0      2      0   \n747  747  10   3   5   5   7   1  14   2   6  ...      0      0      4      1   \n748  748   9  13   8   5  11   9   9   3   3  ...      0      0      0      1   \n749  749  12   5   8   4   7   5   0   3   4  ...      0      0      4      0   \n\n     V9996  V9997  V9998  V9999  V10000        Class  \n0        0      0      0      0       2        Power  \n1        0      0      0      0       0       Goonan  \n2        0      0      0      1       0      Merritt  \n3        0      1      0      0       1       Goonan  \n4        0      1      0      0       3         Corn  \n..     ...    ...    ...    ...     ...          ...  \n745      0      0      0      0       0      Chachra  \n746      0      2      0      0       0     Morrison  \n747      0      0      2      0       0      Sherwin  \n748      0      0      0      0       0  Blankenship  \n749      1      0      0      0       0     Davisson  \n\n[750 rows x 10002 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>9</td>\n      <td>7</td>\n      <td>0</td>\n      <td>8</td>\n      <td>7</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Power</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11</td>\n      <td>9</td>\n      <td>15</td>\n      <td>15</td>\n      <td>5</td>\n      <td>11</td>\n      <td>10</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>11</td>\n      <td>10</td>\n      <td>13</td>\n      <td>12</td>\n      <td>6</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Merritt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>18</td>\n      <td>9</td>\n      <td>7</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>12</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>11</td>\n      <td>7</td>\n      <td>10</td>\n      <td>11</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>8</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Corn</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>745</td>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Chachra</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>746</td>\n      <td>22</td>\n      <td>13</td>\n      <td>8</td>\n      <td>14</td>\n      <td>8</td>\n      <td>11</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Morrison</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>747</td>\n      <td>10</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1</td>\n      <td>14</td>\n      <td>2</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sherwin</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>748</td>\n      <td>9</td>\n      <td>13</td>\n      <td>8</td>\n      <td>5</td>\n      <td>11</td>\n      <td>9</td>\n      <td>9</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Blankenship</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>749</td>\n      <td>12</td>\n      <td>5</td>\n      <td>8</td>\n      <td>4</td>\n      <td>7</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Davisson</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10002 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Data Normalized: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "           V1        V2        V3        V4        V5        V6        V7  \\\n0    0.022849  0.012694  0.012694  0.022849  0.017771  0.000000  0.020310   \n1    0.030256  0.024755  0.041258  0.041258  0.013753  0.030256  0.027505   \n2    0.028761  0.026146  0.033990  0.031376  0.015688  0.013073  0.000000   \n3    0.041891  0.020946  0.016291  0.018618  0.018618  0.016291  0.027927   \n4    0.028918  0.018402  0.026289  0.028918  0.010516  0.013145  0.002629   \n..        ...       ...       ...       ...       ...       ...       ...   \n745  0.026867  0.026867  0.042987  0.010747  0.042987  0.000000  0.026867   \n746  0.048706  0.028781  0.017711  0.030995  0.017711  0.024353  0.006642   \n747  0.026260  0.007878  0.013130  0.013130  0.018382  0.002626  0.036764   \n748  0.025152  0.036330  0.022357  0.013973  0.030741  0.025152  0.025152   \n749  0.036478  0.015199  0.024319  0.012159  0.021279  0.015199  0.000000   \n\n           V8        V9       V10  ...     V9991     V9992     V9993  \\\n0    0.017771  0.002539  0.012694  ...  0.000000  0.000000  0.002539   \n1    0.002751  0.013753  0.019254  ...  0.000000  0.000000  0.000000   \n2    0.007844  0.002615  0.002615  ...  0.002615  0.000000  0.000000   \n3    0.013964  0.016291  0.002327  ...  0.000000  0.000000  0.002327   \n4    0.021031  0.010516  0.010516  ...  0.000000  0.000000  0.000000   \n..        ...       ...       ...  ...       ...       ...       ...   \n745  0.005373  0.010747  0.016120  ...  0.000000  0.005373  0.000000   \n746  0.013284  0.015497  0.013284  ...  0.000000  0.013284  0.000000   \n747  0.005252  0.015756  0.002626  ...  0.000000  0.000000  0.000000   \n748  0.008384  0.008384  0.016768  ...  0.000000  0.000000  0.000000   \n749  0.009120  0.012159  0.012159  ...  0.000000  0.000000  0.000000   \n\n        V9994     V9995    V9996     V9997     V9998     V9999    V10000  \n0    0.000000  0.002539  0.00000  0.000000  0.000000  0.000000  0.005077  \n1    0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n2    0.000000  0.000000  0.00000  0.000000  0.000000  0.002615  0.000000  \n3    0.000000  0.000000  0.00000  0.002327  0.000000  0.000000  0.002327  \n4    0.000000  0.000000  0.00000  0.002629  0.000000  0.000000  0.007887  \n..        ...       ...      ...       ...       ...       ...       ...  \n745  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n746  0.004428  0.000000  0.00000  0.004428  0.000000  0.000000  0.000000  \n747  0.010504  0.002626  0.00000  0.000000  0.005252  0.000000  0.000000  \n748  0.000000  0.002795  0.00000  0.000000  0.000000  0.000000  0.000000  \n749  0.012159  0.000000  0.00304  0.000000  0.000000  0.000000  0.000000  \n\n[750 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.022849</td>\n      <td>0.012694</td>\n      <td>0.012694</td>\n      <td>0.022849</td>\n      <td>0.017771</td>\n      <td>0.000000</td>\n      <td>0.020310</td>\n      <td>0.017771</td>\n      <td>0.002539</td>\n      <td>0.012694</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002539</td>\n      <td>0.000000</td>\n      <td>0.002539</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005077</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.030256</td>\n      <td>0.024755</td>\n      <td>0.041258</td>\n      <td>0.041258</td>\n      <td>0.013753</td>\n      <td>0.030256</td>\n      <td>0.027505</td>\n      <td>0.002751</td>\n      <td>0.013753</td>\n      <td>0.019254</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.028761</td>\n      <td>0.026146</td>\n      <td>0.033990</td>\n      <td>0.031376</td>\n      <td>0.015688</td>\n      <td>0.013073</td>\n      <td>0.000000</td>\n      <td>0.007844</td>\n      <td>0.002615</td>\n      <td>0.002615</td>\n      <td>...</td>\n      <td>0.002615</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002615</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.041891</td>\n      <td>0.020946</td>\n      <td>0.016291</td>\n      <td>0.018618</td>\n      <td>0.018618</td>\n      <td>0.016291</td>\n      <td>0.027927</td>\n      <td>0.013964</td>\n      <td>0.016291</td>\n      <td>0.002327</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002327</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.002327</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002327</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.028918</td>\n      <td>0.018402</td>\n      <td>0.026289</td>\n      <td>0.028918</td>\n      <td>0.010516</td>\n      <td>0.013145</td>\n      <td>0.002629</td>\n      <td>0.021031</td>\n      <td>0.010516</td>\n      <td>0.010516</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.002629</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.007887</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>0.026867</td>\n      <td>0.026867</td>\n      <td>0.042987</td>\n      <td>0.010747</td>\n      <td>0.042987</td>\n      <td>0.000000</td>\n      <td>0.026867</td>\n      <td>0.005373</td>\n      <td>0.010747</td>\n      <td>0.016120</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.005373</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>0.048706</td>\n      <td>0.028781</td>\n      <td>0.017711</td>\n      <td>0.030995</td>\n      <td>0.017711</td>\n      <td>0.024353</td>\n      <td>0.006642</td>\n      <td>0.013284</td>\n      <td>0.015497</td>\n      <td>0.013284</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.013284</td>\n      <td>0.000000</td>\n      <td>0.004428</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.004428</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>0.026260</td>\n      <td>0.007878</td>\n      <td>0.013130</td>\n      <td>0.013130</td>\n      <td>0.018382</td>\n      <td>0.002626</td>\n      <td>0.036764</td>\n      <td>0.005252</td>\n      <td>0.015756</td>\n      <td>0.002626</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010504</td>\n      <td>0.002626</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.005252</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>0.025152</td>\n      <td>0.036330</td>\n      <td>0.022357</td>\n      <td>0.013973</td>\n      <td>0.030741</td>\n      <td>0.025152</td>\n      <td>0.025152</td>\n      <td>0.008384</td>\n      <td>0.008384</td>\n      <td>0.016768</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002795</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>0.036478</td>\n      <td>0.015199</td>\n      <td>0.024319</td>\n      <td>0.012159</td>\n      <td>0.021279</td>\n      <td>0.015199</td>\n      <td>0.000000</td>\n      <td>0.009120</td>\n      <td>0.012159</td>\n      <td>0.012159</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012159</td>\n      <td>0.000000</td>\n      <td>0.00304</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Target: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0            Power\n1           Goonan\n2          Merritt\n3           Goonan\n4             Corn\n          ...     \n745        Chachra\n746       Morrison\n747        Sherwin\n748    Blankenship\n749       Davisson\nName: Class, Length: 750, dtype: category\nCategories (50, object): [Agresti, Ashbacher, Auken, Blankenship, ..., Vernon, Vision, Walters, Wilson]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Test Dataset: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "       ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9991  V9992  V9993  \\\n0     750   3   2   5   1   3   4   9   4   9  ...      0      0      0   \n1     751   9   4   3   4   6   7   2   1   0  ...      0      1      1   \n2     752  18  16   6  13   0   7   0   6   3  ...      1      0      0   \n3     753   5   2   6   2  12   7   1   2   3  ...      0      0      1   \n4     754  14   9   9   5   5   8  10   2   0  ...      0      0      0   \n..    ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...    ...    ...   \n745  1495  10   2   2   5   4   2   6   3   4  ...      0      1      0   \n746  1496  19   8   6  11   6   4   3   8   2  ...      0      0      1   \n747  1497  15   4   8   6  10   6  11   5   9  ...      0      0      3   \n748  1498  13   7  11  14   4   3   0   3   0  ...      0      0      0   \n749  1499   4   3   4   1   4   2   2   1   1  ...      0      0      0   \n\n     V9994  V9995  V9996  V9997  V9998  V9999  V10000  \n0        0      0      1      0      0      0       0  \n1        1      2      0      0      0      0       0  \n2        0      1      0      2      0      0       0  \n3        0      0      0      0      0      0       0  \n4        0      2      1      0      2      0       0  \n..     ...    ...    ...    ...    ...    ...     ...  \n745      0      0      1      0      0      0       0  \n746      0      0      0      3      0      0       0  \n747      0      0      1      0      0      0       0  \n748      0      0      0      0      0      0       0  \n749      0      0      1      0      0      0       0  \n\n[750 rows x 10001 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>750</td>\n      <td>3</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>9</td>\n      <td>4</td>\n      <td>9</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>751</td>\n      <td>9</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>6</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>752</td>\n      <td>18</td>\n      <td>16</td>\n      <td>6</td>\n      <td>13</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>753</td>\n      <td>5</td>\n      <td>2</td>\n      <td>6</td>\n      <td>2</td>\n      <td>12</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>754</td>\n      <td>14</td>\n      <td>9</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>10</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>1495</td>\n      <td>10</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>1496</td>\n      <td>19</td>\n      <td>8</td>\n      <td>6</td>\n      <td>11</td>\n      <td>6</td>\n      <td>4</td>\n      <td>3</td>\n      <td>8</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>1497</td>\n      <td>15</td>\n      <td>4</td>\n      <td>8</td>\n      <td>6</td>\n      <td>10</td>\n      <td>6</td>\n      <td>11</td>\n      <td>5</td>\n      <td>9</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>1498</td>\n      <td>13</td>\n      <td>7</td>\n      <td>11</td>\n      <td>14</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>1499</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10001 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Test Dataset, Predictors: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  ...  V9991  V9992  V9993  V9994  \\\n0     3   2   5   1   3   4   9   4   9    4  ...      0      0      0      0   \n1     9   4   3   4   6   7   2   1   0    1  ...      0      1      1      1   \n2    18  16   6  13   0   7   0   6   3    0  ...      1      0      0      0   \n3     5   2   6   2  12   7   1   2   3    5  ...      0      0      1      0   \n4    14   9   9   5   5   8  10   2   0    5  ...      0      0      0      0   \n..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...    ...    ...    ...    ...   \n745  10   2   2   5   4   2   6   3   4    1  ...      0      1      0      0   \n746  19   8   6  11   6   4   3   8   2    3  ...      0      0      1      0   \n747  15   4   8   6  10   6  11   5   9    2  ...      0      0      3      0   \n748  13   7  11  14   4   3   0   3   0    0  ...      0      0      0      0   \n749   4   3   4   1   4   2   2   1   1    2  ...      0      0      0      0   \n\n     V9995  V9996  V9997  V9998  V9999  V10000  \n0        0      1      0      0      0       0  \n1        2      0      0      0      0       0  \n2        1      0      2      0      0       0  \n3        0      0      0      0      0       0  \n4        2      1      0      2      0       0  \n..     ...    ...    ...    ...    ...     ...  \n745      0      1      0      0      0       0  \n746      0      0      3      0      0       0  \n747      0      1      0      0      0       0  \n748      0      0      0      0      0       0  \n749      0      1      0      0      0       0  \n\n[750 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>9</td>\n      <td>4</td>\n      <td>9</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>6</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18</td>\n      <td>16</td>\n      <td>6</td>\n      <td>13</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>2</td>\n      <td>6</td>\n      <td>2</td>\n      <td>12</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14</td>\n      <td>9</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>10</td>\n      <td>2</td>\n      <td>0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>10</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>19</td>\n      <td>8</td>\n      <td>6</td>\n      <td>11</td>\n      <td>6</td>\n      <td>4</td>\n      <td>3</td>\n      <td>8</td>\n      <td>2</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>15</td>\n      <td>4</td>\n      <td>8</td>\n      <td>6</td>\n      <td>10</td>\n      <td>6</td>\n      <td>11</td>\n      <td>5</td>\n      <td>9</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>13</td>\n      <td>7</td>\n      <td>11</td>\n      <td>14</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Test Dataset, Normalized: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "           V1        V2        V3        V4        V5        V6        V7  \\\n0    0.009978  0.006652  0.016630  0.003326  0.009978  0.013304  0.029935   \n1    0.026896  0.011954  0.008965  0.011954  0.017930  0.020919  0.005977   \n2    0.046578  0.041402  0.015526  0.033639  0.000000  0.018114  0.000000   \n3    0.014007  0.005603  0.016809  0.005603  0.033617  0.019610  0.002801   \n4    0.035705  0.022953  0.022953  0.012752  0.012752  0.020403  0.025503   \n..        ...       ...       ...       ...       ...       ...       ...   \n745  0.033729  0.006746  0.006746  0.016865  0.013492  0.006746  0.020237   \n746  0.057413  0.024174  0.018131  0.033239  0.018131  0.012087  0.009065   \n747  0.035489  0.009464  0.018928  0.014196  0.023659  0.014196  0.026025   \n748  0.036754  0.019790  0.031099  0.039581  0.011309  0.008482  0.000000   \n749  0.027758  0.020818  0.027758  0.006939  0.027758  0.013879  0.013879   \n\n           V8        V9       V10  ...     V9991     V9992     V9993  \\\n0    0.013304  0.029935  0.013304  ...  0.000000  0.000000  0.000000   \n1    0.002988  0.000000  0.002988  ...  0.000000  0.002988  0.002988   \n2    0.015526  0.007763  0.000000  ...  0.002588  0.000000  0.000000   \n3    0.005603  0.008404  0.014007  ...  0.000000  0.000000  0.002801   \n4    0.005101  0.000000  0.012752  ...  0.000000  0.000000  0.000000   \n..        ...       ...       ...  ...       ...       ...       ...   \n745  0.010119  0.013492  0.003373  ...  0.000000  0.003373  0.000000   \n746  0.024174  0.006044  0.009065  ...  0.000000  0.000000  0.003022   \n747  0.011830  0.021293  0.004732  ...  0.000000  0.000000  0.007098   \n748  0.008482  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n749  0.006939  0.006939  0.013879  ...  0.000000  0.000000  0.000000   \n\n        V9994     V9995     V9996     V9997     V9998  V9999  V10000  \n0    0.000000  0.000000  0.003326  0.000000  0.000000    0.0     0.0  \n1    0.002988  0.005977  0.000000  0.000000  0.000000    0.0     0.0  \n2    0.000000  0.002588  0.000000  0.005175  0.000000    0.0     0.0  \n3    0.000000  0.000000  0.000000  0.000000  0.000000    0.0     0.0  \n4    0.000000  0.005101  0.002550  0.000000  0.005101    0.0     0.0  \n..        ...       ...       ...       ...       ...    ...     ...  \n745  0.000000  0.000000  0.003373  0.000000  0.000000    0.0     0.0  \n746  0.000000  0.000000  0.000000  0.009065  0.000000    0.0     0.0  \n747  0.000000  0.000000  0.002366  0.000000  0.000000    0.0     0.0  \n748  0.000000  0.000000  0.000000  0.000000  0.000000    0.0     0.0  \n749  0.000000  0.000000  0.006939  0.000000  0.000000    0.0     0.0  \n\n[750 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.009978</td>\n      <td>0.006652</td>\n      <td>0.016630</td>\n      <td>0.003326</td>\n      <td>0.009978</td>\n      <td>0.013304</td>\n      <td>0.029935</td>\n      <td>0.013304</td>\n      <td>0.029935</td>\n      <td>0.013304</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003326</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.026896</td>\n      <td>0.011954</td>\n      <td>0.008965</td>\n      <td>0.011954</td>\n      <td>0.017930</td>\n      <td>0.020919</td>\n      <td>0.005977</td>\n      <td>0.002988</td>\n      <td>0.000000</td>\n      <td>0.002988</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.002988</td>\n      <td>0.002988</td>\n      <td>0.002988</td>\n      <td>0.005977</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.046578</td>\n      <td>0.041402</td>\n      <td>0.015526</td>\n      <td>0.033639</td>\n      <td>0.000000</td>\n      <td>0.018114</td>\n      <td>0.000000</td>\n      <td>0.015526</td>\n      <td>0.007763</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.002588</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002588</td>\n      <td>0.000000</td>\n      <td>0.005175</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.014007</td>\n      <td>0.005603</td>\n      <td>0.016809</td>\n      <td>0.005603</td>\n      <td>0.033617</td>\n      <td>0.019610</td>\n      <td>0.002801</td>\n      <td>0.005603</td>\n      <td>0.008404</td>\n      <td>0.014007</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002801</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.035705</td>\n      <td>0.022953</td>\n      <td>0.022953</td>\n      <td>0.012752</td>\n      <td>0.012752</td>\n      <td>0.020403</td>\n      <td>0.025503</td>\n      <td>0.005101</td>\n      <td>0.000000</td>\n      <td>0.012752</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005101</td>\n      <td>0.002550</td>\n      <td>0.000000</td>\n      <td>0.005101</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>0.033729</td>\n      <td>0.006746</td>\n      <td>0.006746</td>\n      <td>0.016865</td>\n      <td>0.013492</td>\n      <td>0.006746</td>\n      <td>0.020237</td>\n      <td>0.010119</td>\n      <td>0.013492</td>\n      <td>0.003373</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.003373</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003373</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>0.057413</td>\n      <td>0.024174</td>\n      <td>0.018131</td>\n      <td>0.033239</td>\n      <td>0.018131</td>\n      <td>0.012087</td>\n      <td>0.009065</td>\n      <td>0.024174</td>\n      <td>0.006044</td>\n      <td>0.009065</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003022</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.009065</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>0.035489</td>\n      <td>0.009464</td>\n      <td>0.018928</td>\n      <td>0.014196</td>\n      <td>0.023659</td>\n      <td>0.014196</td>\n      <td>0.026025</td>\n      <td>0.011830</td>\n      <td>0.021293</td>\n      <td>0.004732</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.007098</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002366</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>0.036754</td>\n      <td>0.019790</td>\n      <td>0.031099</td>\n      <td>0.039581</td>\n      <td>0.011309</td>\n      <td>0.008482</td>\n      <td>0.000000</td>\n      <td>0.008482</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>0.027758</td>\n      <td>0.020818</td>\n      <td>0.027758</td>\n      <td>0.006939</td>\n      <td>0.027758</td>\n      <td>0.013879</td>\n      <td>0.013879</td>\n      <td>0.006939</td>\n      <td>0.006939</td>\n      <td>0.013879</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.006939</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Finally recoded: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "       ID      Class\n0     750    Sherwin\n1     751   Engineer\n2     752   Morrison\n3     753       Dent\n4     754    Agresti\n..    ...        ...\n745  1495     Lovitt\n746  1496  Ashbacher\n747  1497   Cholette\n748  1498      Auken\n749  1499    Chachra\n\n[750 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>750</td>\n      <td>Sherwin</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>751</td>\n      <td>Engineer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>752</td>\n      <td>Morrison</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>753</td>\n      <td>Dent</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>754</td>\n      <td>Agresti</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>1495</td>\n      <td>Lovitt</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>1496</td>\n      <td>Ashbacher</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>1497</td>\n      <td>Cholette</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>1498</td>\n      <td>Auken</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>1499</td>\n      <td>Chachra</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "#from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Read Data\n",
    "amazon_data_learn = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.lrn.csv\")\n",
    "amazon_data_test = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.tes.csv\")\n",
    "\n",
    "# Label Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(amazon_data_learn[\"Class\"])\n",
    "#amazon_data_learn[\"Class\"] = le.transform(amazon_data_learn[\"Class\"])\n",
    "amazon_data_learn[\"Class\"] = amazon_data_learn[\"Class\"].astype(\"category\")\n",
    "\n",
    "names_data = amazon_data_learn.loc[:, amazon_data_learn.columns.str.startswith(\"V\")]\n",
    "\n",
    "display(\"Recoded Data\", amazon_data_learn)\n",
    "y = amazon_data_learn[\"Class\"]\n",
    "X = pd.DataFrame(amazon_data_learn.drop([\"ID\", \"Class\"], axis=1))\n",
    "X = X[names_data.columns]\n",
    "\n",
    "#Normalize data\n",
    "def normalize_values(data):\n",
    "    columns = data.columns\n",
    "    data = preprocessing.Normalizer().fit_transform(data)\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "X_norm = normalize_values(X)\n",
    "test_X = normalize_values(amazon_data_test[names_data.columns])\n",
    "\n",
    "display(\"Data Normalized: \", X_norm)\n",
    "display(\"Target: \", y)\n",
    "display(\"Test Dataset: \", amazon_data_test)\n",
    "display(\"Test Dataset, Predictors: \", amazon_data_test[names_data.columns])\n",
    "display(\"Test Dataset, Normalized: \", test_X)\n",
    "\n",
    "#Calculate Model\n",
    "\n",
    "#classifier = svm.SVC(C=101, kernel='poly')\n",
    "classifier = linear_model.LogisticRegression(solver = \"newton-cg\",\n",
    "                                             class_weight = \"balanced\",\n",
    "                                             penalty = \"none\")\n",
    "classifier.fit(X_norm, y)\n",
    "\n",
    "#Predict the Test Data\n",
    "amazon_data_test[\"Class\"] = classifier.predict(test_X)\n",
    "\n",
    "display(\"Finally recoded: \", amazon_data_test[[\"ID\", \"Class\"]])\n",
    "amazon_data_test[[\"ID\", \"Class\"]].to_csv(\"solution_amazon.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}