{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MLE - Exercise 3 - Kaggle Competition\n",
    "## Andreas Kocman (se19m024)\n",
    "\n",
    "\n",
    "This exercise is in the form of a Kaggle competition. A few quick details on Kaggle & the competition format:\n",
    "\n",
    "## Kaggle\n",
    "* Kaggle (https://en.wikipedia.org/wiki/Kaggle) is a platform that allows a competition for a certain data set. Participants submit their prediction on a test set, and will get automated scoring on their results, and will enter the leaderboard.\n",
    "* From Kaggle, you will be able to obtain a labelled training set, and an unlabelled test set.\n",
    "* You can submit multiple entries to Kaggle; for each entry, you need to provide details on how you achieved the results - which software and which version of the software, which operating system, which algorithms, and which parameter settings for these algorithms; further, any processing applied to the data before training/predicting. There is a specific \"description\" field when submitting, you should fill in this information there, and you also need to include this description and the actual submission file in your final submission to Moodle.\n",
    "* To submit to Kaggle, you need to create a specific submission file, which contains the predictions you obtain on the test set. Computing an aggregated evaluation criterion is done automatically by Kaggle\n",
    "* The format of your submission is rather simple - it is a comma-separated file, where the first column is the identifier of the item that you are predicting, and the second column is the class you are predicting for that item. The first line should include a header, and is should use the names provided in the training set. An example is below:\n",
    "```\n",
    "ID,class\n",
    "911366,B\n",
    "852781,B\n",
    "89524,B\n",
    "857438,B\n",
    "905686,B\n",
    "```\n",
    "* There is a limit of 7 submissions per day; finally, you also need to select your top 7 submissions to be counted in the competition\n",
    "* Before you submit, you should evaluate the classifiers \"locally\" on your training set, i.e. by splitting that again in a training & test set (or using cross validation), to select a number of fitting algorithms & parameters. Then re-train your best models on the full local training set, and generate the predictions for the test set.\n",
    "* Evaluation in Kaggle is split in two types of leaderboards - the private and public one. Here, the data is split into 50% / 50%, and as soon as you upload, you will know your results on one of these splits.\n",
    "* The final results will only be visible once the competition closes, and as it is computed on a different split, might be slightly different than what you see initially (e.g. this is similar to a training/test/validation split)\n",
    "* As it is a competition, there will be bonus points for the top 3 submissions.\n",
    "* As reproducible science is great, there will be additional bonus points for submissions that use a notebook within the Kaggle competition (note: this was / partially still is called a \"kernel\" inside the Kaggle competition; Kernel obviously was a confusing term here, as it basically refers to code being executed in the environment of Kaggle itself (e.g. a jupyter notebook, or also a python or R script), and they seem to have realized that, and renamed it). see https://www.kaggle.com/notebooks or https://www.kaggle.com/getting-started/44939. You can first work locally, and then port your code to the notebook version. In Kaggle, your notebook will initially be private. Please share it with me (mayer@ifs.tuwien.ac.at), at least, though. You can also make it public at the end of the competition, to show off :-)\n",
    "\n",
    "## Datasets\n",
    "We will use the following datasets:\n",
    "* Congressional Voting: a small dataset, a good entry point for your experiments (435 instances, 16 features)\n",
    "  * Kaggle page: https://www.kaggle.com/t/c04c953c596e48099d857129f53fcbdb\n",
    "* Amazon reviews: a dataset with many features (10k, extracted from text), but not that many instances (~800)\n",
    "  * Kaggle page: https://www.kaggle.com/t/0bd2ac297dc242478b5979d5ee772136\n",
    "\n",
    "## Submission\n",
    "The Kaggle competition will close on the day displayed in Kaggle. After that, you still have time to submit to Moodle. Your submission to Moodle shall contain:\n",
    "\n",
    "* A brief report, containing\n",
    "  * A description of the datasets, including a short analysis of the features.\n",
    "  * Details on the software you used for creating your solution\n",
    "  * The algorithms and parameters you tried\n",
    "  * The results you obtained on the locally split training/test set\n",
    "    * And a comparison to the results that you received on Kaggle - how large was the difference, did the rank of the classifiers change (i.e. the first on your training set, was it still the best on the test set on Kaggle?)\n",
    "* All the code needed to obtain your results\n",
    "* The solution files that you uploaded to Kaggle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Solution\n",
    "\n",
    "## Helper Functions for Solution and Data Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# global Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#sk learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#Data reporting\n",
    "from IPython.display import display\n",
    "\n",
    "# Global definitions:\n",
    "overall_results_vote = []\n",
    "overall_results_amazon = []\n",
    "averaging_approach = 'macro'\n",
    "zero_division_approach = 0\n",
    "number_of_folds = 5\n",
    "scoring = {'Accuracy': make_scorer(accuracy_score),\n",
    "            'Precision': make_scorer(precision_score, average=averaging_approach, zero_division=zero_division_approach),\n",
    "            'Recall': make_scorer(recall_score, average=averaging_approach, zero_division=zero_division_approach)}\n",
    "\n",
    "# Helper functions\n",
    "def parse_k_fold_results(results):\n",
    "    return \"m: \" + str(np.average(results)) + \" std: \" + str(np.std(results))\n",
    "\n",
    "def parse_argument_tuple_as_string(argumentsTuple):\n",
    "    return \"max Depth: \" + str(argumentsTuple[0])  + \\\n",
    "           \", min Samples: \" + str(argumentsTuple[1])\n",
    "\n",
    "def calculate_results_holdout(classifier_used, X_train, X_test, y_train, y_test):\n",
    "    classifier_used.fit(X_train, y_train)\n",
    "\n",
    "    # predict the test set on our trained classifier\n",
    "    y_test_predicted = classifier_used.predict(X_test)\n",
    "\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    recall=metrics.recall_score(y_test, y_test_predicted)\n",
    "    precision = metrics.precision_score(y_test, y_test_predicted)\n",
    "\n",
    "    return pd.Series({\n",
    "            'classifier': str(classifier_used),\n",
    "            'arguments': \"\",\n",
    "            'accuracy':acc,\n",
    "            'precision':precision,\n",
    "            'recall':recall\n",
    "        })\n",
    "\n",
    "def calculate_results_cross_validate(classifier_used, description_used, data, target):\n",
    "   scores = cross_validate(classifier_used, data, target,\n",
    "                                scoring = scoring,\n",
    "                                cv = number_of_folds,\n",
    "                                error_score = 0)\n",
    "\n",
    "   return pd.Series({\n",
    "            'classifier': str(classifier_used),\n",
    "            'arguments': description_used,\n",
    "            'mean_accuracy': np.average(scores.get('test_Accuracy')),\n",
    "            'mean_precision': np.average(scores.get('test_Precision')),\n",
    "            'mean_recall': np.average(scores.get('test_Recall')),\n",
    "            'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "            'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "            'recall':parse_k_fold_results(scores.get('test_Recall'))\n",
    "        })\n",
    "\n",
    "def print_results(array, column_for_max, ascending=False):\n",
    "    df = pd.DataFrame(array)\n",
    "    df = df.sort_values(by=[column_for_max], ascending=False)\n",
    "    display('Results', df)\n",
    "\n",
    "    best = df.iloc[df[column_for_max].argmax()]\n",
    "    display(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculation Functions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### k-NN Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "def calculate_knn(data, target):\n",
    "    knn_results = []\n",
    "\n",
    "    n_neighbors = range(1,10,1)\n",
    "\n",
    "    for n in n_neighbors:\n",
    "        knn_classifier = neighbors.KNeighborsClassifier(n)\n",
    "        description = \"N = \" + str(n)\n",
    "        result = calculate_results_cross_validate(knn_classifier,\n",
    "                                                  description,\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        knn_results.append(result)\n",
    "    return knn_results\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bayes Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "def calculate_bayes(data, target):\n",
    "    bayes_results = []\n",
    "\n",
    "    alphas = np.arange(0.1,5,1)\n",
    "\n",
    "    for alpha in alphas:\n",
    "        classifier = naive_bayes.CategoricalNB(alpha = alpha)\n",
    "        description = \"Alpha = \" + str(alpha)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  description,\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        bayes_results.append(result)\n",
    "\n",
    "    return bayes_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Perceptron Calculation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def calculate_perceptron(data, target):\n",
    "    perceptron_results=[]\n",
    "    classifier = linear_model.Perceptron()\n",
    "    description = \"No additional args.\"\n",
    "    result = calculate_results_cross_validate(classifier,\n",
    "                                              description,\n",
    "                                              data,\n",
    "                                              target)\n",
    "    perceptron_results.append(result)\n",
    "    return perceptron_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Decision Tree Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import itertools\n",
    "\n",
    "def calculate_decision_tree(data, target):\n",
    "    # Parameters for the decision tree\n",
    "    max_depth_arguments = range(1, 10, 2)\n",
    "    min_samples_leaf_arguments = [2,20,50,100]\n",
    "    argumentTuples = list(itertools.product(max_depth_arguments,\n",
    "                                            min_samples_leaf_arguments))\n",
    "    decision_tree_results = []\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        max_depth = argumentTuple[0]\n",
    "        min_samples_leaf = argumentTuple[1]\n",
    "\n",
    "        classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                 max_depth = max_depth,\n",
    "                                                 min_samples_leaf = min_samples_leaf,\n",
    "                                                 splitter = 'best')\n",
    "        #result = calculate_results_holdout(classifier, X_train, X_test, y_train, y_test)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  parse_argument_tuple_as_string(argumentTuple),\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        decision_tree_results.append(result)\n",
    "    return decision_tree_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import itertools\n",
    "\n",
    "def calculate_svm(data, target):\n",
    "    kernels = [\"poly\", \"rbf\"]#{\"linear\", \"poly\", \"sigmoid\", \"rbf\"}\n",
    "    gamma = [0.001, \"scale\", \"auto\"]\n",
    "    c = [100]\n",
    "    degree = range(1, 10, 1)\n",
    "\n",
    "    argumentTuples = list(itertools.product(kernels,\n",
    "                                            gamma,\n",
    "                                            c,\n",
    "                                            degree))\n",
    "    svm_results = []\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        kernel = argumentTuple[0]\n",
    "        gamma = argumentTuple[1]\n",
    "        c = argumentTuple[2]\n",
    "        degree = argumentTuple[3]\n",
    "\n",
    "        classifier = svm.SVC(kernel = kernel, gamma = gamma, C = c, degree = degree)\n",
    "\n",
    "        #result = calculate_results_holdout(classifier, X_train, X_test, y_train, y_test)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  \"Kernel: \" + kernel + \", Degree: \" + str(degree),\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        svm_results.append(result)\n",
    "    return svm_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congressional Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Original Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID       class handicapped-infants water-project-cost-sharing  \\\n0    213    democrat                   n                          n   \n1     94    democrat                   y                          n   \n2    188    democrat                   y                          n   \n3     61    democrat                   y                          y   \n4    184    democrat                 NaN                        NaN   \n..   ...         ...                 ...                        ...   \n213  250    democrat                   y                          n   \n214   26    democrat                   y                          n   \n215  110    democrat                   y                        NaN   \n216   34  republican                   n                          y   \n217  314  republican                   n                          y   \n\n    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n0                                   y                    n               n   \n1                                   y                    n               n   \n2                                   y                    n               n   \n3                                   y                    n               n   \n4                                 NaN                  NaN             NaN   \n..                                ...                  ...             ...   \n213                                 y                    n               n   \n214                                 y                    n               n   \n215                                 y                    n               n   \n216                                 n                    y               y   \n217                                 y                    y               y   \n\n    religious-groups-in-schools anti-satellite-test-ban  \\\n0                             n                       y   \n1                             n                       y   \n2                             n                       y   \n3                           NaN                       y   \n4                           NaN                     NaN   \n..                          ...                     ...   \n213                           n                       y   \n214                           n                       y   \n215                           n                       y   \n216                           y                       n   \n217                           y                       n   \n\n    aid-to-nicaraguan-contras mx-missile immigration  \\\n0                           y          y           n   \n1                           n          y           y   \n2                           y          y           n   \n3                           y          y           y   \n4                         NaN          y         NaN   \n..                        ...        ...         ...   \n213                         y        NaN           n   \n214                         y          y           y   \n215                         y          y           n   \n216                         n          n           n   \n217                         n          n           y   \n\n    synfuels-crporation-cutback education-spending superfund-right-to-sue  \\\n0                             y                  n                      n   \n1                             y                  n                      n   \n2                             n                  n                      n   \n3                             n                  n                      n   \n4                           NaN                NaN                    NaN   \n..                          ...                ...                    ...   \n213                           y                  n                      n   \n214                           n                  n                      n   \n215                           n                  n                      n   \n216                           n                  y                      y   \n217                           n                  y                      y   \n\n    crime duty-free-exports export-administration-act-south-africa  \n0       n                 y                                      y  \n1       n                 y                                      y  \n2       n                 y                                    NaN  \n3       n                 y                                    NaN  \n4     NaN               NaN                                    NaN  \n..    ...               ...                                    ...  \n213     n                 y                                      y  \n214     n                 y                                      y  \n215     n                 y                                    NaN  \n216     y                 n                                      y  \n217     y                 n                                      y  \n\n[218 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>213</td>\n      <td>democrat</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>94</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>188</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>184</td>\n      <td>democrat</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>250</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>26</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>110</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>34</td>\n      <td>republican</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>314</td>\n      <td>republican</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n    </tr>\n  </tbody>\n</table>\n<p>218 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\sklearn\\impute\\_iterative.py:670: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Recoded Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID class handicapped-infants water-project-cost-sharing  \\\n0    213     2                   0                          0   \n1     94     2                   1                          0   \n2    188     2                   1                          0   \n3     61     2                   1                          1   \n4    184     2                   1                          0   \n..   ...   ...                 ...                        ...   \n213  250     2                   1                          0   \n214   26     2                   1                          0   \n215  110     2                   1                          0   \n216   34     3                   0                          1   \n217  314     3                   0                          1   \n\n    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n0                                   1                    0               0   \n1                                   1                    0               0   \n2                                   1                    0               0   \n3                                   1                    0               0   \n4                                   1                    0               0   \n..                                ...                  ...             ...   \n213                                 1                    0               0   \n214                                 1                    0               0   \n215                                 1                    0               0   \n216                                 0                    1               1   \n217                                 1                    1               1   \n\n    religious-groups-in-schools anti-satellite-test-ban  \\\n0                             0                       1   \n1                             0                       1   \n2                             0                       1   \n3                             0                       1   \n4                             0                       1   \n..                          ...                     ...   \n213                           0                       1   \n214                           0                       1   \n215                           0                       1   \n216                           1                       0   \n217                           1                       0   \n\n    aid-to-nicaraguan-contras mx-missile immigration  \\\n0                           1          1           0   \n1                           0          1           1   \n2                           1          1           0   \n3                           1          1           1   \n4                           1          1           1   \n..                        ...        ...         ...   \n213                         1          1           0   \n214                         1          1           1   \n215                         1          1           0   \n216                         0          0           0   \n217                         0          0           1   \n\n    synfuels-crporation-cutback education-spending superfund-right-to-sue  \\\n0                             1                  0                      0   \n1                             1                  0                      0   \n2                             0                  0                      0   \n3                             0                  0                      0   \n4                             0                  0                      0   \n..                          ...                ...                    ...   \n213                           1                  0                      0   \n214                           0                  0                      0   \n215                           0                  0                      0   \n216                           0                  1                      1   \n217                           0                  1                      1   \n\n    crime duty-free-exports export-administration-act-south-africa  \n0       0                 1                                      1  \n1       0                 1                                      1  \n2       0                 1                                      1  \n3       0                 1                                      1  \n4       0                 1                                      1  \n..    ...               ...                                    ...  \n213     0                 1                                      1  \n214     0                 1                                      1  \n215     0                 1                                      1  \n216     1                 0                                      1  \n217     1                 0                                      1  \n\n[218 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>213</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>94</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>188</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>184</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>250</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>26</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>110</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>34</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>314</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>218 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Data: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "    handicapped-infants water-project-cost-sharing  \\\n0                     0                          0   \n1                     1                          0   \n2                     1                          0   \n3                     1                          1   \n4                     1                          0   \n..                  ...                        ...   \n213                   1                          0   \n214                   1                          0   \n215                   1                          0   \n216                   0                          1   \n217                   0                          1   \n\n    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n0                                   1                    0               0   \n1                                   1                    0               0   \n2                                   1                    0               0   \n3                                   1                    0               0   \n4                                   1                    0               0   \n..                                ...                  ...             ...   \n213                                 1                    0               0   \n214                                 1                    0               0   \n215                                 1                    0               0   \n216                                 0                    1               1   \n217                                 1                    1               1   \n\n    religious-groups-in-schools anti-satellite-test-ban  \\\n0                             0                       1   \n1                             0                       1   \n2                             0                       1   \n3                             0                       1   \n4                             0                       1   \n..                          ...                     ...   \n213                           0                       1   \n214                           0                       1   \n215                           0                       1   \n216                           1                       0   \n217                           1                       0   \n\n    aid-to-nicaraguan-contras mx-missile immigration  \\\n0                           1          1           0   \n1                           0          1           1   \n2                           1          1           0   \n3                           1          1           1   \n4                           1          1           1   \n..                        ...        ...         ...   \n213                         1          1           0   \n214                         1          1           1   \n215                         1          1           0   \n216                         0          0           0   \n217                         0          0           1   \n\n    synfuels-crporation-cutback education-spending superfund-right-to-sue  \\\n0                             1                  0                      0   \n1                             1                  0                      0   \n2                             0                  0                      0   \n3                             0                  0                      0   \n4                             0                  0                      0   \n..                          ...                ...                    ...   \n213                           1                  0                      0   \n214                           0                  0                      0   \n215                           0                  0                      0   \n216                           0                  1                      1   \n217                           0                  1                      1   \n\n    crime duty-free-exports export-administration-act-south-africa  \n0       0                 1                                      1  \n1       0                 1                                      1  \n2       0                 1                                      1  \n3       0                 1                                      1  \n4       0                 1                                      1  \n..    ...               ...                                    ...  \n213     0                 1                                      1  \n214     0                 1                                      1  \n215     0                 1                                      1  \n216     1                 0                                      1  \n217     1                 0                                      1  \n\n[218 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>218 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Target: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0      2\n1      2\n2      2\n3      2\n4      2\n      ..\n213    2\n214    2\n215    2\n216    3\n217    3\nName: class, Length: 218, dtype: category\nCategories (2, int64): [2, 3]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Recode values for predicting variables\n",
    "def recode_voting_data(dataset):\n",
    "    dataset = dataset.replace('y', 1)\\\n",
    "        .replace('n', 0)\\\n",
    "        .replace('democrat', 2)\\\n",
    "        .replace('republican', 3)\n",
    "    dataset.loc[:, dataset.columns != \"ID\"] = dataset.loc[:, dataset.columns != \"ID\"].astype('category')\n",
    "    return pd.DataFrame(dataset, columns=dataset.columns)\n",
    "\n",
    "#Imput missing values\n",
    "def input_missing_values(data):\n",
    "    columns = data.columns\n",
    "    imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "    imp.fit(data.loc[:, data.columns != \"ID\"])\n",
    "    data.loc[:, data.columns != \"ID\"] = np.round(imp.transform(data.loc[:, data.columns != \"ID\"]))\n",
    "    data.loc[:, data.columns != \"ID\"] = data.loc[:, data.columns != \"ID\"].apply(lambda x: x.astype('int'))\n",
    "    data.loc[:, data.columns != \"ID\"] = data.loc[:, data.columns != \"ID\"].astype('category')\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "#Read Data\n",
    "votingDataLearn = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.lrn.csv\", na_values='unknown')\n",
    "votingDataSolutionExample = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.sol.ex.csv\", na_values='unknown')\n",
    "votingDataTest = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.tes.csv\", na_values='unknown')\n",
    "display(\"Original Data\", votingDataLearn)\n",
    "\n",
    "#Recode values\n",
    "votingDataLearn = recode_voting_data(votingDataLearn)\n",
    "votingDataLearn = input_missing_values(votingDataLearn)\n",
    "\n",
    "display(\"Recoded Data\", votingDataLearn)\n",
    "\n",
    "display(\"Data: \", votingDataLearn[votingDataLearn.columns[2:18]])\n",
    "display(\"Target: \", votingDataLearn[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### k-NN - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                            classifier arguments  mean_accuracy  \\\n6  KNeighborsClassifier(n_neighbors=7)     N = 7       0.949789   \n7  KNeighborsClassifier(n_neighbors=8)     N = 8       0.949683   \n8  KNeighborsClassifier(n_neighbors=9)     N = 9       0.945243   \n0  KNeighborsClassifier(n_neighbors=1)     N = 1       0.945032   \n2  KNeighborsClassifier(n_neighbors=3)     N = 3       0.945032   \n4               KNeighborsClassifier()     N = 5       0.945032   \n1  KNeighborsClassifier(n_neighbors=2)     N = 2       0.944926   \n3  KNeighborsClassifier(n_neighbors=4)     N = 4       0.940381   \n5  KNeighborsClassifier(n_neighbors=6)     N = 6       0.935835   \n\n   mean_precision  mean_recall  \\\n6        0.946634     0.956796   \n7        0.946080     0.956796   \n8        0.942160     0.953092   \n0        0.942523     0.946331   \n2        0.941734     0.950913   \n4        0.941734     0.950913   \n1        0.945693     0.941606   \n3        0.937812     0.942485   \n5        0.934132     0.938781   \n\n                                          accuracy  \\\n6   m: 0.9497885835095138 std: 0.03633965972902396   \n7   m: 0.9496828752642706 std: 0.03925378581485785   \n8   m: 0.9452431289640592 std: 0.03687778755803422   \n0   m: 0.945031712473573 std: 0.034048886698533634   \n2   m: 0.945031712473573 std: 0.042524418215617005   \n4   m: 0.945031712473573 std: 0.042524418215617005   \n1   m: 0.9449260042283297 std: 0.03699848987727991   \n3  m: 0.9403805496828752 std: 0.027634973997320893   \n5  m: 0.9358350951374208 std: 0.033627186829120255   \n\n                                         precision  \\\n6   m: 0.9466340390488999 std: 0.03608620915053702   \n7   m: 0.9460797448165869 std: 0.03905530325409666   \n8  m: 0.9421603548383735 std: 0.037090417983209244   \n0   m: 0.9425226260094682 std: 0.03634869147380645   \n2   m: 0.9417338423530375 std: 0.04229555526924847   \n4   m: 0.9417338423530375 std: 0.04229555526924847   \n1   m: 0.9456933175569079 std: 0.04001026811690184   \n3   m: 0.937811566371938 std: 0.030278525504452966   \n5  m: 0.9341319126922842 std: 0.034844958450856264   \n\n                                            recall  \n6  m: 0.9567957097368863 std: 0.029626605680041794  \n7  m: 0.9567957097368863 std: 0.033352054331873056  \n8   m: 0.9530920060331824 std: 0.02978123723739161  \n0  m: 0.9463308614043908 std: 0.031909717382637634  \n2  m: 0.9509133567957099 std: 0.039255464764560155  \n4  m: 0.9509133567957099 std: 0.039255464764560155  \n1   m: 0.9416059158706218 std: 0.03451379175922509  \n3    m: 0.942484707558237 std: 0.02472620156914983  \n5  m: 0.9387810038545334 std: 0.028087583916356424  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>KNeighborsClassifier(n_neighbors=7)</td>\n      <td>N = 7</td>\n      <td>0.949789</td>\n      <td>0.946634</td>\n      <td>0.956796</td>\n      <td>m: 0.9497885835095138 std: 0.03633965972902396</td>\n      <td>m: 0.9466340390488999 std: 0.03608620915053702</td>\n      <td>m: 0.9567957097368863 std: 0.029626605680041794</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>KNeighborsClassifier(n_neighbors=8)</td>\n      <td>N = 8</td>\n      <td>0.949683</td>\n      <td>0.946080</td>\n      <td>0.956796</td>\n      <td>m: 0.9496828752642706 std: 0.03925378581485785</td>\n      <td>m: 0.9460797448165869 std: 0.03905530325409666</td>\n      <td>m: 0.9567957097368863 std: 0.033352054331873056</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>KNeighborsClassifier(n_neighbors=9)</td>\n      <td>N = 9</td>\n      <td>0.945243</td>\n      <td>0.942160</td>\n      <td>0.953092</td>\n      <td>m: 0.9452431289640592 std: 0.03687778755803422</td>\n      <td>m: 0.9421603548383735 std: 0.037090417983209244</td>\n      <td>m: 0.9530920060331824 std: 0.02978123723739161</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>KNeighborsClassifier(n_neighbors=1)</td>\n      <td>N = 1</td>\n      <td>0.945032</td>\n      <td>0.942523</td>\n      <td>0.946331</td>\n      <td>m: 0.945031712473573 std: 0.034048886698533634</td>\n      <td>m: 0.9425226260094682 std: 0.03634869147380645</td>\n      <td>m: 0.9463308614043908 std: 0.031909717382637634</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KNeighborsClassifier(n_neighbors=3)</td>\n      <td>N = 3</td>\n      <td>0.945032</td>\n      <td>0.941734</td>\n      <td>0.950913</td>\n      <td>m: 0.945031712473573 std: 0.042524418215617005</td>\n      <td>m: 0.9417338423530375 std: 0.04229555526924847</td>\n      <td>m: 0.9509133567957099 std: 0.039255464764560155</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNeighborsClassifier()</td>\n      <td>N = 5</td>\n      <td>0.945032</td>\n      <td>0.941734</td>\n      <td>0.950913</td>\n      <td>m: 0.945031712473573 std: 0.042524418215617005</td>\n      <td>m: 0.9417338423530375 std: 0.04229555526924847</td>\n      <td>m: 0.9509133567957099 std: 0.039255464764560155</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KNeighborsClassifier(n_neighbors=2)</td>\n      <td>N = 2</td>\n      <td>0.944926</td>\n      <td>0.945693</td>\n      <td>0.941606</td>\n      <td>m: 0.9449260042283297 std: 0.03699848987727991</td>\n      <td>m: 0.9456933175569079 std: 0.04001026811690184</td>\n      <td>m: 0.9416059158706218 std: 0.03451379175922509</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KNeighborsClassifier(n_neighbors=4)</td>\n      <td>N = 4</td>\n      <td>0.940381</td>\n      <td>0.937812</td>\n      <td>0.942485</td>\n      <td>m: 0.9403805496828752 std: 0.027634973997320893</td>\n      <td>m: 0.937811566371938 std: 0.030278525504452966</td>\n      <td>m: 0.942484707558237 std: 0.02472620156914983</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNeighborsClassifier(n_neighbors=6)</td>\n      <td>N = 6</td>\n      <td>0.935835</td>\n      <td>0.934132</td>\n      <td>0.938781</td>\n      <td>m: 0.9358350951374208 std: 0.033627186829120255</td>\n      <td>m: 0.9341319126922842 std: 0.034844958450856264</td>\n      <td>m: 0.9387810038545334 std: 0.028087583916356424</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                    KNeighborsClassifier(n_neighbors=7)\narguments                                                   N = 7\nmean_accuracy                                            0.949789\nmean_precision                                           0.946634\nmean_recall                                              0.956796\naccuracy           m: 0.9497885835095138 std: 0.03633965972902396\nprecision          m: 0.9466340390488999 std: 0.03608620915053702\nrecall            m: 0.9567957097368863 std: 0.029626605680041794\nName: 6, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_results_vote = calculate_knn(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                 votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(knn_results_vote)\n",
    "\n",
    "print_results(knn_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bayes - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                 classifier    arguments  mean_accuracy  mean_precision  \\\n3  CategoricalNB(alpha=3.1)  Alpha = 3.1       0.922304        0.918578   \n4  CategoricalNB(alpha=4.1)  Alpha = 4.1       0.922304        0.918578   \n2  CategoricalNB(alpha=2.1)  Alpha = 2.1       0.917759        0.914147   \n0  CategoricalNB(alpha=0.1)  Alpha = 0.1       0.917653        0.916001   \n1  CategoricalNB(alpha=1.1)  Alpha = 1.1       0.908562        0.905936   \n\n   mean_recall                                         accuracy  \\\n3     0.929706   m: 0.9223044397463003 std: 0.04195165926635185   \n4     0.929706   m: 0.9223044397463003 std: 0.04195165926635185   \n2     0.923824   m: 0.9177589852008456 std: 0.03936351367397849   \n0     0.919099  m: 0.9176532769556026 std: 0.036606812641491196   \n1     0.911691   m: 0.9085623678646935 std: 0.03759113618117659   \n\n                                         precision  \\\n3   m: 0.9185782390759508 std: 0.04469462645086833   \n4   m: 0.9185782390759508 std: 0.04469462645086833   \n2   m: 0.9141472899081595 std: 0.04267326106536261   \n0  m: 0.9160010673755272 std: 0.041199924531873135   \n1   m: 0.9059362018431694 std: 0.04263650611873664   \n\n                                           recall  \n3  m: 0.9297060918384448 std: 0.03623512490395484  \n4  m: 0.9297060918384448 std: 0.03623512490395484  \n2  m: 0.9238237388972683 std: 0.03255971857919237  \n0  m: 0.9190987933634993 std: 0.03090170389606902  \n1  m: 0.9116913859560919 std: 0.03226414499176202  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>CategoricalNB(alpha=3.1)</td>\n      <td>Alpha = 3.1</td>\n      <td>0.922304</td>\n      <td>0.918578</td>\n      <td>0.929706</td>\n      <td>m: 0.9223044397463003 std: 0.04195165926635185</td>\n      <td>m: 0.9185782390759508 std: 0.04469462645086833</td>\n      <td>m: 0.9297060918384448 std: 0.03623512490395484</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CategoricalNB(alpha=4.1)</td>\n      <td>Alpha = 4.1</td>\n      <td>0.922304</td>\n      <td>0.918578</td>\n      <td>0.929706</td>\n      <td>m: 0.9223044397463003 std: 0.04195165926635185</td>\n      <td>m: 0.9185782390759508 std: 0.04469462645086833</td>\n      <td>m: 0.9297060918384448 std: 0.03623512490395484</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CategoricalNB(alpha=2.1)</td>\n      <td>Alpha = 2.1</td>\n      <td>0.917759</td>\n      <td>0.914147</td>\n      <td>0.923824</td>\n      <td>m: 0.9177589852008456 std: 0.03936351367397849</td>\n      <td>m: 0.9141472899081595 std: 0.04267326106536261</td>\n      <td>m: 0.9238237388972683 std: 0.03255971857919237</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>CategoricalNB(alpha=0.1)</td>\n      <td>Alpha = 0.1</td>\n      <td>0.917653</td>\n      <td>0.916001</td>\n      <td>0.919099</td>\n      <td>m: 0.9176532769556026 std: 0.036606812641491196</td>\n      <td>m: 0.9160010673755272 std: 0.041199924531873135</td>\n      <td>m: 0.9190987933634993 std: 0.03090170389606902</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CategoricalNB(alpha=1.1)</td>\n      <td>Alpha = 1.1</td>\n      <td>0.908562</td>\n      <td>0.905936</td>\n      <td>0.911691</td>\n      <td>m: 0.9085623678646935 std: 0.03759113618117659</td>\n      <td>m: 0.9059362018431694 std: 0.04263650611873664</td>\n      <td>m: 0.9116913859560919 std: 0.03226414499176202</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                              CategoricalNB(alpha=3.1)\narguments                                            Alpha = 3.1\nmean_accuracy                                           0.922304\nmean_precision                                          0.918578\nmean_recall                                             0.929706\naccuracy          m: 0.9223044397463003 std: 0.04195165926635185\nprecision         m: 0.9185782390759508 std: 0.04469462645086833\nrecall            m: 0.9297060918384448 std: 0.03623512490395484\nName: 3, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bayes_results_vote = calculate_bayes(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                     votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(bayes_results_vote)\n",
    "\n",
    "print_results(bayes_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     classifier            arguments  mean_accuracy  mean_precision  \\\n0  Perceptron()  No additional args.       0.944715        0.948016   \n\n   mean_recall                                        accuracy  \\\n0     0.941238  m: 0.9447145877378436 std: 0.03746846609226435   \n\n                                        precision  \\\n0  m: 0.948015873015873 std: 0.035728392275797285   \n\n                                           recall  \n0  m: 0.9412382688117983 std: 0.04219766815473462  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Perceptron()</td>\n      <td>No additional args.</td>\n      <td>0.944715</td>\n      <td>0.948016</td>\n      <td>0.941238</td>\n      <td>m: 0.9447145877378436 std: 0.03746846609226435</td>\n      <td>m: 0.948015873015873 std: 0.035728392275797285</td>\n      <td>m: 0.9412382688117983 std: 0.04219766815473462</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                                          Perceptron()\narguments                                    No additional args.\nmean_accuracy                                           0.944715\nmean_precision                                          0.948016\nmean_recall                                             0.941238\naccuracy          m: 0.9447145877378436 std: 0.03746846609226435\nprecision         m: 0.948015873015873 std: 0.035728392275797285\nrecall            m: 0.9412382688117983 std: 0.04219766815473462\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perceptron_results_vote = calculate_perceptron(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                               votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(perceptron_results_vote)\n",
    "\n",
    "print_results(perceptron_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n0   DecisionTreeClassifier(max_depth=1, min_sample...   \n9   DecisionTreeClassifier(max_depth=5, min_sample...   \n18  DecisionTreeClassifier(max_depth=9, min_sample...   \n17  DecisionTreeClassifier(max_depth=9, min_sample...   \n14  DecisionTreeClassifier(max_depth=7, min_sample...   \n13  DecisionTreeClassifier(max_depth=7, min_sample...   \n1   DecisionTreeClassifier(max_depth=1, min_sample...   \n10  DecisionTreeClassifier(max_depth=5, min_sample...   \n6   DecisionTreeClassifier(max_depth=3, min_sample...   \n5   DecisionTreeClassifier(max_depth=3, min_sample...   \n2   DecisionTreeClassifier(max_depth=1, min_sample...   \n16  DecisionTreeClassifier(max_depth=9, min_sample...   \n12  DecisionTreeClassifier(max_depth=7, min_sample...   \n8   DecisionTreeClassifier(max_depth=5, min_sample...   \n4   DecisionTreeClassifier(max_depth=3, min_sample...   \n7   DecisionTreeClassifier(max_depth=3, min_sample...   \n11  DecisionTreeClassifier(max_depth=5, min_sample...   \n15  DecisionTreeClassifier(max_depth=7, min_sample...   \n3   DecisionTreeClassifier(max_depth=1, min_sample...   \n19  DecisionTreeClassifier(max_depth=9, min_sample...   \n\n                         arguments  mean_accuracy  mean_precision  \\\n0     max Depth: 1, min Samples: 2       0.967970        0.963363   \n9    max Depth: 5, min Samples: 20       0.967970        0.963363   \n18   max Depth: 9, min Samples: 50       0.967970        0.963363   \n17   max Depth: 9, min Samples: 20       0.967970        0.963363   \n14   max Depth: 7, min Samples: 50       0.967970        0.963363   \n13   max Depth: 7, min Samples: 20       0.967970        0.963363   \n1    max Depth: 1, min Samples: 20       0.967970        0.963363   \n10   max Depth: 5, min Samples: 50       0.967970        0.963363   \n6    max Depth: 3, min Samples: 50       0.967970        0.963363   \n5    max Depth: 3, min Samples: 20       0.967970        0.963363   \n2    max Depth: 1, min Samples: 50       0.967970        0.963363   \n16    max Depth: 9, min Samples: 2       0.963108        0.962291   \n12    max Depth: 7, min Samples: 2       0.958562        0.958720   \n8     max Depth: 5, min Samples: 2       0.954017        0.952705   \n4     max Depth: 3, min Samples: 2       0.954017        0.951803   \n7   max Depth: 3, min Samples: 100       0.614693        0.307347   \n11  max Depth: 5, min Samples: 100       0.614693        0.307347   \n15  max Depth: 7, min Samples: 100       0.614693        0.307347   \n3   max Depth: 1, min Samples: 100       0.614693        0.307347   \n19  max Depth: 9, min Samples: 100       0.614693        0.307347   \n\n    mean_recall                                         accuracy  \\\n0      0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n9      0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n18     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n17     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n14     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n13     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n1      0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n10     0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n6      0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n5      0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n2      0.973789   m: 0.967970401691332 std: 0.023305252083176783   \n16     0.961371  m: 0.9631078224101479 std: 0.043123781971146476   \n12     0.955489   m: 0.9585623678646934 std: 0.04008642871295887   \n8      0.951785  m: 0.9540169133192389 std: 0.038980408138212665   \n4      0.953963   m: 0.9540169133192389 std: 0.04396243122391554   \n7      0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n11     0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n15     0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n3      0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n19     0.500000   m: 0.614693446088795 std: 0.007467223261077965   \n\n                                           precision  \\\n0    m: 0.9633625730994153 std: 0.025403888401415272   \n9    m: 0.9633625730994153 std: 0.025403888401415272   \n18   m: 0.9633625730994153 std: 0.025403888401415272   \n17   m: 0.9633625730994153 std: 0.025403888401415272   \n14   m: 0.9633625730994153 std: 0.025403888401415272   \n13   m: 0.9633625730994153 std: 0.025403888401415272   \n1    m: 0.9633625730994153 std: 0.025403888401415272   \n10   m: 0.9633625730994153 std: 0.025403888401415272   \n6    m: 0.9633625730994153 std: 0.025403888401415272   \n5    m: 0.9633625730994153 std: 0.025403888401415272   \n2    m: 0.9633625730994153 std: 0.025403888401415272   \n16    m: 0.9622911445279867 std: 0.04453377582464436   \n12   m: 0.9587197159565581 std: 0.042011053660979576   \n8     m: 0.9527050878831066 std: 0.04034685450017689   \n4     m: 0.9518028322440089 std: 0.04526497840274823   \n7   m: 0.3073467230443975 std: 0.0037336116305389825   \n11  m: 0.3073467230443975 std: 0.0037336116305389825   \n15  m: 0.3073467230443975 std: 0.0037336116305389825   \n3   m: 0.3073467230443975 std: 0.0037336116305389825   \n19  m: 0.3073467230443975 std: 0.0037336116305389825   \n\n                                            recall  \n0    m: 0.9737891737891738 std: 0.0190606594685786  \n9    m: 0.9737891737891738 std: 0.0190606594685786  \n18   m: 0.9737891737891738 std: 0.0190606594685786  \n17   m: 0.9737891737891738 std: 0.0190606594685786  \n14   m: 0.9737891737891738 std: 0.0190606594685786  \n13   m: 0.9737891737891738 std: 0.0190606594685786  \n1    m: 0.9737891737891738 std: 0.0190606594685786  \n10   m: 0.9737891737891738 std: 0.0190606594685786  \n6    m: 0.9737891737891738 std: 0.0190606594685786  \n5    m: 0.9737891737891738 std: 0.0190606594685786  \n2    m: 0.9737891737891738 std: 0.0190606594685786  \n16  m: 0.9613708731355789 std: 0.04653565125719753  \n12  m: 0.9554885201944024 std: 0.04300598593658525  \n8   m: 0.9517848164906988 std: 0.04233833687566992  \n4   m: 0.9539634657281717 std: 0.04655965367106959  \n7                                  m: 0.5 std: 0.0  \n11                                 m: 0.5 std: 0.0  \n15                                 m: 0.5 std: 0.0  \n3                                  m: 0.5 std: 0.0  \n19                                 m: 0.5 std: 0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 2</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 2</td>\n      <td>0.963108</td>\n      <td>0.962291</td>\n      <td>0.961371</td>\n      <td>m: 0.9631078224101479 std: 0.043123781971146476</td>\n      <td>m: 0.9622911445279867 std: 0.04453377582464436</td>\n      <td>m: 0.9613708731355789 std: 0.04653565125719753</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 2</td>\n      <td>0.958562</td>\n      <td>0.958720</td>\n      <td>0.955489</td>\n      <td>m: 0.9585623678646934 std: 0.04008642871295887</td>\n      <td>m: 0.9587197159565581 std: 0.042011053660979576</td>\n      <td>m: 0.9554885201944024 std: 0.04300598593658525</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 2</td>\n      <td>0.954017</td>\n      <td>0.952705</td>\n      <td>0.951785</td>\n      <td>m: 0.9540169133192389 std: 0.038980408138212665</td>\n      <td>m: 0.9527050878831066 std: 0.04034685450017689</td>\n      <td>m: 0.9517848164906988 std: 0.04233833687566992</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 2</td>\n      <td>0.954017</td>\n      <td>0.951803</td>\n      <td>0.953963</td>\n      <td>m: 0.9540169133192389 std: 0.04396243122391554</td>\n      <td>m: 0.9518028322440089 std: 0.04526497840274823</td>\n      <td>m: 0.9539634657281717 std: 0.04655965367106959</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        DecisionTreeClassifier(max_depth=1, min_sample...\narguments                              max Depth: 1, min Samples: 2\nmean_accuracy                                               0.96797\nmean_precision                                             0.963363\nmean_recall                                                0.973789\naccuracy             m: 0.967970401691332 std: 0.023305252083176783\nprecision           m: 0.9633625730994153 std: 0.025403888401415272\nrecall                m: 0.9737891737891738 std: 0.0190606594685786\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_results_vote = calculate_decision_tree(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                                     votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(decision_tree_results_vote)\n",
    "\n",
    "print_results(decision_tree_results_vote, \"mean_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n0    SVC(C=100, degree=1, gamma=0.001, kernel='poly')   \n28                  SVC(C=100, degree=2, gamma=0.001)   \n35                  SVC(C=100, degree=9, gamma=0.001)   \n34                  SVC(C=100, degree=8, gamma=0.001)   \n33                  SVC(C=100, degree=7, gamma=0.001)   \n32                  SVC(C=100, degree=6, gamma=0.001)   \n31                  SVC(C=100, degree=5, gamma=0.001)   \n30                  SVC(C=100, degree=4, gamma=0.001)   \n29                            SVC(C=100, gamma=0.001)   \n27                  SVC(C=100, degree=1, gamma=0.001)   \n22  SVC(C=100, degree=5, gamma='auto', kernel='poly')   \n37                               SVC(C=100, degree=2)   \n36                               SVC(C=100, degree=1)   \n38                                         SVC(C=100)   \n39                               SVC(C=100, degree=4)   \n11                          SVC(C=100, kernel='poly')   \n40                               SVC(C=100, degree=5)   \n41                               SVC(C=100, degree=6)   \n42                               SVC(C=100, degree=7)   \n43                               SVC(C=100, degree=8)   \n19  SVC(C=100, degree=2, gamma='auto', kernel='poly')   \n20            SVC(C=100, gamma='auto', kernel='poly')   \n44                               SVC(C=100, degree=9)   \n23  SVC(C=100, degree=6, gamma='auto', kernel='poly')   \n21  SVC(C=100, degree=4, gamma='auto', kernel='poly')   \n47                           SVC(C=100, gamma='auto')   \n46                 SVC(C=100, degree=2, gamma='auto')   \n45                 SVC(C=100, degree=1, gamma='auto')   \n18  SVC(C=100, degree=1, gamma='auto', kernel='poly')   \n48                 SVC(C=100, degree=4, gamma='auto')   \n49                 SVC(C=100, degree=5, gamma='auto')   \n50                 SVC(C=100, degree=6, gamma='auto')   \n51                 SVC(C=100, degree=7, gamma='auto')   \n52                 SVC(C=100, degree=8, gamma='auto')   \n12                SVC(C=100, degree=4, kernel='poly')   \n53                 SVC(C=100, degree=9, gamma='auto')   \n10                SVC(C=100, degree=2, kernel='poly')   \n15                SVC(C=100, degree=7, kernel='poly')   \n14                SVC(C=100, degree=6, kernel='poly')   \n13                SVC(C=100, degree=5, kernel='poly')   \n16                SVC(C=100, degree=8, kernel='poly')   \n24  SVC(C=100, degree=7, gamma='auto', kernel='poly')   \n17                SVC(C=100, degree=9, kernel='poly')   \n9                 SVC(C=100, degree=1, kernel='poly')   \n25  SVC(C=100, degree=8, gamma='auto', kernel='poly')   \n26  SVC(C=100, degree=9, gamma='auto', kernel='poly')   \n2              SVC(C=100, gamma=0.001, kernel='poly')   \n3    SVC(C=100, degree=4, gamma=0.001, kernel='poly')   \n1    SVC(C=100, degree=2, gamma=0.001, kernel='poly')   \n8    SVC(C=100, degree=9, gamma=0.001, kernel='poly')   \n7    SVC(C=100, degree=8, gamma=0.001, kernel='poly')   \n6    SVC(C=100, degree=7, gamma=0.001, kernel='poly')   \n4    SVC(C=100, degree=5, gamma=0.001, kernel='poly')   \n5    SVC(C=100, degree=6, gamma=0.001, kernel='poly')   \n\n                  arguments  mean_accuracy  mean_precision  mean_recall  \\\n0   Kernel: poly, Degree: 1       0.967970        0.963363     0.973789   \n28   Kernel: rbf, Degree: 2       0.967970        0.963363     0.973789   \n35   Kernel: rbf, Degree: 9       0.967970        0.963363     0.973789   \n34   Kernel: rbf, Degree: 8       0.967970        0.963363     0.973789   \n33   Kernel: rbf, Degree: 7       0.967970        0.963363     0.973789   \n32   Kernel: rbf, Degree: 6       0.967970        0.963363     0.973789   \n31   Kernel: rbf, Degree: 5       0.967970        0.963363     0.973789   \n30   Kernel: rbf, Degree: 4       0.967970        0.963363     0.973789   \n29   Kernel: rbf, Degree: 3       0.967970        0.963363     0.973789   \n27   Kernel: rbf, Degree: 1       0.967970        0.963363     0.973789   \n22  Kernel: poly, Degree: 5       0.958562        0.957817     0.957667   \n37   Kernel: rbf, Degree: 2       0.953805        0.954492     0.951050   \n36   Kernel: rbf, Degree: 1       0.953805        0.954492     0.951050   \n38   Kernel: rbf, Degree: 3       0.953805        0.954492     0.951050   \n39   Kernel: rbf, Degree: 4       0.953805        0.954492     0.951050   \n11  Kernel: poly, Degree: 3       0.953805        0.954492     0.951050   \n40   Kernel: rbf, Degree: 5       0.953805        0.954492     0.951050   \n41   Kernel: rbf, Degree: 6       0.953805        0.954492     0.951050   \n42   Kernel: rbf, Degree: 7       0.953805        0.954492     0.951050   \n43   Kernel: rbf, Degree: 8       0.953805        0.954492     0.951050   \n19  Kernel: poly, Degree: 2       0.953805        0.954492     0.951050   \n20  Kernel: poly, Degree: 3       0.953805        0.954492     0.951050   \n44   Kernel: rbf, Degree: 9       0.953805        0.954492     0.951050   \n23  Kernel: poly, Degree: 6       0.949366        0.950675     0.945535   \n21  Kernel: poly, Degree: 4       0.949366        0.950238     0.945902   \n47   Kernel: rbf, Degree: 3       0.949260        0.948937     0.947346   \n46   Kernel: rbf, Degree: 2       0.949260        0.948937     0.947346   \n45   Kernel: rbf, Degree: 1       0.949260        0.948937     0.947346   \n18  Kernel: poly, Degree: 1       0.949260        0.950921     0.945167   \n48   Kernel: rbf, Degree: 4       0.949260        0.948937     0.947346   \n49   Kernel: rbf, Degree: 5       0.949260        0.948937     0.947346   \n50   Kernel: rbf, Degree: 6       0.949260        0.948937     0.947346   \n51   Kernel: rbf, Degree: 7       0.949260        0.948937     0.947346   \n52   Kernel: rbf, Degree: 8       0.949260        0.948937     0.947346   \n12  Kernel: poly, Degree: 4       0.949260        0.950238     0.945535   \n53   Kernel: rbf, Degree: 9       0.949260        0.948937     0.947346   \n10  Kernel: poly, Degree: 2       0.949154        0.951389     0.944800   \n15  Kernel: poly, Degree: 7       0.944820        0.945885     0.939652   \n14  Kernel: poly, Degree: 6       0.944715        0.946131     0.939285   \n13  Kernel: poly, Degree: 5       0.944609        0.946913     0.939285   \n16  Kernel: poly, Degree: 8       0.940275        0.942560     0.933770   \n24  Kernel: poly, Degree: 7       0.940275        0.944024     0.933770   \n17  Kernel: poly, Degree: 9       0.935729        0.939235     0.927888   \n9   Kernel: poly, Degree: 1       0.935518        0.940445     0.929331   \n25  Kernel: poly, Degree: 8       0.931184        0.938646     0.921638   \n26  Kernel: poly, Degree: 9       0.866808        0.894655     0.834560   \n2   Kernel: poly, Degree: 3       0.614693        0.307347     0.500000   \n3   Kernel: poly, Degree: 4       0.614693        0.307347     0.500000   \n1   Kernel: poly, Degree: 2       0.614693        0.307347     0.500000   \n8   Kernel: poly, Degree: 9       0.614693        0.307347     0.500000   \n7   Kernel: poly, Degree: 8       0.614693        0.307347     0.500000   \n6   Kernel: poly, Degree: 7       0.614693        0.307347     0.500000   \n4   Kernel: poly, Degree: 5       0.614693        0.307347     0.500000   \n5   Kernel: poly, Degree: 6       0.614693        0.307347     0.500000   \n\n                                           accuracy  \\\n0    m: 0.967970401691332 std: 0.023305252083176783   \n28   m: 0.967970401691332 std: 0.023305252083176783   \n35   m: 0.967970401691332 std: 0.023305252083176783   \n34   m: 0.967970401691332 std: 0.023305252083176783   \n33   m: 0.967970401691332 std: 0.023305252083176783   \n32   m: 0.967970401691332 std: 0.023305252083176783   \n31   m: 0.967970401691332 std: 0.023305252083176783   \n30   m: 0.967970401691332 std: 0.023305252083176783   \n29   m: 0.967970401691332 std: 0.023305252083176783   \n27   m: 0.967970401691332 std: 0.023305252083176783   \n22   m: 0.9585623678646934 std: 0.04494602215385697   \n37   m: 0.9538054968287526 std: 0.04396192286723881   \n36   m: 0.9538054968287526 std: 0.04396192286723881   \n38   m: 0.9538054968287526 std: 0.04396192286723881   \n39   m: 0.9538054968287526 std: 0.04396192286723881   \n11   m: 0.9538054968287526 std: 0.04396192286723881   \n40   m: 0.9538054968287526 std: 0.04396192286723881   \n41   m: 0.9538054968287526 std: 0.04396192286723881   \n42   m: 0.9538054968287526 std: 0.04396192286723881   \n43   m: 0.9538054968287526 std: 0.04396192286723881   \n19   m: 0.9538054968287526 std: 0.04396192286723881   \n20   m: 0.9538054968287526 std: 0.04396192286723881   \n44   m: 0.9538054968287526 std: 0.04396192286723881   \n23   m: 0.9493657505285412 std: 0.03721380666567032   \n21  m: 0.9493657505285412 std: 0.049664204129618535   \n47   m: 0.9492600422832981 std: 0.03994177338895591   \n46   m: 0.9492600422832981 std: 0.03994177338895591   \n45   m: 0.9492600422832981 std: 0.03994177338895591   \n18   m: 0.9492600422832981 std: 0.03994177338895591   \n48   m: 0.9492600422832981 std: 0.03994177338895591   \n49   m: 0.9492600422832981 std: 0.03994177338895591   \n50   m: 0.9492600422832981 std: 0.03994177338895591   \n51   m: 0.9492600422832981 std: 0.03994177338895591   \n52   m: 0.9492600422832981 std: 0.03994177338895591   \n12  m: 0.9492600422832981 std: 0.049605220226076316   \n53   m: 0.9492600422832981 std: 0.03994177338895591   \n10   m: 0.9491543340380548 std: 0.04496814340117908   \n15   m: 0.9448202959830866 std: 0.04033652670423447   \n14   m: 0.9447145877378436 std: 0.04285501437893323   \n13   m: 0.9446088794926004 std: 0.04787008127514016   \n16  m: 0.9402748414376321 std: 0.037611938424222405   \n24  m: 0.9402748414376321 std: 0.031645454200115844   \n17  m: 0.9357293868921776 std: 0.034072835565065435   \n9     m: 0.9355179704016914 std: 0.0398226965851031   \n25   m: 0.931183932346723 std: 0.014728766467147719   \n26   m: 0.8668076109936574 std: 0.06132444988723495   \n2    m: 0.614693446088795 std: 0.007467223261077965   \n3    m: 0.614693446088795 std: 0.007467223261077965   \n1    m: 0.614693446088795 std: 0.007467223261077965   \n8    m: 0.614693446088795 std: 0.007467223261077965   \n7    m: 0.614693446088795 std: 0.007467223261077965   \n6    m: 0.614693446088795 std: 0.007467223261077965   \n4    m: 0.614693446088795 std: 0.007467223261077965   \n5    m: 0.614693446088795 std: 0.007467223261077965   \n\n                                           precision  \\\n0    m: 0.9633625730994153 std: 0.025403888401415272   \n28   m: 0.9633625730994153 std: 0.025403888401415272   \n35   m: 0.9633625730994153 std: 0.025403888401415272   \n34   m: 0.9633625730994153 std: 0.025403888401415272   \n33   m: 0.9633625730994153 std: 0.025403888401415272   \n32   m: 0.9633625730994153 std: 0.025403888401415272   \n31   m: 0.9633625730994153 std: 0.025403888401415272   \n30   m: 0.9633625730994153 std: 0.025403888401415272   \n29   m: 0.9633625730994153 std: 0.025403888401415272   \n27   m: 0.9633625730994153 std: 0.025403888401415272   \n22   m: 0.9578174603174604 std: 0.046870371191630435   \n37    m: 0.954492337164751 std: 0.045599206036925855   \n36    m: 0.954492337164751 std: 0.045599206036925855   \n38    m: 0.954492337164751 std: 0.045599206036925855   \n39    m: 0.954492337164751 std: 0.045599206036925855   \n11    m: 0.954492337164751 std: 0.045599206036925855   \n40    m: 0.954492337164751 std: 0.045599206036925855   \n41    m: 0.954492337164751 std: 0.045599206036925855   \n42    m: 0.954492337164751 std: 0.045599206036925855   \n43    m: 0.954492337164751 std: 0.045599206036925855   \n19    m: 0.954492337164751 std: 0.045599206036925855   \n20    m: 0.954492337164751 std: 0.045599206036925855   \n44    m: 0.954492337164751 std: 0.045599206036925855   \n23   m: 0.9506746031746032 std: 0.040874865114585435   \n21    m: 0.9502380952380953 std: 0.05089560699894818   \n47    m: 0.9489367816091955 std: 0.04119591828266531   \n46    m: 0.9489367816091955 std: 0.04119591828266531   \n45    m: 0.9489367816091955 std: 0.04119591828266531   \n18    m: 0.9509209085933226 std: 0.04248827208564486   \n48    m: 0.9489367816091955 std: 0.04119591828266531   \n49    m: 0.9489367816091955 std: 0.04119591828266531   \n50    m: 0.9489367816091955 std: 0.04119591828266531   \n51    m: 0.9489367816091955 std: 0.04119591828266531   \n52    m: 0.9489367816091955 std: 0.04119591828266531   \n12    m: 0.9502380952380953 std: 0.05089560699894818   \n53    m: 0.9489367816091955 std: 0.04119591828266531   \n10    m: 0.951388888888889 std: 0.045270108416585256   \n15    m: 0.9458851294903926 std: 0.04481569483269399   \n14   m: 0.9461314349091119 std: 0.046317432103559646   \n13    m: 0.946912972085386 std: 0.049218025790676634   \n16   m: 0.9425600063376832 std: 0.042562300923425285   \n24    m: 0.9440243568691844 std: 0.03631184355880235   \n17    m: 0.939234883184974 std: 0.039906635143718824   \n9    m: 0.9404447181171319 std: 0.042337481322026534   \n25   m: 0.9386464347012016 std: 0.022168198839040785   \n26   m: 0.8946552711993888 std: 0.058266182801191176   \n2   m: 0.3073467230443975 std: 0.0037336116305389825   \n3   m: 0.3073467230443975 std: 0.0037336116305389825   \n1   m: 0.3073467230443975 std: 0.0037336116305389825   \n8   m: 0.3073467230443975 std: 0.0037336116305389825   \n7   m: 0.3073467230443975 std: 0.0037336116305389825   \n6   m: 0.3073467230443975 std: 0.0037336116305389825   \n4   m: 0.3073467230443975 std: 0.0037336116305389825   \n5   m: 0.3073467230443975 std: 0.0037336116305389825   \n\n                                             recall  \n0     m: 0.9737891737891738 std: 0.0190606594685786  \n28    m: 0.9737891737891738 std: 0.0190606594685786  \n35    m: 0.9737891737891738 std: 0.0190606594685786  \n34    m: 0.9737891737891738 std: 0.0190606594685786  \n33    m: 0.9737891737891738 std: 0.0190606594685786  \n32    m: 0.9737891737891738 std: 0.0190606594685786  \n31    m: 0.9737891737891738 std: 0.0190606594685786  \n30    m: 0.9737891737891738 std: 0.0190606594685786  \n29    m: 0.9737891737891738 std: 0.0190606594685786  \n27    m: 0.9737891737891738 std: 0.0190606594685786  \n22   m: 0.9576671694318752 std: 0.04699620478772943  \n37   m: 0.951049522373052 std: 0.047040431203705595  \n36   m: 0.951049522373052 std: 0.047040431203705595  \n38   m: 0.951049522373052 std: 0.047040431203705595  \n39   m: 0.951049522373052 std: 0.047040431203705595  \n11   m: 0.951049522373052 std: 0.047040431203705595  \n40   m: 0.951049522373052 std: 0.047040431203705595  \n41   m: 0.951049522373052 std: 0.047040431203705595  \n42   m: 0.951049522373052 std: 0.047040431203705595  \n43   m: 0.951049522373052 std: 0.047040431203705595  \n19   m: 0.951049522373052 std: 0.047040431203705595  \n20   m: 0.951049522373052 std: 0.047040431203705595  \n44   m: 0.951049522373052 std: 0.047040431203705595  \n23   m: 0.9455348164906988 std: 0.03745101432913054  \n21   m: 0.9459024635495223 std: 0.05395127515744649  \n47  m: 0.9473458186693481 std: 0.043647173124497826  \n46  m: 0.9473458186693481 std: 0.043647173124497826  \n45  m: 0.9473458186693481 std: 0.043647173124497826  \n18   m: 0.9451671694318753 std: 0.04213457606582847  \n48  m: 0.9473458186693481 std: 0.043647173124497826  \n49  m: 0.9473458186693481 std: 0.043647173124497826  \n50  m: 0.9473458186693481 std: 0.043647173124497826  \n51  m: 0.9473458186693481 std: 0.043647173124497826  \n52  m: 0.9473458186693481 std: 0.043647173124497826  \n12   m: 0.9455348164906988 std: 0.05378781874923513  \n53  m: 0.9473458186693481 std: 0.043647173124497826  \n10  m: 0.9447995223730519 std: 0.050382747022107745  \n15   m: 0.9396524635495224 std: 0.03941845614944265  \n14   m: 0.9392848164906988 std: 0.04384328285674222  \n13  m: 0.9392848164906988 std: 0.052527989224167966  \n16   m: 0.9337701106083459 std: 0.03644547617860185  \n24   m: 0.9337701106083458 std: 0.03194837591942475  \n17  m: 0.9278877576671694 std: 0.032148508990548885  \n9    m: 0.9293311127869952 std: 0.04199492314164729  \n25   m: 0.9216377576671695 std: 0.01627748950611654  \n26   m: 0.8345598709569299 std: 0.07265018156242421  \n2                                   m: 0.5 std: 0.0  \n3                                   m: 0.5 std: 0.0  \n1                                   m: 0.5 std: 0.0  \n8                                   m: 0.5 std: 0.0  \n7                                   m: 0.5 std: 0.0  \n6                                   m: 0.5 std: 0.0  \n4                                   m: 0.5 std: 0.0  \n5                                   m: 0.5 std: 0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SVC(C=100, degree=1, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>SVC(C=100, degree=2, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 2</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>SVC(C=100, degree=9, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 9</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>SVC(C=100, degree=8, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 8</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>SVC(C=100, degree=7, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 7</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>SVC(C=100, degree=6, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 6</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>SVC(C=100, degree=5, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 5</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>SVC(C=100, degree=4, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 4</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>SVC(C=100, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 3</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>SVC(C=100, degree=1, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>SVC(C=100, degree=5, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 5</td>\n      <td>0.958562</td>\n      <td>0.957817</td>\n      <td>0.957667</td>\n      <td>m: 0.9585623678646934 std: 0.04494602215385697</td>\n      <td>m: 0.9578174603174604 std: 0.046870371191630435</td>\n      <td>m: 0.9576671694318752 std: 0.04699620478772943</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>SVC(C=100, degree=2)</td>\n      <td>Kernel: rbf, Degree: 2</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>SVC(C=100, degree=1)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>SVC(C=100)</td>\n      <td>Kernel: rbf, Degree: 3</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>SVC(C=100, degree=4)</td>\n      <td>Kernel: rbf, Degree: 4</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>SVC(C=100, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 3</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>SVC(C=100, degree=5)</td>\n      <td>Kernel: rbf, Degree: 5</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>SVC(C=100, degree=6)</td>\n      <td>Kernel: rbf, Degree: 6</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>SVC(C=100, degree=7)</td>\n      <td>Kernel: rbf, Degree: 7</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>SVC(C=100, degree=8)</td>\n      <td>Kernel: rbf, Degree: 8</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>SVC(C=100, degree=2, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 2</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>SVC(C=100, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 3</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>SVC(C=100, degree=9)</td>\n      <td>Kernel: rbf, Degree: 9</td>\n      <td>0.953805</td>\n      <td>0.954492</td>\n      <td>0.951050</td>\n      <td>m: 0.9538054968287526 std: 0.04396192286723881</td>\n      <td>m: 0.954492337164751 std: 0.045599206036925855</td>\n      <td>m: 0.951049522373052 std: 0.047040431203705595</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>SVC(C=100, degree=6, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 6</td>\n      <td>0.949366</td>\n      <td>0.950675</td>\n      <td>0.945535</td>\n      <td>m: 0.9493657505285412 std: 0.03721380666567032</td>\n      <td>m: 0.9506746031746032 std: 0.040874865114585435</td>\n      <td>m: 0.9455348164906988 std: 0.03745101432913054</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>SVC(C=100, degree=4, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 4</td>\n      <td>0.949366</td>\n      <td>0.950238</td>\n      <td>0.945902</td>\n      <td>m: 0.9493657505285412 std: 0.049664204129618535</td>\n      <td>m: 0.9502380952380953 std: 0.05089560699894818</td>\n      <td>m: 0.9459024635495223 std: 0.05395127515744649</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>SVC(C=100, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 3</td>\n      <td>0.949260</td>\n      <td>0.948937</td>\n      <td>0.947346</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9489367816091955 std: 0.04119591828266531</td>\n      <td>m: 0.9473458186693481 std: 0.043647173124497826</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>SVC(C=100, degree=2, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 2</td>\n      <td>0.949260</td>\n      <td>0.948937</td>\n      <td>0.947346</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9489367816091955 std: 0.04119591828266531</td>\n      <td>m: 0.9473458186693481 std: 0.043647173124497826</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>SVC(C=100, degree=1, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.949260</td>\n      <td>0.948937</td>\n      <td>0.947346</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9489367816091955 std: 0.04119591828266531</td>\n      <td>m: 0.9473458186693481 std: 0.043647173124497826</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>SVC(C=100, degree=1, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.949260</td>\n      <td>0.950921</td>\n      <td>0.945167</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9509209085933226 std: 0.04248827208564486</td>\n      <td>m: 0.9451671694318753 std: 0.04213457606582847</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>SVC(C=100, degree=4, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 4</td>\n      <td>0.949260</td>\n      <td>0.948937</td>\n      <td>0.947346</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9489367816091955 std: 0.04119591828266531</td>\n      <td>m: 0.9473458186693481 std: 0.043647173124497826</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>SVC(C=100, degree=5, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 5</td>\n      <td>0.949260</td>\n      <td>0.948937</td>\n      <td>0.947346</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9489367816091955 std: 0.04119591828266531</td>\n      <td>m: 0.9473458186693481 std: 0.043647173124497826</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>SVC(C=100, degree=6, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 6</td>\n      <td>0.949260</td>\n      <td>0.948937</td>\n      <td>0.947346</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9489367816091955 std: 0.04119591828266531</td>\n      <td>m: 0.9473458186693481 std: 0.043647173124497826</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>SVC(C=100, degree=7, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 7</td>\n      <td>0.949260</td>\n      <td>0.948937</td>\n      <td>0.947346</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9489367816091955 std: 0.04119591828266531</td>\n      <td>m: 0.9473458186693481 std: 0.043647173124497826</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>SVC(C=100, degree=8, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 8</td>\n      <td>0.949260</td>\n      <td>0.948937</td>\n      <td>0.947346</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9489367816091955 std: 0.04119591828266531</td>\n      <td>m: 0.9473458186693481 std: 0.043647173124497826</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>SVC(C=100, degree=4, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 4</td>\n      <td>0.949260</td>\n      <td>0.950238</td>\n      <td>0.945535</td>\n      <td>m: 0.9492600422832981 std: 0.049605220226076316</td>\n      <td>m: 0.9502380952380953 std: 0.05089560699894818</td>\n      <td>m: 0.9455348164906988 std: 0.05378781874923513</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>SVC(C=100, degree=9, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 9</td>\n      <td>0.949260</td>\n      <td>0.948937</td>\n      <td>0.947346</td>\n      <td>m: 0.9492600422832981 std: 0.03994177338895591</td>\n      <td>m: 0.9489367816091955 std: 0.04119591828266531</td>\n      <td>m: 0.9473458186693481 std: 0.043647173124497826</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>SVC(C=100, degree=2, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 2</td>\n      <td>0.949154</td>\n      <td>0.951389</td>\n      <td>0.944800</td>\n      <td>m: 0.9491543340380548 std: 0.04496814340117908</td>\n      <td>m: 0.951388888888889 std: 0.045270108416585256</td>\n      <td>m: 0.9447995223730519 std: 0.050382747022107745</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>SVC(C=100, degree=7, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 7</td>\n      <td>0.944820</td>\n      <td>0.945885</td>\n      <td>0.939652</td>\n      <td>m: 0.9448202959830866 std: 0.04033652670423447</td>\n      <td>m: 0.9458851294903926 std: 0.04481569483269399</td>\n      <td>m: 0.9396524635495224 std: 0.03941845614944265</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>SVC(C=100, degree=6, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 6</td>\n      <td>0.944715</td>\n      <td>0.946131</td>\n      <td>0.939285</td>\n      <td>m: 0.9447145877378436 std: 0.04285501437893323</td>\n      <td>m: 0.9461314349091119 std: 0.046317432103559646</td>\n      <td>m: 0.9392848164906988 std: 0.04384328285674222</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>SVC(C=100, degree=5, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 5</td>\n      <td>0.944609</td>\n      <td>0.946913</td>\n      <td>0.939285</td>\n      <td>m: 0.9446088794926004 std: 0.04787008127514016</td>\n      <td>m: 0.946912972085386 std: 0.049218025790676634</td>\n      <td>m: 0.9392848164906988 std: 0.052527989224167966</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SVC(C=100, degree=8, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 8</td>\n      <td>0.940275</td>\n      <td>0.942560</td>\n      <td>0.933770</td>\n      <td>m: 0.9402748414376321 std: 0.037611938424222405</td>\n      <td>m: 0.9425600063376832 std: 0.042562300923425285</td>\n      <td>m: 0.9337701106083459 std: 0.03644547617860185</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>SVC(C=100, degree=7, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 7</td>\n      <td>0.940275</td>\n      <td>0.944024</td>\n      <td>0.933770</td>\n      <td>m: 0.9402748414376321 std: 0.031645454200115844</td>\n      <td>m: 0.9440243568691844 std: 0.03631184355880235</td>\n      <td>m: 0.9337701106083458 std: 0.03194837591942475</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>SVC(C=100, degree=9, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 9</td>\n      <td>0.935729</td>\n      <td>0.939235</td>\n      <td>0.927888</td>\n      <td>m: 0.9357293868921776 std: 0.034072835565065435</td>\n      <td>m: 0.939234883184974 std: 0.039906635143718824</td>\n      <td>m: 0.9278877576671694 std: 0.032148508990548885</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SVC(C=100, degree=1, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.935518</td>\n      <td>0.940445</td>\n      <td>0.929331</td>\n      <td>m: 0.9355179704016914 std: 0.0398226965851031</td>\n      <td>m: 0.9404447181171319 std: 0.042337481322026534</td>\n      <td>m: 0.9293311127869952 std: 0.04199492314164729</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>SVC(C=100, degree=8, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 8</td>\n      <td>0.931184</td>\n      <td>0.938646</td>\n      <td>0.921638</td>\n      <td>m: 0.931183932346723 std: 0.014728766467147719</td>\n      <td>m: 0.9386464347012016 std: 0.022168198839040785</td>\n      <td>m: 0.9216377576671695 std: 0.01627748950611654</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>SVC(C=100, degree=9, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 9</td>\n      <td>0.866808</td>\n      <td>0.894655</td>\n      <td>0.834560</td>\n      <td>m: 0.8668076109936574 std: 0.06132444988723495</td>\n      <td>m: 0.8946552711993888 std: 0.058266182801191176</td>\n      <td>m: 0.8345598709569299 std: 0.07265018156242421</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVC(C=100, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 3</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SVC(C=100, degree=4, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 4</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVC(C=100, degree=2, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 2</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>SVC(C=100, degree=9, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 9</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SVC(C=100, degree=8, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 8</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>SVC(C=100, degree=7, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 7</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SVC(C=100, degree=5, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 5</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>SVC(C=100, degree=6, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 6</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        SVC(C=100, degree=1, gamma=0.001, kernel='poly')\narguments                                  Kernel: poly, Degree: 1\nmean_accuracy                                              0.96797\nmean_precision                                            0.963363\nmean_recall                                               0.973789\naccuracy            m: 0.967970401691332 std: 0.023305252083176783\nprecision          m: 0.9633625730994153 std: 0.025403888401415272\nrecall               m: 0.9737891737891738 std: 0.0190606594685786\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_results_vote = calculate_svm(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                 votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(svm_results_vote)\n",
    "\n",
    "print_results(svm_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overall Results for Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n15  DecisionTreeClassifier(max_depth=1, min_sample...   \n70                  SVC(C=100, degree=9, gamma=0.001)   \n28  DecisionTreeClassifier(max_depth=7, min_sample...   \n32  DecisionTreeClassifier(max_depth=9, min_sample...   \n33  DecisionTreeClassifier(max_depth=9, min_sample...   \n..                                                ...   \n30  DecisionTreeClassifier(max_depth=7, min_sample...   \n34  DecisionTreeClassifier(max_depth=9, min_sample...   \n40   SVC(C=100, degree=6, gamma=0.001, kernel='poly')   \n37             SVC(C=100, gamma=0.001, kernel='poly')   \n36   SVC(C=100, degree=2, gamma=0.001, kernel='poly')   \n\n                         arguments  mean_accuracy  mean_precision  \\\n15    max Depth: 1, min Samples: 2       0.967970        0.963363   \n70          Kernel: rbf, Degree: 9       0.967970        0.963363   \n28   max Depth: 7, min Samples: 20       0.967970        0.963363   \n32   max Depth: 9, min Samples: 20       0.967970        0.963363   \n33   max Depth: 9, min Samples: 50       0.967970        0.963363   \n..                             ...            ...             ...   \n30  max Depth: 7, min Samples: 100       0.614693        0.307347   \n34  max Depth: 9, min Samples: 100       0.614693        0.307347   \n40         Kernel: poly, Degree: 6       0.614693        0.307347   \n37         Kernel: poly, Degree: 3       0.614693        0.307347   \n36         Kernel: poly, Degree: 2       0.614693        0.307347   \n\n    mean_recall                                        accuracy  \\\n15     0.973789  m: 0.967970401691332 std: 0.023305252083176783   \n70     0.973789  m: 0.967970401691332 std: 0.023305252083176783   \n28     0.973789  m: 0.967970401691332 std: 0.023305252083176783   \n32     0.973789  m: 0.967970401691332 std: 0.023305252083176783   \n33     0.973789  m: 0.967970401691332 std: 0.023305252083176783   \n..          ...                                             ...   \n30     0.500000  m: 0.614693446088795 std: 0.007467223261077965   \n34     0.500000  m: 0.614693446088795 std: 0.007467223261077965   \n40     0.500000  m: 0.614693446088795 std: 0.007467223261077965   \n37     0.500000  m: 0.614693446088795 std: 0.007467223261077965   \n36     0.500000  m: 0.614693446088795 std: 0.007467223261077965   \n\n                                           precision  \\\n15   m: 0.9633625730994153 std: 0.025403888401415272   \n70   m: 0.9633625730994153 std: 0.025403888401415272   \n28   m: 0.9633625730994153 std: 0.025403888401415272   \n32   m: 0.9633625730994153 std: 0.025403888401415272   \n33   m: 0.9633625730994153 std: 0.025403888401415272   \n..                                               ...   \n30  m: 0.3073467230443975 std: 0.0037336116305389825   \n34  m: 0.3073467230443975 std: 0.0037336116305389825   \n40  m: 0.3073467230443975 std: 0.0037336116305389825   \n37  m: 0.3073467230443975 std: 0.0037336116305389825   \n36  m: 0.3073467230443975 std: 0.0037336116305389825   \n\n                                           recall  \n15  m: 0.9737891737891738 std: 0.0190606594685786  \n70  m: 0.9737891737891738 std: 0.0190606594685786  \n28  m: 0.9737891737891738 std: 0.0190606594685786  \n32  m: 0.9737891737891738 std: 0.0190606594685786  \n33  m: 0.9737891737891738 std: 0.0190606594685786  \n..                                            ...  \n30                                m: 0.5 std: 0.0  \n34                                m: 0.5 std: 0.0  \n40                                m: 0.5 std: 0.0  \n37                                m: 0.5 std: 0.0  \n36                                m: 0.5 std: 0.0  \n\n[89 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 2</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>SVC(C=100, degree=9, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 9</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 20</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 50</td>\n      <td>0.967970</td>\n      <td>0.963363</td>\n      <td>0.973789</td>\n      <td>m: 0.967970401691332 std: 0.023305252083176783</td>\n      <td>m: 0.9633625730994153 std: 0.025403888401415272</td>\n      <td>m: 0.9737891737891738 std: 0.0190606594685786</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 100</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>SVC(C=100, degree=6, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 6</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>SVC(C=100, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 3</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>SVC(C=100, degree=2, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 2</td>\n      <td>0.614693</td>\n      <td>0.307347</td>\n      <td>0.500000</td>\n      <td>m: 0.614693446088795 std: 0.007467223261077965</td>\n      <td>m: 0.3073467230443975 std: 0.0037336116305389825</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>89 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        DecisionTreeClassifier(max_depth=1, min_sample...\narguments                              max Depth: 1, min Samples: 2\nmean_accuracy                                               0.96797\nmean_precision                                             0.963363\nmean_recall                                                0.973789\naccuracy             m: 0.967970401691332 std: 0.023305252083176783\nprecision           m: 0.9633625730994153 std: 0.025403888401415272\nrecall                m: 0.9737891737891738 std: 0.0190606594685786\nName: 15, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_results(overall_results_vote, \"mean_accuracy\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train submission file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'Finally recoded back: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID       class\n0     13    democrat\n1    393  republican\n2    163    democrat\n3     57  republican\n4    148    democrat\n..   ...         ...\n212  359    democrat\n213  128    democrat\n214   27    democrat\n215  119    democrat\n216  133  republican\n\n[217 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>393</td>\n      <td>republican</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>163</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>57</td>\n      <td>republican</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>148</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>359</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>128</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>27</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>119</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>133</td>\n      <td>republican</td>\n    </tr>\n  </tbody>\n</table>\n<p>217 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Required Imports\n",
    "from sklearn import svm\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Recode values for predicting variables\n",
    "def recode_voting_data(dataset):\n",
    "    dataset = dataset.replace('y', 1)\\\n",
    "        .replace('n', 0)\n",
    "    dataset[dataset.columns[1:18]] = dataset[dataset.columns[1:18]].astype('category')\n",
    "    return pd.DataFrame(dataset, columns=dataset.columns)\n",
    "\n",
    "#Imput missing values\n",
    "def input_missing_values(data, iterative_imputer):\n",
    "    columns = data.columns\n",
    "    data.loc[:, data.columns != \"ID\"] = np.round(imp.transform(data.loc[:, data.columns != \"ID\"]))\n",
    "    data.loc[:, data.columns != \"ID\"] = data.loc[:, data.columns != \"ID\"].apply(lambda x: x.astype('int'))\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "#Read Data\n",
    "votingDataLearn = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.lrn.csv\", na_values='unknown')\n",
    "votingDataTest = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.tes.csv\", na_values='unknown')\n",
    "\n",
    "#Extract target variable\n",
    "votingDataLearn = votingDataLearn.replace('democrat', 2)\\\n",
    "    .replace('republican', 3)\n",
    "\n",
    "y = votingDataLearn[\"class\"]\n",
    "X = pd.DataFrame(votingDataLearn.drop([\"ID\", \"class\"], axis=1))\n",
    "\n",
    "#Recode Variables\n",
    "X = recode_voting_data(X)\n",
    "votingDataTest = recode_voting_data(votingDataTest)\n",
    "\n",
    "#Input missing values\n",
    "imp = IterativeImputer(max_iter=50, random_state=0)\n",
    "combined_data = X.append(votingDataTest)\n",
    "imp.fit(combined_data.loc[:, combined_data.columns != \"ID\"])\n",
    "X = input_missing_values(X, imp)\n",
    "votingDataTest = input_missing_values(votingDataTest, imp)\n",
    "\n",
    "#Calculate Model\n",
    "classifier = svm.SVC(kernel = \"rbf\", gamma=0.001, C=100)\n",
    "#classifier = tree.DecisionTreeClassifier(max_depth=1)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "#Predict the Test Data\n",
    "votingDataTest[\"class\"] = classifier.predict(votingDataTest[votingDataTest.columns[1:18]])\n",
    "\n",
    "#Recode to required output\n",
    "votingDataTest[\"class\"].replace({2: \"democrat\", 3: \"republican\"}, inplace=True)\n",
    "display(\"Finally recoded back: \", votingDataTest[[\"ID\", \"class\"]])\n",
    "votingDataTest[[\"ID\", \"class\"]].to_csv(\"solution_voting.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "'Original Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9992  V9993  V9994  V9995  \\\n0      0   9   5   5   9   7   0   8   7   1  ...      0      1      0      1   \n1      1  11   9  15  15   5  11  10   1   5  ...      0      0      0      0   \n2      2  11  10  13  12   6   5   0   3   1  ...      0      0      0      0   \n3      3  18   9   7   8   8   7  12   6   7  ...      0      1      0      0   \n4      4  11   7  10  11   4   5   1   8   4  ...      0      0      0      0   \n..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...    ...    ...    ...   \n745  745   5   5   8   2   8   0   5   1   2  ...      1      0      0      0   \n746  746  22  13   8  14   8  11   3   6   7  ...      6      0      2      0   \n747  747  10   3   5   5   7   1  14   2   6  ...      0      0      4      1   \n748  748   9  13   8   5  11   9   9   3   3  ...      0      0      0      1   \n749  749  12   5   8   4   7   5   0   3   4  ...      0      0      4      0   \n\n     V9996  V9997  V9998  V9999  V10000        Class  \n0        0      0      0      0       2        Power  \n1        0      0      0      0       0       Goonan  \n2        0      0      0      1       0      Merritt  \n3        0      1      0      0       1       Goonan  \n4        0      1      0      0       3         Corn  \n..     ...    ...    ...    ...     ...          ...  \n745      0      0      0      0       0      Chachra  \n746      0      2      0      0       0     Morrison  \n747      0      0      2      0       0      Sherwin  \n748      0      0      0      0       0  Blankenship  \n749      1      0      0      0       0     Davisson  \n\n[750 rows x 10002 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>9</td>\n      <td>7</td>\n      <td>0</td>\n      <td>8</td>\n      <td>7</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Power</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11</td>\n      <td>9</td>\n      <td>15</td>\n      <td>15</td>\n      <td>5</td>\n      <td>11</td>\n      <td>10</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>11</td>\n      <td>10</td>\n      <td>13</td>\n      <td>12</td>\n      <td>6</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Merritt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>18</td>\n      <td>9</td>\n      <td>7</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>12</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>11</td>\n      <td>7</td>\n      <td>10</td>\n      <td>11</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>8</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Corn</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>745</td>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Chachra</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>746</td>\n      <td>22</td>\n      <td>13</td>\n      <td>8</td>\n      <td>14</td>\n      <td>8</td>\n      <td>11</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Morrison</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>747</td>\n      <td>10</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1</td>\n      <td>14</td>\n      <td>2</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sherwin</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>748</td>\n      <td>9</td>\n      <td>13</td>\n      <td>8</td>\n      <td>5</td>\n      <td>11</td>\n      <td>9</td>\n      <td>9</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Blankenship</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>749</td>\n      <td>12</td>\n      <td>5</td>\n      <td>8</td>\n      <td>4</td>\n      <td>7</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Davisson</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10002 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Recoded Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9992  V9993  V9994  V9995  \\\n0      0   9   5   5   9   7   0   8   7   1  ...      0      1      0      1   \n1      1  11   9  15  15   5  11  10   1   5  ...      0      0      0      0   \n2      2  11  10  13  12   6   5   0   3   1  ...      0      0      0      0   \n3      3  18   9   7   8   8   7  12   6   7  ...      0      1      0      0   \n4      4  11   7  10  11   4   5   1   8   4  ...      0      0      0      0   \n..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...    ...    ...    ...   \n745  745   5   5   8   2   8   0   5   1   2  ...      1      0      0      0   \n746  746  22  13   8  14   8  11   3   6   7  ...      6      0      2      0   \n747  747  10   3   5   5   7   1  14   2   6  ...      0      0      4      1   \n748  748   9  13   8   5  11   9   9   3   3  ...      0      0      0      1   \n749  749  12   5   8   4   7   5   0   3   4  ...      0      0      4      0   \n\n     V9996  V9997  V9998  V9999  V10000        Class  \n0        0      0      0      0       2        Power  \n1        0      0      0      0       0       Goonan  \n2        0      0      0      1       0      Merritt  \n3        0      1      0      0       1       Goonan  \n4        0      1      0      0       3         Corn  \n..     ...    ...    ...    ...     ...          ...  \n745      0      0      0      0       0      Chachra  \n746      0      2      0      0       0     Morrison  \n747      0      0      2      0       0      Sherwin  \n748      0      0      0      0       0  Blankenship  \n749      1      0      0      0       0     Davisson  \n\n[750 rows x 10002 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>9</td>\n      <td>7</td>\n      <td>0</td>\n      <td>8</td>\n      <td>7</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Power</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11</td>\n      <td>9</td>\n      <td>15</td>\n      <td>15</td>\n      <td>5</td>\n      <td>11</td>\n      <td>10</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>11</td>\n      <td>10</td>\n      <td>13</td>\n      <td>12</td>\n      <td>6</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Merritt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>18</td>\n      <td>9</td>\n      <td>7</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>12</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>11</td>\n      <td>7</td>\n      <td>10</td>\n      <td>11</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>8</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Corn</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>745</td>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Chachra</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>746</td>\n      <td>22</td>\n      <td>13</td>\n      <td>8</td>\n      <td>14</td>\n      <td>8</td>\n      <td>11</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Morrison</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>747</td>\n      <td>10</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1</td>\n      <td>14</td>\n      <td>2</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sherwin</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>748</td>\n      <td>9</td>\n      <td>13</td>\n      <td>8</td>\n      <td>5</td>\n      <td>11</td>\n      <td>9</td>\n      <td>9</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Blankenship</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>749</td>\n      <td>12</td>\n      <td>5</td>\n      <td>8</td>\n      <td>4</td>\n      <td>7</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Davisson</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10002 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Data: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "           V1        V2        V3        V4        V5        V6        V7  \\\n0    0.022849  0.012694  0.012694  0.022849  0.017771  0.000000  0.020310   \n1    0.030256  0.024755  0.041258  0.041258  0.013753  0.030256  0.027505   \n2    0.028761  0.026146  0.033990  0.031376  0.015688  0.013073  0.000000   \n3    0.041891  0.020946  0.016291  0.018618  0.018618  0.016291  0.027927   \n4    0.028918  0.018402  0.026289  0.028918  0.010516  0.013145  0.002629   \n..        ...       ...       ...       ...       ...       ...       ...   \n745  0.026867  0.026867  0.042987  0.010747  0.042987  0.000000  0.026867   \n746  0.048706  0.028781  0.017711  0.030995  0.017711  0.024353  0.006642   \n747  0.026260  0.007878  0.013130  0.013130  0.018382  0.002626  0.036764   \n748  0.025152  0.036330  0.022357  0.013973  0.030741  0.025152  0.025152   \n749  0.036478  0.015199  0.024319  0.012159  0.021279  0.015199  0.000000   \n\n           V8        V9       V10  ...     V9991     V9992     V9993  \\\n0    0.017771  0.002539  0.012694  ...  0.000000  0.000000  0.002539   \n1    0.002751  0.013753  0.019254  ...  0.000000  0.000000  0.000000   \n2    0.007844  0.002615  0.002615  ...  0.002615  0.000000  0.000000   \n3    0.013964  0.016291  0.002327  ...  0.000000  0.000000  0.002327   \n4    0.021031  0.010516  0.010516  ...  0.000000  0.000000  0.000000   \n..        ...       ...       ...  ...       ...       ...       ...   \n745  0.005373  0.010747  0.016120  ...  0.000000  0.005373  0.000000   \n746  0.013284  0.015497  0.013284  ...  0.000000  0.013284  0.000000   \n747  0.005252  0.015756  0.002626  ...  0.000000  0.000000  0.000000   \n748  0.008384  0.008384  0.016768  ...  0.000000  0.000000  0.000000   \n749  0.009120  0.012159  0.012159  ...  0.000000  0.000000  0.000000   \n\n        V9994     V9995    V9996     V9997     V9998     V9999    V10000  \n0    0.000000  0.002539  0.00000  0.000000  0.000000  0.000000  0.005077  \n1    0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n2    0.000000  0.000000  0.00000  0.000000  0.000000  0.002615  0.000000  \n3    0.000000  0.000000  0.00000  0.002327  0.000000  0.000000  0.002327  \n4    0.000000  0.000000  0.00000  0.002629  0.000000  0.000000  0.007887  \n..        ...       ...      ...       ...       ...       ...       ...  \n745  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n746  0.004428  0.000000  0.00000  0.004428  0.000000  0.000000  0.000000  \n747  0.010504  0.002626  0.00000  0.000000  0.005252  0.000000  0.000000  \n748  0.000000  0.002795  0.00000  0.000000  0.000000  0.000000  0.000000  \n749  0.012159  0.000000  0.00304  0.000000  0.000000  0.000000  0.000000  \n\n[750 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.022849</td>\n      <td>0.012694</td>\n      <td>0.012694</td>\n      <td>0.022849</td>\n      <td>0.017771</td>\n      <td>0.000000</td>\n      <td>0.020310</td>\n      <td>0.017771</td>\n      <td>0.002539</td>\n      <td>0.012694</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002539</td>\n      <td>0.000000</td>\n      <td>0.002539</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005077</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.030256</td>\n      <td>0.024755</td>\n      <td>0.041258</td>\n      <td>0.041258</td>\n      <td>0.013753</td>\n      <td>0.030256</td>\n      <td>0.027505</td>\n      <td>0.002751</td>\n      <td>0.013753</td>\n      <td>0.019254</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.028761</td>\n      <td>0.026146</td>\n      <td>0.033990</td>\n      <td>0.031376</td>\n      <td>0.015688</td>\n      <td>0.013073</td>\n      <td>0.000000</td>\n      <td>0.007844</td>\n      <td>0.002615</td>\n      <td>0.002615</td>\n      <td>...</td>\n      <td>0.002615</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002615</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.041891</td>\n      <td>0.020946</td>\n      <td>0.016291</td>\n      <td>0.018618</td>\n      <td>0.018618</td>\n      <td>0.016291</td>\n      <td>0.027927</td>\n      <td>0.013964</td>\n      <td>0.016291</td>\n      <td>0.002327</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002327</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.002327</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002327</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.028918</td>\n      <td>0.018402</td>\n      <td>0.026289</td>\n      <td>0.028918</td>\n      <td>0.010516</td>\n      <td>0.013145</td>\n      <td>0.002629</td>\n      <td>0.021031</td>\n      <td>0.010516</td>\n      <td>0.010516</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.002629</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.007887</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>0.026867</td>\n      <td>0.026867</td>\n      <td>0.042987</td>\n      <td>0.010747</td>\n      <td>0.042987</td>\n      <td>0.000000</td>\n      <td>0.026867</td>\n      <td>0.005373</td>\n      <td>0.010747</td>\n      <td>0.016120</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.005373</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>0.048706</td>\n      <td>0.028781</td>\n      <td>0.017711</td>\n      <td>0.030995</td>\n      <td>0.017711</td>\n      <td>0.024353</td>\n      <td>0.006642</td>\n      <td>0.013284</td>\n      <td>0.015497</td>\n      <td>0.013284</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.013284</td>\n      <td>0.000000</td>\n      <td>0.004428</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.004428</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>0.026260</td>\n      <td>0.007878</td>\n      <td>0.013130</td>\n      <td>0.013130</td>\n      <td>0.018382</td>\n      <td>0.002626</td>\n      <td>0.036764</td>\n      <td>0.005252</td>\n      <td>0.015756</td>\n      <td>0.002626</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010504</td>\n      <td>0.002626</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.005252</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>0.025152</td>\n      <td>0.036330</td>\n      <td>0.022357</td>\n      <td>0.013973</td>\n      <td>0.030741</td>\n      <td>0.025152</td>\n      <td>0.025152</td>\n      <td>0.008384</td>\n      <td>0.008384</td>\n      <td>0.016768</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002795</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>0.036478</td>\n      <td>0.015199</td>\n      <td>0.024319</td>\n      <td>0.012159</td>\n      <td>0.021279</td>\n      <td>0.015199</td>\n      <td>0.000000</td>\n      <td>0.009120</td>\n      <td>0.012159</td>\n      <td>0.012159</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012159</td>\n      <td>0.000000</td>\n      <td>0.00304</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Target: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0            Power\n1           Goonan\n2          Merritt\n3           Goonan\n4             Corn\n          ...     \n745        Chachra\n746       Morrison\n747        Sherwin\n748    Blankenship\n749       Davisson\nName: Class, Length: 750, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "#Read Data\n",
    "amazonDataLearn = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.lrn.csv\")\n",
    "amazonDataSolutionExample = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.sol.ex.csv\")\n",
    "amazonDataTest = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.tes.csv\")\n",
    "display(\"Original Data\", amazonDataLearn)\n",
    "\n",
    "#Recode values\n",
    "#For One Hot Encoding of Class\n",
    "#amazonDataLearn = pd.concat([amazonDataLearn, pd.get_dummies(amazonDataLearn[\"Class\"], prefix='author_',drop_first=False)], axis=1)\n",
    "#amazonDataLearn.drop(['Class'],axis=1, inplace=True)\n",
    "#names_target = amazonDataLearn.loc[:, amazonDataLearn.columns.str.startswith('author_')]\n",
    "#amazonDataLearn[names_target.columns] = amazonDataLearn[names_target.columns].apply(lambda x: x.astype('category'))\n",
    "\n",
    "# For Label Encoding\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#le.fit(amazonDataLearn['Class'])\n",
    "#amazonDataLearn['Class'] = le.transform(amazonDataLearn['Class'])\n",
    "#amazonDataLearn['Class'] = amazonDataLearn['Class'].astype('category')\n",
    "\n",
    "names_data = amazonDataLearn.loc[:, amazonDataLearn.columns.str.startswith('V')]\n",
    "#amazonDataLearn[0:10000] = amazonDataLearn[0:10000].apply(lambda x: x.astype('int'))\n",
    "\n",
    "# Normalize data\n",
    "def normalize_values(data):\n",
    "    columns = data.columns\n",
    "    data = preprocessing.Normalizer().fit_transform(data)\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "display(\"Recoded Data\", amazonDataLearn)\n",
    "\n",
    "X_amazon = normalize_values(amazonDataLearn[names_data.columns])\n",
    "y_amazon = amazonDataLearn[\"Class\"]\n",
    "\n",
    "display(\"Data: \", X_amazon)\n",
    "display(\"Target: \", y_amazon)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### k-NN Calculation - Amazon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                            classifier arguments  mean_accuracy  \\\n0  KNeighborsClassifier(n_neighbors=1)     N = 1       0.273333   \n6  KNeighborsClassifier(n_neighbors=7)     N = 7       0.253333   \n7  KNeighborsClassifier(n_neighbors=8)     N = 8       0.246667   \n4               KNeighborsClassifier()     N = 5       0.238667   \n5  KNeighborsClassifier(n_neighbors=6)     N = 6       0.237333   \n8  KNeighborsClassifier(n_neighbors=9)     N = 9       0.234667   \n2  KNeighborsClassifier(n_neighbors=3)     N = 3       0.229333   \n3  KNeighborsClassifier(n_neighbors=4)     N = 4       0.226667   \n1  KNeighborsClassifier(n_neighbors=2)     N = 2       0.221333   \n\n   mean_precision  mean_recall  \\\n0        0.279978     0.262333   \n6        0.280771     0.244000   \n7        0.266944     0.238333   \n4        0.260482     0.232333   \n5        0.256108     0.226667   \n8        0.249151     0.227667   \n2        0.244745     0.227000   \n3        0.250132     0.221333   \n1        0.224895     0.218667   \n\n                                           accuracy  \\\n0   m: 0.2733333333333333 std: 0.018378731669453627   \n6  m: 0.25333333333333335 std: 0.013333333333333327   \n7   m: 0.24666666666666665 std: 0.01632993161855452   \n4  m: 0.23866666666666667 std: 0.022070593809662472   \n5  m: 0.23733333333333334 std: 0.030579586509812573   \n8  m: 0.23466666666666666 std: 0.022469732728470294   \n2   m: 0.22933333333333333 std: 0.01768866554856214   \n3  m: 0.22666666666666666 std: 0.017384539747207068   \n1  m: 0.22133333333333333 std: 0.016546231527987804   \n\n                                          precision  \\\n0   m: 0.2799775335775336 std: 0.024564836359824562   \n6    m: 0.2807707117264662 std: 0.02619790566738083   \n7   m: 0.26694380717321897 std: 0.03690138309463883   \n4   m: 0.2604821920108877 std: 0.043216904898388454   \n5    m: 0.2561081249668206 std: 0.05422575028681419   \n8   m: 0.24915127694981914 std: 0.02777585327246395   \n2   m: 0.24474459037021967 std: 0.04298428983874409   \n3  m: 0.25013176185624697 std: 0.046394677392848166   \n1  m: 0.22489529914529913 std: 0.012649167661970356   \n\n                                             recall  \n0   m: 0.2623333333333333 std: 0.014087031072743617  \n6                m: 0.244 std: 0.009463379711052279  \n7  m: 0.23833333333333334 std: 0.012247448713915901  \n4  m: 0.23233333333333334 std: 0.017907168024751053  \n5  m: 0.22666666666666666 std: 0.026729093595639287  \n8  m: 0.22766666666666663 std: 0.023036203390894655  \n2                 m: 0.227 std: 0.01833030277982336  \n3   m: 0.22133333333333333 std: 0.01442990721460891  \n1   m: 0.21866666666666665 std: 0.01671326818229556  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KNeighborsClassifier(n_neighbors=1)</td>\n      <td>N = 1</td>\n      <td>0.273333</td>\n      <td>0.279978</td>\n      <td>0.262333</td>\n      <td>m: 0.2733333333333333 std: 0.018378731669453627</td>\n      <td>m: 0.2799775335775336 std: 0.024564836359824562</td>\n      <td>m: 0.2623333333333333 std: 0.014087031072743617</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>KNeighborsClassifier(n_neighbors=7)</td>\n      <td>N = 7</td>\n      <td>0.253333</td>\n      <td>0.280771</td>\n      <td>0.244000</td>\n      <td>m: 0.25333333333333335 std: 0.013333333333333327</td>\n      <td>m: 0.2807707117264662 std: 0.02619790566738083</td>\n      <td>m: 0.244 std: 0.009463379711052279</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>KNeighborsClassifier(n_neighbors=8)</td>\n      <td>N = 8</td>\n      <td>0.246667</td>\n      <td>0.266944</td>\n      <td>0.238333</td>\n      <td>m: 0.24666666666666665 std: 0.01632993161855452</td>\n      <td>m: 0.26694380717321897 std: 0.03690138309463883</td>\n      <td>m: 0.23833333333333334 std: 0.012247448713915901</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNeighborsClassifier()</td>\n      <td>N = 5</td>\n      <td>0.238667</td>\n      <td>0.260482</td>\n      <td>0.232333</td>\n      <td>m: 0.23866666666666667 std: 0.022070593809662472</td>\n      <td>m: 0.2604821920108877 std: 0.043216904898388454</td>\n      <td>m: 0.23233333333333334 std: 0.017907168024751053</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNeighborsClassifier(n_neighbors=6)</td>\n      <td>N = 6</td>\n      <td>0.237333</td>\n      <td>0.256108</td>\n      <td>0.226667</td>\n      <td>m: 0.23733333333333334 std: 0.030579586509812573</td>\n      <td>m: 0.2561081249668206 std: 0.05422575028681419</td>\n      <td>m: 0.22666666666666666 std: 0.026729093595639287</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>KNeighborsClassifier(n_neighbors=9)</td>\n      <td>N = 9</td>\n      <td>0.234667</td>\n      <td>0.249151</td>\n      <td>0.227667</td>\n      <td>m: 0.23466666666666666 std: 0.022469732728470294</td>\n      <td>m: 0.24915127694981914 std: 0.02777585327246395</td>\n      <td>m: 0.22766666666666663 std: 0.023036203390894655</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KNeighborsClassifier(n_neighbors=3)</td>\n      <td>N = 3</td>\n      <td>0.229333</td>\n      <td>0.244745</td>\n      <td>0.227000</td>\n      <td>m: 0.22933333333333333 std: 0.01768866554856214</td>\n      <td>m: 0.24474459037021967 std: 0.04298428983874409</td>\n      <td>m: 0.227 std: 0.01833030277982336</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KNeighborsClassifier(n_neighbors=4)</td>\n      <td>N = 4</td>\n      <td>0.226667</td>\n      <td>0.250132</td>\n      <td>0.221333</td>\n      <td>m: 0.22666666666666666 std: 0.017384539747207068</td>\n      <td>m: 0.25013176185624697 std: 0.046394677392848166</td>\n      <td>m: 0.22133333333333333 std: 0.01442990721460891</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KNeighborsClassifier(n_neighbors=2)</td>\n      <td>N = 2</td>\n      <td>0.221333</td>\n      <td>0.224895</td>\n      <td>0.218667</td>\n      <td>m: 0.22133333333333333 std: 0.016546231527987804</td>\n      <td>m: 0.22489529914529913 std: 0.012649167661970356</td>\n      <td>m: 0.21866666666666665 std: 0.01671326818229556</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                    KNeighborsClassifier(n_neighbors=1)\narguments                                                   N = 1\nmean_accuracy                                            0.273333\nmean_precision                                           0.279978\nmean_recall                                              0.262333\naccuracy          m: 0.2733333333333333 std: 0.018378731669453627\nprecision         m: 0.2799775335775336 std: 0.024564836359824562\nrecall            m: 0.2623333333333333 std: 0.014087031072743617\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_results_amazon = calculate_knn(X_amazon,\n",
    "                                   y_amazon)\n",
    "overall_results_amazon.extend(knn_results_amazon)\n",
    "\n",
    "print_results(knn_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     classifier            arguments  mean_accuracy  mean_precision  \\\n0  Perceptron()  No additional args.          0.224        0.228859   \n\n   mean_recall                                         accuracy  \\\n0        0.211  m: 0.22400000000000003 std: 0.07584780081774876   \n\n                                         precision  \\\n0  m: 0.22885949351343768 std: 0.08540867785826414   \n\n                             recall  \n0  m: 0.211 std: 0.0708958547605022  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Perceptron()</td>\n      <td>No additional args.</td>\n      <td>0.224</td>\n      <td>0.228859</td>\n      <td>0.211</td>\n      <td>m: 0.22400000000000003 std: 0.07584780081774876</td>\n      <td>m: 0.22885949351343768 std: 0.08540867785826414</td>\n      <td>m: 0.211 std: 0.0708958547605022</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                                           Perceptron()\narguments                                     No additional args.\nmean_accuracy                                               0.224\nmean_precision                                           0.228859\nmean_recall                                                 0.211\naccuracy          m: 0.22400000000000003 std: 0.07584780081774876\nprecision         m: 0.22885949351343768 std: 0.08540867785826414\nrecall                           m: 0.211 std: 0.0708958547605022\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perceptron_results_amazon = calculate_perceptron(X_amazon,\n",
    "                                                 y_amazon)\n",
    "overall_results_amazon.extend(perceptron_results_amazon)\n",
    "\n",
    "print_results(perceptron_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n17  DecisionTreeClassifier(max_depth=9, min_sample...   \n16  DecisionTreeClassifier(max_depth=9, min_sample...   \n13  DecisionTreeClassifier(max_depth=7, min_sample...   \n12  DecisionTreeClassifier(max_depth=7, min_sample...   \n10  DecisionTreeClassifier(max_depth=5, min_sample...   \n18  DecisionTreeClassifier(max_depth=9, min_sample...   \n14  DecisionTreeClassifier(max_depth=7, min_sample...   \n8   DecisionTreeClassifier(max_depth=5, min_sample...   \n9   DecisionTreeClassifier(max_depth=5, min_sample...   \n6   DecisionTreeClassifier(max_depth=3, min_sample...   \n4   DecisionTreeClassifier(max_depth=3, min_sample...   \n5   DecisionTreeClassifier(max_depth=3, min_sample...   \n15  DecisionTreeClassifier(max_depth=7, min_sample...   \n19  DecisionTreeClassifier(max_depth=9, min_sample...   \n11  DecisionTreeClassifier(max_depth=5, min_sample...   \n7   DecisionTreeClassifier(max_depth=3, min_sample...   \n3   DecisionTreeClassifier(max_depth=1, min_sample...   \n2   DecisionTreeClassifier(max_depth=1, min_sample...   \n0   DecisionTreeClassifier(max_depth=1, min_sample...   \n1   DecisionTreeClassifier(max_depth=1, min_sample...   \n\n                         arguments  mean_accuracy  mean_precision  \\\n17   max Depth: 9, min Samples: 20       0.221333        0.109078   \n16    max Depth: 9, min Samples: 2       0.197333        0.182503   \n13   max Depth: 7, min Samples: 20       0.186667        0.080795   \n12    max Depth: 7, min Samples: 2       0.161333        0.135135   \n10   max Depth: 5, min Samples: 50       0.141333        0.028742   \n18   max Depth: 9, min Samples: 50       0.141333        0.028742   \n14   max Depth: 7, min Samples: 50       0.141333        0.028742   \n8     max Depth: 5, min Samples: 2       0.130667        0.099738   \n9    max Depth: 5, min Samples: 20       0.120000        0.044873   \n6    max Depth: 3, min Samples: 50       0.093333        0.014105   \n4     max Depth: 3, min Samples: 2       0.088000        0.060513   \n5    max Depth: 3, min Samples: 20       0.081333        0.027902   \n15  max Depth: 7, min Samples: 100       0.076000        0.007133   \n19  max Depth: 9, min Samples: 100       0.076000        0.007133   \n11  max Depth: 5, min Samples: 100       0.076000        0.007133   \n7   max Depth: 3, min Samples: 100       0.076000        0.007133   \n3   max Depth: 1, min Samples: 100       0.044000        0.002378   \n2    max Depth: 1, min Samples: 50       0.044000        0.002378   \n0     max Depth: 1, min Samples: 2       0.044000        0.020490   \n1    max Depth: 1, min Samples: 20       0.038667        0.010735   \n\n    mean_recall                                           accuracy  \\\n17     0.209000    m: 0.22133333333333338 std: 0.03166491223210112   \n16     0.191000    m: 0.1973333333333333 std: 0.020912516188477497   \n13     0.172667    m: 0.18666666666666668 std: 0.02666666666666667   \n12     0.152000   m: 0.16133333333333333 std: 0.009797958971132713   \n10     0.132333    m: 0.1413333333333333 std: 0.025785439474418283   \n18     0.132333    m: 0.1413333333333333 std: 0.025785439474418283   \n14     0.132333    m: 0.1413333333333333 std: 0.025785439474418283   \n8      0.117667   m: 0.13066666666666665 std: 0.009977753031397182   \n9      0.108333                  m: 0.12 std: 0.023851391759997755   \n6      0.084667   m: 0.09333333333333334 std: 0.008432740427115679   \n4      0.079000                m: 0.088 std: 0.0049888765156985895   \n5      0.071333   m: 0.08133333333333333 std: 0.009797958971132713   \n15     0.071333                 m: 0.076 std: 0.006798692684790382   \n19     0.071333                 m: 0.076 std: 0.006798692684790382   \n11     0.071333                 m: 0.076 std: 0.006798692684790382   \n7      0.071333                 m: 0.076 std: 0.006798692684790382   \n3      0.040000  m: 0.044000000000000004 std: 0.003265986323710...   \n2      0.040000  m: 0.044000000000000004 std: 0.003265986323710...   \n0      0.039000  m: 0.044000000000000004 std: 0.003265986323710...   \n1      0.033333  m: 0.03866666666666667 std: 0.0077746025264604016   \n\n                                            precision  \\\n17    m: 0.10907801631217191 std: 0.02207017014108872   \n16      m: 0.1825029903600236 std: 0.0178525974282946   \n13   m: 0.08079470558607138 std: 0.016771590163415853   \n12   m: 0.13513467576779098 std: 0.008851949077256116   \n10  m: 0.028741512735630387 std: 0.005716058018951...   \n18  m: 0.028741512735630387 std: 0.005716058018951...   \n14  m: 0.028741512735630387 std: 0.005716058018951...   \n8    m: 0.09973849224963775 std: 0.001567674636739009   \n9   m: 0.044873463008003094 std: 0.012153757507980322   \n6   m: 0.014105219748524134 std: 0.001445612402666...   \n4   m: 0.06051286727456939 std: 7.009036233202909e-05   \n5   m: 0.027901722075223366 std: 0.009062519344084894   \n15  m: 0.007133472684943909 std: 0.000861010467426...   \n19  m: 0.007133472684943909 std: 0.000861010467426...   \n11  m: 0.007133472684943909 std: 0.000861010467426...   \n7   m: 0.007133472684943909 std: 0.000861010467426...   \n3   m: 0.002377865968224286 std: 0.000207602854652...   \n2   m: 0.002377865968224286 std: 0.000207602854652...   \n0   m: 0.02048979591836735 std: 6.665278211654873e-05   \n1   m: 0.010734637964774951 std: 0.003902944563754...   \n\n                                               recall  \n17                 m: 0.209 std: 0.030886890422961007  \n16                  m: 0.191 std: 0.01830604029032797  \n13    m: 0.1726666666666667 std: 0.025854292572887103  \n12                 m: 0.152 std: 0.009273618495495703  \n10    m: 0.1323333333333333 std: 0.028256759270030317  \n18    m: 0.1323333333333333 std: 0.028256759270030317  \n14    m: 0.1323333333333333 std: 0.028256759270030317  \n8    m: 0.11766666666666666 std: 0.002905932629027114  \n9     m: 0.10833333333333332 std: 0.02019350830781462  \n6    m: 0.08466666666666667 std: 0.007774602526460402  \n4                 m: 0.079 std: 0.0020000000000000018  \n5    m: 0.07133333333333333 std: 0.009510228411791404  \n15   m: 0.07133333333333333 std: 0.007845734863959881  \n19   m: 0.07133333333333333 std: 0.007845734863959881  \n11   m: 0.07133333333333333 std: 0.007845734863959881  \n7    m: 0.07133333333333333 std: 0.007845734863959881  \n3                                    m: 0.04 std: 0.0  \n2                                    m: 0.04 std: 0.0  \n0                 m: 0.039 std: 0.0019999999999999987  \n1   m: 0.03333333333333334 std: 0.0064117946872237815  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 20</td>\n      <td>0.221333</td>\n      <td>0.109078</td>\n      <td>0.209000</td>\n      <td>m: 0.22133333333333338 std: 0.03166491223210112</td>\n      <td>m: 0.10907801631217191 std: 0.02207017014108872</td>\n      <td>m: 0.209 std: 0.030886890422961007</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 2</td>\n      <td>0.197333</td>\n      <td>0.182503</td>\n      <td>0.191000</td>\n      <td>m: 0.1973333333333333 std: 0.020912516188477497</td>\n      <td>m: 0.1825029903600236 std: 0.0178525974282946</td>\n      <td>m: 0.191 std: 0.01830604029032797</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 20</td>\n      <td>0.186667</td>\n      <td>0.080795</td>\n      <td>0.172667</td>\n      <td>m: 0.18666666666666668 std: 0.02666666666666667</td>\n      <td>m: 0.08079470558607138 std: 0.016771590163415853</td>\n      <td>m: 0.1726666666666667 std: 0.025854292572887103</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 2</td>\n      <td>0.161333</td>\n      <td>0.135135</td>\n      <td>0.152000</td>\n      <td>m: 0.16133333333333333 std: 0.009797958971132713</td>\n      <td>m: 0.13513467576779098 std: 0.008851949077256116</td>\n      <td>m: 0.152 std: 0.009273618495495703</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 50</td>\n      <td>0.141333</td>\n      <td>0.028742</td>\n      <td>0.132333</td>\n      <td>m: 0.1413333333333333 std: 0.025785439474418283</td>\n      <td>m: 0.028741512735630387 std: 0.005716058018951...</td>\n      <td>m: 0.1323333333333333 std: 0.028256759270030317</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 50</td>\n      <td>0.141333</td>\n      <td>0.028742</td>\n      <td>0.132333</td>\n      <td>m: 0.1413333333333333 std: 0.025785439474418283</td>\n      <td>m: 0.028741512735630387 std: 0.005716058018951...</td>\n      <td>m: 0.1323333333333333 std: 0.028256759270030317</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 50</td>\n      <td>0.141333</td>\n      <td>0.028742</td>\n      <td>0.132333</td>\n      <td>m: 0.1413333333333333 std: 0.025785439474418283</td>\n      <td>m: 0.028741512735630387 std: 0.005716058018951...</td>\n      <td>m: 0.1323333333333333 std: 0.028256759270030317</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 2</td>\n      <td>0.130667</td>\n      <td>0.099738</td>\n      <td>0.117667</td>\n      <td>m: 0.13066666666666665 std: 0.009977753031397182</td>\n      <td>m: 0.09973849224963775 std: 0.001567674636739009</td>\n      <td>m: 0.11766666666666666 std: 0.002905932629027114</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 20</td>\n      <td>0.120000</td>\n      <td>0.044873</td>\n      <td>0.108333</td>\n      <td>m: 0.12 std: 0.023851391759997755</td>\n      <td>m: 0.044873463008003094 std: 0.012153757507980322</td>\n      <td>m: 0.10833333333333332 std: 0.02019350830781462</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 50</td>\n      <td>0.093333</td>\n      <td>0.014105</td>\n      <td>0.084667</td>\n      <td>m: 0.09333333333333334 std: 0.008432740427115679</td>\n      <td>m: 0.014105219748524134 std: 0.001445612402666...</td>\n      <td>m: 0.08466666666666667 std: 0.007774602526460402</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 2</td>\n      <td>0.088000</td>\n      <td>0.060513</td>\n      <td>0.079000</td>\n      <td>m: 0.088 std: 0.0049888765156985895</td>\n      <td>m: 0.06051286727456939 std: 7.009036233202909e-05</td>\n      <td>m: 0.079 std: 0.0020000000000000018</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 20</td>\n      <td>0.081333</td>\n      <td>0.027902</td>\n      <td>0.071333</td>\n      <td>m: 0.08133333333333333 std: 0.009797958971132713</td>\n      <td>m: 0.027901722075223366 std: 0.009062519344084894</td>\n      <td>m: 0.07133333333333333 std: 0.009510228411791404</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 100</td>\n      <td>0.076000</td>\n      <td>0.007133</td>\n      <td>0.071333</td>\n      <td>m: 0.076 std: 0.006798692684790382</td>\n      <td>m: 0.007133472684943909 std: 0.000861010467426...</td>\n      <td>m: 0.07133333333333333 std: 0.007845734863959881</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 100</td>\n      <td>0.076000</td>\n      <td>0.007133</td>\n      <td>0.071333</td>\n      <td>m: 0.076 std: 0.006798692684790382</td>\n      <td>m: 0.007133472684943909 std: 0.000861010467426...</td>\n      <td>m: 0.07133333333333333 std: 0.007845734863959881</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 100</td>\n      <td>0.076000</td>\n      <td>0.007133</td>\n      <td>0.071333</td>\n      <td>m: 0.076 std: 0.006798692684790382</td>\n      <td>m: 0.007133472684943909 std: 0.000861010467426...</td>\n      <td>m: 0.07133333333333333 std: 0.007845734863959881</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 100</td>\n      <td>0.076000</td>\n      <td>0.007133</td>\n      <td>0.071333</td>\n      <td>m: 0.076 std: 0.006798692684790382</td>\n      <td>m: 0.007133472684943909 std: 0.000861010467426...</td>\n      <td>m: 0.07133333333333333 std: 0.007845734863959881</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 100</td>\n      <td>0.044000</td>\n      <td>0.002378</td>\n      <td>0.040000</td>\n      <td>m: 0.044000000000000004 std: 0.003265986323710...</td>\n      <td>m: 0.002377865968224286 std: 0.000207602854652...</td>\n      <td>m: 0.04 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 50</td>\n      <td>0.044000</td>\n      <td>0.002378</td>\n      <td>0.040000</td>\n      <td>m: 0.044000000000000004 std: 0.003265986323710...</td>\n      <td>m: 0.002377865968224286 std: 0.000207602854652...</td>\n      <td>m: 0.04 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 2</td>\n      <td>0.044000</td>\n      <td>0.020490</td>\n      <td>0.039000</td>\n      <td>m: 0.044000000000000004 std: 0.003265986323710...</td>\n      <td>m: 0.02048979591836735 std: 6.665278211654873e-05</td>\n      <td>m: 0.039 std: 0.0019999999999999987</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 20</td>\n      <td>0.038667</td>\n      <td>0.010735</td>\n      <td>0.033333</td>\n      <td>m: 0.03866666666666667 std: 0.0077746025264604016</td>\n      <td>m: 0.010734637964774951 std: 0.003902944563754...</td>\n      <td>m: 0.03333333333333334 std: 0.0064117946872237815</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        DecisionTreeClassifier(max_depth=9, min_sample...\narguments                             max Depth: 9, min Samples: 20\nmean_accuracy                                              0.221333\nmean_precision                                             0.109078\nmean_recall                                                   0.209\naccuracy            m: 0.22133333333333338 std: 0.03166491223210112\nprecision           m: 0.10907801631217191 std: 0.02207017014108872\nrecall                           m: 0.209 std: 0.030886890422961007\nName: 17, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_results_amazon = calculate_decision_tree(X_amazon,\n",
    "                                                       y_amazon)\n",
    "overall_results_amazon.extend(decision_tree_results_amazon)\n",
    "\n",
    "print_results(decision_tree_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_results_amazon = calculate_svm(X_amazon,\n",
    "                                   y_amazon)\n",
    "overall_results_amazon.extend(svm_results_amazon)\n",
    "\n",
    "print_results(svm_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overall Results for Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_results(overall_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Read Data\n",
    "amazon_data_learn = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.lrn.csv\")\n",
    "amazon_data_test = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.tes.csv\")\n",
    "\n",
    "# Label Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(amazon_data_learn[\"Class\"])\n",
    "#amazon_data_learn[\"Class\"] = le.transform(amazon_data_learn[\"Class\"])\n",
    "amazon_data_learn[\"Class\"] = amazon_data_learn[\"Class\"].astype(\"category\")\n",
    "\n",
    "names_data = amazon_data_learn.loc[:, amazon_data_learn.columns.str.startswith(\"V\")]\n",
    "\n",
    "display(\"Recoded Data\", amazon_data_learn)\n",
    "y = amazon_data_learn[\"Class\"]\n",
    "X = pd.DataFrame(amazon_data_learn.drop([\"ID\", \"Class\"], axis=1))\n",
    "X = X[names_data.columns]\n",
    "\n",
    "#Normalize data\n",
    "def normalize_values(data):\n",
    "    columns = data.columns\n",
    "    data = preprocessing.Normalizer().fit_transform(data)\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "X_norm = normalize_values(X)\n",
    "test_X = normalize_values(amazon_data_test[names_data.columns])\n",
    "\n",
    "display(\"Data Normalized: \", X_norm)\n",
    "display(\"Target: \", y)\n",
    "display(\"Test Dataset: \", amazon_data_test)\n",
    "display(\"Test Dataset, Predictors: \", amazon_data_test[names_data.columns])\n",
    "display(\"Test Dataset, Normalized: \", test_X)\n",
    "\n",
    "#Calculate Model\n",
    "classifier = svm.SVC(C=101, kernel='poly')\n",
    "classifier.fit(X_norm, y)\n",
    "\n",
    "#Predict the Test Data\n",
    "amazon_data_test[\"Class\"] = classifier.predict(test_X)\n",
    "\n",
    "display(\"Finally recoded: \", amazon_data_test[[\"ID\", \"Class\"]])\n",
    "amazon_data_test[[\"ID\", \"Class\"]].to_csv(\"solution_amazon.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}