{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MLE - Exercise 3 - Kaggle Competition\n",
    "## Andreas Kocman (se19m024)\n",
    "\n",
    "##Assignment\n",
    "This exercise is in the form of a Kaggle competition. A few quick details on Kaggle & the competition format:\n",
    "\n",
    "### Kaggle\n",
    "* Kaggle (https://en.wikipedia.org/wiki/Kaggle) is a platform that allows a competition for a certain data set. Participants submit their prediction on a test set, and will get automated scoring on their results, and will enter the leaderboard.\n",
    "* From Kaggle, you will be able to obtain a labelled training set, and an unlabelled test set.\n",
    "* You can submit multiple entries to Kaggle; for each entry, you need to provide details on how you achieved the results - which software and which version of the software, which operating system, which algorithms, and which parameter settings for these algorithms; further, any processing applied to the data before training/predicting. There is a specific \"description\" field when submitting, you should fill in this information there, and you also need to include this description and the actual submission file in your final submission to Moodle.\n",
    "* To submit to Kaggle, you need to create a specific submission file, which contains the predictions you obtain on the test set. Computing an aggregated evaluation criterion is done automatically by Kaggle\n",
    "* The format of your submission is rather simple - it is a comma-separated file, where the first column is the identifier of the item that you are predicting, and the second column is the class you are predicting for that item. The first line should include a header, and is should use the names provided in the training set. An example is below:\n",
    "```\n",
    "ID,class\n",
    "911366,B\n",
    "852781,B\n",
    "89524,B\n",
    "857438,B\n",
    "905686,B\n",
    "```\n",
    "* There is a limit of 7 submissions per day; finally, you also need to select your top 7 submissions to be counted in the competition\n",
    "* Before you submit, you should evaluate the classifiers \"locally\" on your training set, i.e. by splitting that again in a training & test set (or using cross validation), to select a number of fitting algorithms & parameters. Then re-train your best models on the full local training set, and generate the predictions for the test set.\n",
    "* Evaluation in Kaggle is split in two types of leaderboards - the private and public one. Here, the data is split into 50% / 50%, and as soon as you upload, you will know your results on one of these splits.\n",
    "* The final results will only be visible once the competition closes, and as it is computed on a different split, might be slightly different than what you see initially (e.g. this is similar to a training/test/validation split)\n",
    "* As it is a competition, there will be bonus points for the top 3 submissions.\n",
    "* As reproducible science is great, there will be additional bonus points for submissions that use a notebook within the Kaggle competition (note: this was / partially still is called a \"kernel\" inside the Kaggle competition; Kernel obviously was a confusing term here, as it basically refers to code being executed in the environment of Kaggle itself (e.g. a jupyter notebook, or also a python or R script), and they seem to have realized that, and renamed it). see https://www.kaggle.com/notebooks or https://www.kaggle.com/getting-started/44939. You can first work locally, and then port your code to the notebook version. In Kaggle, your notebook will initially be private. Please share it with me (mayer@ifs.tuwien.ac.at), at least, though. You can also make it public at the end of the competition, to show off :-)\n",
    "\n",
    "### Datasets\n",
    "We will use the following datasets:\n",
    "* Congressional Voting: a small dataset, a good entry point for your experiments (435 instances, 16 features)\n",
    "  * Kaggle page: https://www.kaggle.com/t/c04c953c596e48099d857129f53fcbdb\n",
    "* Amazon reviews: a dataset with many features (10k, extracted from text), but not that many instances (~800)\n",
    "  * Kaggle page: https://www.kaggle.com/t/0bd2ac297dc242478b5979d5ee772136\n",
    "\n",
    "### Submission\n",
    "The Kaggle competition will close on the day displayed in Kaggle. After that, you still have time to submit to Moodle. Your submission to Moodle shall contain:\n",
    "\n",
    "* A brief report, containing\n",
    "  * A description of the datasets, including a short analysis of the features.\n",
    "  * Details on the software you used for creating your solution\n",
    "  * The algorithms and parameters you tried\n",
    "  * The results you obtained on the locally split training/test set\n",
    "    * And a comparison to the results that you received on Kaggle - how large was the difference, did the rank of the classifiers change (i.e. the first on your training set, was it still the best on the test set on Kaggle?)\n",
    "* All the code needed to obtain your results\n",
    "* The solution files that you uploaded to Kaggle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Solution\n",
    "## Brief Description of Datasets\n",
    "\n",
    "### Congressional Voting\n",
    "#### Background\n",
    "The classification task relates to the prediction of voting behaviour in relation to opinions on certain political questions/topics.\n",
    "\n",
    "#### Dataset Features\n",
    "The dataset features boolean responses to 16 political topics or issues like allowing religious groups in schools of 219 people.\n",
    "Features are coded as 'y' and 'n' and are in most cases relatively evenly distributed.\n",
    "\n",
    "There missing data labeled as \"unknown\".\n",
    "\n",
    "The classes for this classification task is the voting behaviour of the respective persons, coded as \"democrat\" or \"republican\".\n",
    "\n",
    "### Amazon\n",
    "#### Background\n",
    "The classification task relates to language features of frequent authors of Amazon reviews.\n",
    "\n",
    "#### Dataset Features\n",
    "The dataset consists of 10 000 dimensions relating to language features with only 750 rows. The actual meaning of the data that can be used for prediction is unknown to the author.\n",
    "The fields are integer values which makes it likely that the fields represent frequencies or occurancies of specific language features.\n",
    "The distribution of these features are in most cases following a slightly skewed normal distribution (rechtssteile/linksschiefe Verteilung).\n",
    "\n",
    "There is no missing data.\n",
    "\n",
    "The classes for this classification task are the names of the authors of the reviews.\n",
    "\n",
    "\n",
    "## Software used\n",
    "The solutions were calculated on Python with Scikit Learn using a mixture of local Jupyter Notebooks (using Pycharm) and the Kaggle Notebooks\n",
    "\n",
    "While the Kaggle Notebooks provided a surprisingly powerful environment for data analysis and calculation of predictions,\n",
    "frequent disconnections and errors when using the notebooks for longer periods of time made it necessary to also use Jupyter\n",
    "locally on PyCharm.\n",
    "\n",
    "## Approaches used\n",
    "Main Approaches (with five folds each):\n",
    "* Naive Bayes\n",
    "* Decision Tree\n",
    "* Perceptron\n",
    "* Regression Models\n",
    "* SVM\n",
    "\n",
    "For the specific combinations of parameters tried, please see the following chapters.\n",
    "The following describes in detail the approach used as well as the selection of classifiers and the preparation of the data submission, especially the section \"Calculation Functions\".\n",
    "\n",
    "## Obtained Results\n",
    "### Congressional Voting\n",
    "The best results were found for a Decision Tree closely followed by a SVM solution:\n",
    "```\n",
    "classifier        DecisionTreeClassifier(max_depth=1, min_sample...\n",
    "arguments                              max Depth: 1, min Samples: 2\n",
    "mean_accuracy                                               0.96797\n",
    "mean_precision                                             0.963363\n",
    "mean_recall                                                0.973789\n",
    "accuracy             m: 0.967970401691332 std: 0.023305252083176783\n",
    "precision           m: 0.9633625730994153 std: 0.025403888401415272\n",
    "recall                m: 0.9737891737891738 std: 0.0190606594685786\n",
    "Name: 15, dtype: object\n",
    "```\n",
    "Solutions for SVM were good, irrespective of kernels used, i.e.:\n",
    "```\n",
    "classifier        SVC(C=100, degree=1, gamma=0.001, kernel='poly')\n",
    "arguments                                  Kernel: poly, Degree: 1\n",
    "mean_accuracy                                              0.96797\n",
    "mean_precision                                            0.963363\n",
    "mean_recall                                               0.973789\n",
    "accuracy            m: 0.967970401691332 std: 0.023305252083176783\n",
    "precision          m: 0.9633625730994153 std: 0.025403888401415272\n",
    "recall               m: 0.9737891737891738 std: 0.0190606594685786\n",
    "Name: 0, dtype: object\n",
    "```\n",
    "The mean accuracy of both the SVM solution and the Decision Tree Classifiers were close to those yielded during submission.\n",
    "\n",
    "One notable finding was that the Decision Tree classifier worked with max_depth=1, which means that responses to one question was sufficient to correctly assign 96% of people.\n",
    "\n",
    "For detailed results, please see the section \"Overall Results for Congressional Vote\"\n",
    "\n",
    "### Amazon\n",
    "\n",
    "For detailed results, please see the section \"Overall Results for Amazon\"\n",
    "\n",
    "### Helper Functions for Solution and Data Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# global Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#sk learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#Data reporting\n",
    "from IPython.display import display\n",
    "\n",
    "# Global definitions:\n",
    "overall_results_vote = []\n",
    "overall_results_amazon = []\n",
    "averaging_approach = 'macro'\n",
    "zero_division_approach = 0\n",
    "number_of_folds = 5\n",
    "scoring = {'Accuracy': make_scorer(accuracy_score),\n",
    "            'Precision': make_scorer(precision_score, average=averaging_approach, zero_division=zero_division_approach),\n",
    "            'Recall': make_scorer(recall_score, average=averaging_approach, zero_division=zero_division_approach)}\n",
    "\n",
    "# Helper functions\n",
    "def parse_k_fold_results(results):\n",
    "    return \"m: \" + str(np.average(results)) + \" std: \" + str(np.std(results))\n",
    "\n",
    "def parse_argument_tuple_as_string(argumentsTuple):\n",
    "    return \"max Depth: \" + str(argumentsTuple[0])  + \\\n",
    "           \", min Samples: \" + str(argumentsTuple[1])\n",
    "\n",
    "def calculate_results_holdout(classifier_used, X_train, X_test, y_train, y_test):\n",
    "    classifier_used.fit(X_train, y_train)\n",
    "\n",
    "    # predict the test set on our trained classifier\n",
    "    y_test_predicted = classifier_used.predict(X_test)\n",
    "\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    recall=metrics.recall_score(y_test, y_test_predicted)\n",
    "    precision = metrics.precision_score(y_test, y_test_predicted)\n",
    "\n",
    "    return pd.Series({\n",
    "            'classifier': str(classifier_used),\n",
    "            'arguments': \"\",\n",
    "            'accuracy':acc,\n",
    "            'precision':precision,\n",
    "            'recall':recall\n",
    "        })\n",
    "\n",
    "def calculate_results_cross_validate(classifier_used, description_used, data, target):\n",
    "   scores = cross_validate(classifier_used, data, target,\n",
    "                                scoring = scoring,\n",
    "                                cv = number_of_folds,\n",
    "                                error_score = 0)\n",
    "\n",
    "   return pd.Series({\n",
    "            'classifier': str(classifier_used),\n",
    "            'arguments': description_used,\n",
    "            'mean_accuracy': np.average(scores.get('test_Accuracy')),\n",
    "            'mean_precision': np.average(scores.get('test_Precision')),\n",
    "            'mean_recall': np.average(scores.get('test_Recall')),\n",
    "            'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "            'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "            'recall':parse_k_fold_results(scores.get('test_Recall'))\n",
    "        })\n",
    "\n",
    "def print_results(array, column_for_max, ascending=False):\n",
    "    df = pd.DataFrame(array)\n",
    "    df = df.sort_values(by=[column_for_max], ascending=False)\n",
    "    display('Results', df)\n",
    "\n",
    "    best = df.iloc[df[column_for_max].argmax()]\n",
    "    display(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculation Functions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### k-NN Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "def calculate_knn(data, target):\n",
    "    knn_results = []\n",
    "\n",
    "    n_neighbors = range(1,10,1)\n",
    "\n",
    "    for n in n_neighbors:\n",
    "        knn_classifier = neighbors.KNeighborsClassifier(n)\n",
    "        description = \"N = \" + str(n)\n",
    "        result = calculate_results_cross_validate(knn_classifier,\n",
    "                                                  description,\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        knn_results.append(result)\n",
    "    return knn_results\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bayes Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "def calculate_bayes(data, target):\n",
    "    bayes_results = []\n",
    "\n",
    "    alphas = np.arange(0.1,5,1)\n",
    "\n",
    "    for alpha in alphas:\n",
    "        classifier = naive_bayes.CategoricalNB(alpha = alpha)\n",
    "        description = \"Alpha = \" + str(alpha)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  description,\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        bayes_results.append(result)\n",
    "\n",
    "    return bayes_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Perceptron Calculation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def calculate_perceptron(data, target):\n",
    "    perceptron_results=[]\n",
    "    classifier = linear_model.Perceptron()\n",
    "    description = \"No additional args.\"\n",
    "    result = calculate_results_cross_validate(classifier,\n",
    "                                              description,\n",
    "                                              data,\n",
    "                                              target)\n",
    "    perceptron_results.append(result)\n",
    "    return perceptron_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Decision Tree Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import itertools\n",
    "\n",
    "def calculate_decision_tree(data, target):\n",
    "    # Parameters for the decision tree\n",
    "    max_depth_arguments = range(1, 10, 2)\n",
    "    min_samples_leaf_arguments = [2,20,50,100]\n",
    "    argumentTuples = list(itertools.product(max_depth_arguments,\n",
    "                                            min_samples_leaf_arguments))\n",
    "    decision_tree_results = []\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        max_depth = argumentTuple[0]\n",
    "        min_samples_leaf = argumentTuple[1]\n",
    "\n",
    "        classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                 max_depth = max_depth,\n",
    "                                                 min_samples_leaf = min_samples_leaf,\n",
    "                                                 splitter = 'best')\n",
    "        #result = calculate_results_holdout(classifier, X_train, X_test, y_train, y_test)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  parse_argument_tuple_as_string(argumentTuple),\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        decision_tree_results.append(result)\n",
    "    return decision_tree_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def calculate_logistic_regression(data, target):\n",
    "    penalty = [\"none\", \"l2\"]#, \"l1\", \"elasticnet\"]\n",
    "    class_weight = [\"balanced\"]\n",
    "    solvers = [\"newton-cg\"]#, \"lbfgs\", \"liblinear\"]\n",
    "\n",
    "    argumentTuples = list(itertools.product(solvers, penalty, class_weight))\n",
    "\n",
    "    regression_results = []\n",
    "\n",
    "    for tuple in argumentTuples:\n",
    "        solver = tuple[0]\n",
    "        penalty = tuple[1]\n",
    "        class_weight = tuple[2]\n",
    "        classifier = linear_model.LogisticRegression(solver = solver, class_weight = class_weight, penalty = penalty)\n",
    "\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  solver + \", \" + penalty,\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        regression_results.append(result)\n",
    "    return regression_results\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import itertools\n",
    "\n",
    "def calculate_svm(data, target):\n",
    "    kernels = [\"poly\", \"rbf\"]#{\"linear\", \"poly\", \"sigmoid\", \"rbf\"}\n",
    "    gamma = [0.001, \"scale\", \"auto\"]\n",
    "    c = [100]\n",
    "    degree = 1#range(1, 10, 1)\n",
    "\n",
    "    argumentTuples = list(itertools.product(kernels,\n",
    "                                            gamma,\n",
    "                                            c,\n",
    "                                            degree))\n",
    "    svm_results = []\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        kernel = argumentTuple[0]\n",
    "        gamma = argumentTuple[1]\n",
    "        c = argumentTuple[2]\n",
    "        degree = argumentTuple[3]\n",
    "\n",
    "        classifier = svm.SVC(kernel = kernel, gamma = gamma, C = c, degree = degree)\n",
    "\n",
    "        #result = calculate_results_holdout(classifier, X_train, X_test, y_train, y_test)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  \"Kernel: \" + kernel + \", Degree: \" + str(degree),\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        svm_results.append(result)\n",
    "    return svm_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congressional Voting\n",
    "\n",
    "### Preparation of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Original Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID       class handicapped-infants water-project-cost-sharing  \\\n0    213    democrat                   n                          n   \n1     94    democrat                   y                          n   \n2    188    democrat                   y                          n   \n3     61    democrat                   y                          y   \n4    184    democrat                 NaN                        NaN   \n..   ...         ...                 ...                        ...   \n213  250    democrat                   y                          n   \n214   26    democrat                   y                          n   \n215  110    democrat                   y                        NaN   \n216   34  republican                   n                          y   \n217  314  republican                   n                          y   \n\n    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n0                                   y                    n               n   \n1                                   y                    n               n   \n2                                   y                    n               n   \n3                                   y                    n               n   \n4                                 NaN                  NaN             NaN   \n..                                ...                  ...             ...   \n213                                 y                    n               n   \n214                                 y                    n               n   \n215                                 y                    n               n   \n216                                 n                    y               y   \n217                                 y                    y               y   \n\n    religious-groups-in-schools anti-satellite-test-ban  \\\n0                             n                       y   \n1                             n                       y   \n2                             n                       y   \n3                           NaN                       y   \n4                           NaN                     NaN   \n..                          ...                     ...   \n213                           n                       y   \n214                           n                       y   \n215                           n                       y   \n216                           y                       n   \n217                           y                       n   \n\n    aid-to-nicaraguan-contras mx-missile immigration  \\\n0                           y          y           n   \n1                           n          y           y   \n2                           y          y           n   \n3                           y          y           y   \n4                         NaN          y         NaN   \n..                        ...        ...         ...   \n213                         y        NaN           n   \n214                         y          y           y   \n215                         y          y           n   \n216                         n          n           n   \n217                         n          n           y   \n\n    synfuels-crporation-cutback education-spending superfund-right-to-sue  \\\n0                             y                  n                      n   \n1                             y                  n                      n   \n2                             n                  n                      n   \n3                             n                  n                      n   \n4                           NaN                NaN                    NaN   \n..                          ...                ...                    ...   \n213                           y                  n                      n   \n214                           n                  n                      n   \n215                           n                  n                      n   \n216                           n                  y                      y   \n217                           n                  y                      y   \n\n    crime duty-free-exports export-administration-act-south-africa  \n0       n                 y                                      y  \n1       n                 y                                      y  \n2       n                 y                                    NaN  \n3       n                 y                                    NaN  \n4     NaN               NaN                                    NaN  \n..    ...               ...                                    ...  \n213     n                 y                                      y  \n214     n                 y                                      y  \n215     n                 y                                    NaN  \n216     y                 n                                      y  \n217     y                 n                                      y  \n\n[218 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>213</td>\n      <td>democrat</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>94</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>188</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>184</td>\n      <td>democrat</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>250</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>26</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>110</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>34</td>\n      <td>republican</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>314</td>\n      <td>republican</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n    </tr>\n  </tbody>\n</table>\n<p>218 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\sklearn\\impute\\_iterative.py:670: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Recoded Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID class handicapped-infants water-project-cost-sharing  \\\n0    213     2                   0                          0   \n1     94     2                   1                          0   \n2    188     2                   1                          0   \n3     61     2                   1                          1   \n4    184     2                   1                          0   \n..   ...   ...                 ...                        ...   \n213  250     2                   1                          0   \n214   26     2                   1                          0   \n215  110     2                   1                          0   \n216   34     3                   0                          1   \n217  314     3                   0                          1   \n\n    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n0                                   1                    0               0   \n1                                   1                    0               0   \n2                                   1                    0               0   \n3                                   1                    0               0   \n4                                   1                    0               0   \n..                                ...                  ...             ...   \n213                                 1                    0               0   \n214                                 1                    0               0   \n215                                 1                    0               0   \n216                                 0                    1               1   \n217                                 1                    1               1   \n\n    religious-groups-in-schools anti-satellite-test-ban  \\\n0                             0                       1   \n1                             0                       1   \n2                             0                       1   \n3                             0                       1   \n4                             0                       1   \n..                          ...                     ...   \n213                           0                       1   \n214                           0                       1   \n215                           0                       1   \n216                           1                       0   \n217                           1                       0   \n\n    aid-to-nicaraguan-contras mx-missile immigration  \\\n0                           1          1           0   \n1                           0          1           1   \n2                           1          1           0   \n3                           1          1           1   \n4                           1          1           1   \n..                        ...        ...         ...   \n213                         1          1           0   \n214                         1          1           1   \n215                         1          1           0   \n216                         0          0           0   \n217                         0          0           1   \n\n    synfuels-crporation-cutback education-spending superfund-right-to-sue  \\\n0                             1                  0                      0   \n1                             1                  0                      0   \n2                             0                  0                      0   \n3                             0                  0                      0   \n4                             0                  0                      0   \n..                          ...                ...                    ...   \n213                           1                  0                      0   \n214                           0                  0                      0   \n215                           0                  0                      0   \n216                           0                  1                      1   \n217                           0                  1                      1   \n\n    crime duty-free-exports export-administration-act-south-africa  \n0       0                 1                                      1  \n1       0                 1                                      1  \n2       0                 1                                      1  \n3       0                 1                                      1  \n4       0                 1                                      1  \n..    ...               ...                                    ...  \n213     0                 1                                      1  \n214     0                 1                                      1  \n215     0                 1                                      1  \n216     1                 0                                      1  \n217     1                 0                                      1  \n\n[218 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>213</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>94</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>188</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>184</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>250</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>26</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>110</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>34</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>314</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>218 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Data: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "    handicapped-infants water-project-cost-sharing  \\\n0                     0                          0   \n1                     1                          0   \n2                     1                          0   \n3                     1                          1   \n4                     1                          0   \n..                  ...                        ...   \n213                   1                          0   \n214                   1                          0   \n215                   1                          0   \n216                   0                          1   \n217                   0                          1   \n\n    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n0                                   1                    0               0   \n1                                   1                    0               0   \n2                                   1                    0               0   \n3                                   1                    0               0   \n4                                   1                    0               0   \n..                                ...                  ...             ...   \n213                                 1                    0               0   \n214                                 1                    0               0   \n215                                 1                    0               0   \n216                                 0                    1               1   \n217                                 1                    1               1   \n\n    religious-groups-in-schools anti-satellite-test-ban  \\\n0                             0                       1   \n1                             0                       1   \n2                             0                       1   \n3                             0                       1   \n4                             0                       1   \n..                          ...                     ...   \n213                           0                       1   \n214                           0                       1   \n215                           0                       1   \n216                           1                       0   \n217                           1                       0   \n\n    aid-to-nicaraguan-contras mx-missile immigration  \\\n0                           1          1           0   \n1                           0          1           1   \n2                           1          1           0   \n3                           1          1           1   \n4                           1          1           1   \n..                        ...        ...         ...   \n213                         1          1           0   \n214                         1          1           1   \n215                         1          1           0   \n216                         0          0           0   \n217                         0          0           1   \n\n    synfuels-crporation-cutback education-spending superfund-right-to-sue  \\\n0                             1                  0                      0   \n1                             1                  0                      0   \n2                             0                  0                      0   \n3                             0                  0                      0   \n4                             0                  0                      0   \n..                          ...                ...                    ...   \n213                           1                  0                      0   \n214                           0                  0                      0   \n215                           0                  0                      0   \n216                           0                  1                      1   \n217                           0                  1                      1   \n\n    crime duty-free-exports export-administration-act-south-africa  \n0       0                 1                                      1  \n1       0                 1                                      1  \n2       0                 1                                      1  \n3       0                 1                                      1  \n4       0                 1                                      1  \n..    ...               ...                                    ...  \n213     0                 1                                      1  \n214     0                 1                                      1  \n215     0                 1                                      1  \n216     1                 0                                      1  \n217     1                 0                                      1  \n\n[218 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>218 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Target: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0      2\n1      2\n2      2\n3      2\n4      2\n      ..\n213    2\n214    2\n215    2\n216    3\n217    3\nName: class, Length: 218, dtype: category\nCategories (2, int64): [2, 3]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Recode values for predicting variables\n",
    "def recode_voting_data(dataset):\n",
    "    dataset = dataset.replace('y', 1)\\\n",
    "        .replace('n', 0)\\\n",
    "        .replace('democrat', 2)\\\n",
    "        .replace('republican', 3)\n",
    "    dataset.loc[:, dataset.columns != \"ID\"] = dataset.loc[:, dataset.columns != \"ID\"].astype('category')\n",
    "    return pd.DataFrame(dataset, columns=dataset.columns)\n",
    "\n",
    "#Imput missing values\n",
    "def input_missing_values(data):\n",
    "    columns = data.columns\n",
    "    imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "    imp.fit(data.loc[:, data.columns != \"ID\"])\n",
    "    data.loc[:, data.columns != \"ID\"] = np.round(imp.transform(data.loc[:, data.columns != \"ID\"]))\n",
    "    data.loc[:, data.columns != \"ID\"] = data.loc[:, data.columns != \"ID\"].apply(lambda x: x.astype('int'))\n",
    "    data.loc[:, data.columns != \"ID\"] = data.loc[:, data.columns != \"ID\"].astype('category')\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "#Read Data\n",
    "votingDataLearnOriginal = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.lrn.csv\", na_values='unknown')\n",
    "votingDataSolutionExample = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.sol.ex.csv\", na_values='unknown')\n",
    "votingDataTest = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.tes.csv\", na_values='unknown')\n",
    "display(\"Original Data\", votingDataLearnOriginal)\n",
    "\n",
    "#Recode values\n",
    "votingDataLearn = recode_voting_data(votingDataLearnOriginal)\n",
    "votingDataLearn = input_missing_values(votingDataLearn)\n",
    "\n",
    "display(\"Recoded Data\", votingDataLearn)\n",
    "\n",
    "display(\"Data: \", votingDataLearn[votingDataLearn.columns[2:18]])\n",
    "display(\"Target: \", votingDataLearn[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Exploration - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'[2]' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-28-7c71a4830c61>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mvotingDataLearnOriginal\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue_counts\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkind\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'bar'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;31m#votingDataLearnOriginal.apply(lambda x: x.value_counts().plot(kind='bar'), axis = 'columns')\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mf:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1766\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1767\u001B[0m             \u001B[0mmaybe_callable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_if_callable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1768\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmaybe_callable\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1769\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1770\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_is_scalar_access\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mf:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1910\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mslice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1911\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_key\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1912\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_slice_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1913\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mcom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_bool_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1914\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getbool_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mf:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_get_slice_axis\u001B[1;34m(self, slice_obj, axis)\u001B[0m\n\u001B[0;32m   1795\u001B[0m         \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1796\u001B[0m         indexer = labels.slice_indexer(\n\u001B[1;32m-> 1797\u001B[1;33m             \u001B[0mslice_obj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mslice_obj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstop\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mslice_obj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkind\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1798\u001B[0m         )\n\u001B[0;32m   1799\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mf:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mslice_indexer\u001B[1;34m(self, start, end, step, kind)\u001B[0m\n\u001B[0;32m   4710\u001B[0m         \u001B[0mslice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4711\u001B[0m         \"\"\"\n\u001B[1;32m-> 4712\u001B[1;33m         \u001B[0mstart_slice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend_slice\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mslice_locs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkind\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkind\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4713\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4714\u001B[0m         \u001B[1;31m# return a slice\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mf:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mslice_locs\u001B[1;34m(self, start, end, step, kind)\u001B[0m\n\u001B[0;32m   4929\u001B[0m         \u001B[0mend_slice\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4930\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mend\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4931\u001B[1;33m             \u001B[0mend_slice\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_slice_bound\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"right\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkind\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4932\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mend_slice\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4933\u001B[0m             \u001B[0mend_slice\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mf:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_slice_bound\u001B[1;34m(self, label, side, kind)\u001B[0m\n\u001B[0;32m   4839\u001B[0m         \u001B[1;31m# we need to look up the label\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4840\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4841\u001B[1;33m             \u001B[0mslc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4842\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4843\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mf:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m    351\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    352\u001B[0m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 353\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtolerance\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtolerance\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    354\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    355\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mAppender\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_index_shared_docs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"get_indexer\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mf:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   2644\u001B[0m                 )\n\u001B[0;32m   2645\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2646\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2647\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2648\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_cast_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: '[2]' is an invalid key"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### k-NN - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_results_vote = calculate_knn(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                 votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(knn_results_vote)\n",
    "\n",
    "print_results(knn_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bayes - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bayes_results_vote = calculate_bayes(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                     votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(bayes_results_vote)\n",
    "\n",
    "print_results(bayes_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "perceptron_results_vote = calculate_perceptron(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                               votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(perceptron_results_vote)\n",
    "\n",
    "print_results(perceptron_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "decision_tree_results_vote = calculate_decision_tree(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                                     votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(decision_tree_results_vote)\n",
    "\n",
    "print_results(decision_tree_results_vote, \"mean_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_results_vote = calculate_svm(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                 votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(svm_results_vote)\n",
    "\n",
    "print_results(svm_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overall Results for Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_results(overall_results_vote, \"mean_accuracy\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train submission file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Required Imports\n",
    "from sklearn import svm\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Recode values for predicting variables\n",
    "def recode_voting_data(dataset):\n",
    "    dataset = dataset.replace('y', 1)\\\n",
    "        .replace('n', 0)\n",
    "    dataset[dataset.columns[1:18]] = dataset[dataset.columns[1:18]].astype('category')\n",
    "    return pd.DataFrame(dataset, columns=dataset.columns)\n",
    "\n",
    "#Imput missing values\n",
    "def input_missing_values(data, iterative_imputer):\n",
    "    columns = data.columns\n",
    "    data.loc[:, data.columns != \"ID\"] = np.round(imp.transform(data.loc[:, data.columns != \"ID\"]))\n",
    "    data.loc[:, data.columns != \"ID\"] = data.loc[:, data.columns != \"ID\"].apply(lambda x: x.astype('int'))\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "#Read Data\n",
    "votingDataLearn = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.lrn.csv\", na_values='unknown')\n",
    "votingDataTest = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.tes.csv\", na_values='unknown')\n",
    "\n",
    "#Extract target variable\n",
    "votingDataLearn = votingDataLearn.replace('democrat', 2)\\\n",
    "    .replace('republican', 3)\n",
    "\n",
    "y = votingDataLearn[\"class\"]\n",
    "X = pd.DataFrame(votingDataLearn.drop([\"ID\", \"class\"], axis=1))\n",
    "\n",
    "#Recode Variables\n",
    "X = recode_voting_data(X)\n",
    "votingDataTest = recode_voting_data(votingDataTest)\n",
    "\n",
    "#Input missing values\n",
    "imp = IterativeImputer(max_iter=50, random_state=0)\n",
    "combined_data = X.append(votingDataTest)\n",
    "imp.fit(combined_data.loc[:, combined_data.columns != \"ID\"])\n",
    "X = input_missing_values(X, imp)\n",
    "votingDataTest = input_missing_values(votingDataTest, imp)\n",
    "\n",
    "#Calculate Model\n",
    "classifier = svm.SVC(kernel = \"rbf\", gamma=0.001, C=100)\n",
    "#classifier = tree.DecisionTreeClassifier(max_depth=1)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "#Predict the Test Data\n",
    "votingDataTest[\"class\"] = classifier.predict(votingDataTest[votingDataTest.columns[1:18]])\n",
    "\n",
    "#Recode to required output\n",
    "votingDataTest[\"class\"].replace({2: \"democrat\", 3: \"republican\"}, inplace=True)\n",
    "display(\"Finally recoded back: \", votingDataTest[[\"ID\", \"class\"]])\n",
    "votingDataTest[[\"ID\", \"class\"]].to_csv(\"solution_voting.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Amazon\n",
    "\n",
    "### Preparation of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#Read Data\n",
    "amazonDataLearn = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.lrn.csv\")\n",
    "amazonDataSolutionExample = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.sol.ex.csv\")\n",
    "amazonDataTest = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.tes.csv\")\n",
    "display(\"Original Data\", amazonDataLearn)\n",
    "\n",
    "#Recode values\n",
    "#For One Hot Encoding of Class\n",
    "#amazonDataLearn = pd.concat([amazonDataLearn, pd.get_dummies(amazonDataLearn[\"Class\"], prefix='author_',drop_first=False)], axis=1)\n",
    "#amazonDataLearn.drop(['Class'],axis=1, inplace=True)\n",
    "#names_target = amazonDataLearn.loc[:, amazonDataLearn.columns.str.startswith('author_')]\n",
    "#amazonDataLearn[names_target.columns] = amazonDataLearn[names_target.columns].apply(lambda x: x.astype('category'))\n",
    "\n",
    "# For Label Encoding\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#le.fit(amazonDataLearn['Class'])\n",
    "#amazonDataLearn['Class'] = le.transform(amazonDataLearn['Class'])\n",
    "#amazonDataLearn['Class'] = amazonDataLearn['Class'].astype('category')\n",
    "\n",
    "names_data = amazonDataLearn.loc[:, amazonDataLearn.columns.str.startswith('V')]\n",
    "#amazonDataLearn[0:10000] = amazonDataLearn[0:10000].apply(lambda x: x.astype('int'))\n",
    "\n",
    "# Normalize data\n",
    "def normalize_values(data):\n",
    "    columns = data.columns\n",
    "    data = preprocessing.Normalizer().fit_transform(data)\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "display(\"Recoded Data\", amazonDataLearn)\n",
    "\n",
    "X_amazon = normalize_values(amazonDataLearn[names_data.columns])\n",
    "y_amazon = amazonDataLearn[\"Class\"]\n",
    "\n",
    "display(\"Data: \", X_amazon)\n",
    "display(\"Target: \", y_amazon)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### k-NN Calculation - Amazon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_results_amazon = calculate_knn(X_amazon,\n",
    "                                   y_amazon)\n",
    "overall_results_amazon.extend(knn_results_amazon)\n",
    "\n",
    "print_results(knn_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "perceptron_results_amazon = calculate_perceptron(X_amazon,\n",
    "                                                 y_amazon)\n",
    "overall_results_amazon.extend(perceptron_results_amazon)\n",
    "\n",
    "print_results(perceptron_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decision_tree_results_amazon = calculate_decision_tree(X_amazon,\n",
    "                                                       y_amazon)\n",
    "overall_results_amazon.extend(decision_tree_results_amazon)\n",
    "\n",
    "print_results(decision_tree_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regression_results_amazon = calculate_logistic_regression(X_amazon,\n",
    "                                                          y_amazon)\n",
    "overall_results_amazon.extend(regression_results_amazon)\n",
    "\n",
    "print_results(regression_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_results_amazon = calculate_svm(X_amazon,\n",
    "                                   y_amazon)\n",
    "overall_results_amazon.extend(svm_results_amazon)\n",
    "\n",
    "print_results(svm_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overall Results for Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_results(overall_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Read Data\n",
    "amazon_data_learn = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.lrn.csv\")\n",
    "amazon_data_test = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.tes.csv\")\n",
    "\n",
    "# Label Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(amazon_data_learn[\"Class\"])\n",
    "#amazon_data_learn[\"Class\"] = le.transform(amazon_data_learn[\"Class\"])\n",
    "amazon_data_learn[\"Class\"] = amazon_data_learn[\"Class\"].astype(\"category\")\n",
    "\n",
    "names_data = amazon_data_learn.loc[:, amazon_data_learn.columns.str.startswith(\"V\")]\n",
    "\n",
    "display(\"Recoded Data\", amazon_data_learn)\n",
    "y = amazon_data_learn[\"Class\"]\n",
    "X = pd.DataFrame(amazon_data_learn.drop([\"ID\", \"Class\"], axis=1))\n",
    "X = X[names_data.columns]\n",
    "\n",
    "#Normalize data\n",
    "def normalize_values(data):\n",
    "    columns = data.columns\n",
    "    data = preprocessing.Normalizer().fit_transform(data)\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "X_norm = normalize_values(X)\n",
    "test_X = normalize_values(amazon_data_test[names_data.columns])\n",
    "\n",
    "display(\"Data Normalized: \", X_norm)\n",
    "display(\"Target: \", y)\n",
    "display(\"Test Dataset: \", amazon_data_test)\n",
    "display(\"Test Dataset, Predictors: \", amazon_data_test[names_data.columns])\n",
    "display(\"Test Dataset, Normalized: \", test_X)\n",
    "\n",
    "#Calculate Model\n",
    "\n",
    "#classifier = svm.SVC(C=101, kernel='poly')\n",
    "classifier = linear_model.LogisticRegression(solver = \"newton-cg\",\n",
    "                                             class_weight = \"balanced\",\n",
    "                                             penalty = \"none\")\n",
    "classifier.fit(X_norm, y)\n",
    "\n",
    "#Predict the Test Data\n",
    "amazon_data_test[\"Class\"] = classifier.predict(test_X)\n",
    "\n",
    "display(\"Finally recoded: \", amazon_data_test[[\"ID\", \"Class\"]])\n",
    "amazon_data_test[[\"ID\", \"Class\"]].to_csv(\"solution_amazon.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}