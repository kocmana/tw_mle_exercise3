{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MLE - Exercise 3 - Kaggle Competition\n",
    "## Andreas Kocman (se19m024)\n",
    "\n",
    "\n",
    "This exercise is in the form of a Kaggle competition. A few quick details on Kaggle & the competition format:\n",
    "\n",
    "## Kaggle\n",
    "* Kaggle (https://en.wikipedia.org/wiki/Kaggle) is a platform that allows a competition for a certain data set. Participants submit their prediction on a test set, and will get automated scoring on their results, and will enter the leaderboard.\n",
    "* From Kaggle, you will be able to obtain a labelled training set, and an unlabelled test set.\n",
    "* You can submit multiple entries to Kaggle; for each entry, you need to provide details on how you achieved the results - which software and which version of the software, which operating system, which algorithms, and which parameter settings for these algorithms; further, any processing applied to the data before training/predicting. There is a specific \"description\" field when submitting, you should fill in this information there, and you also need to include this description and the actual submission file in your final submission to Moodle.\n",
    "* To submit to Kaggle, you need to create a specific submission file, which contains the predictions you obtain on the test set. Computing an aggregated evaluation criterion is done automatically by Kaggle\n",
    "* The format of your submission is rather simple - it is a comma-separated file, where the first column is the identifier of the item that you are predicting, and the second column is the class you are predicting for that item. The first line should include a header, and is should use the names provided in the training set. An example is below:\n",
    "```\n",
    "ID,class\n",
    "911366,B\n",
    "852781,B\n",
    "89524,B\n",
    "857438,B\n",
    "905686,B\n",
    "```\n",
    "* There is a limit of 7 submissions per day; finally, you also need to select your top 7 submissions to be counted in the competition\n",
    "* Before you submit, you should evaluate the classifiers \"locally\" on your training set, i.e. by splitting that again in a training & test set (or using cross validation), to select a number of fitting algorithms & parameters. Then re-train your best models on the full local training set, and generate the predictions for the test set.\n",
    "* Evaluation in Kaggle is split in two types of leaderboards - the private and public one. Here, the data is split into 50% / 50%, and as soon as you upload, you will know your results on one of these splits.\n",
    "* The final results will only be visible once the competition closes, and as it is computed on a different split, might be slightly different than what you see initially (e.g. this is similar to a training/test/validation split)\n",
    "* As it is a competition, there will be bonus points for the top 3 submissions.\n",
    "* As reproducible science is great, there will be additional bonus points for submissions that use a notebook within the Kaggle competition (note: this was / partially still is called a \"kernel\" inside the Kaggle competition; Kernel obviously was a confusing term here, as it basically refers to code being executed in the environment of Kaggle itself (e.g. a jupyter notebook, or also a python or R script), and they seem to have realized that, and renamed it). see https://www.kaggle.com/notebooks or https://www.kaggle.com/getting-started/44939. You can first work locally, and then port your code to the notebook version. In Kaggle, your notebook will initially be private. Please share it with me (mayer@ifs.tuwien.ac.at), at least, though. You can also make it public at the end of the competition, to show off :-)\n",
    "\n",
    "## Datasets\n",
    "We will use the following datasets:\n",
    "* Congressional Voting: a small dataset, a good entry point for your experiments (435 instances, 16 features)\n",
    "  * Kaggle page: https://www.kaggle.com/t/c04c953c596e48099d857129f53fcbdb\n",
    "* Amazon reviews: a dataset with many features (10k, extracted from text), but not that many instances (~800)\n",
    "  * Kaggle page: https://www.kaggle.com/t/0bd2ac297dc242478b5979d5ee772136\n",
    "\n",
    "## Submission\n",
    "The Kaggle competition will close on the day displayed in Kaggle. After that, you still have time to submit to Moodle. Your submission to Moodle shall contain:\n",
    "\n",
    "* A brief report, containing\n",
    "  * A description of the datasets, including a short analysis of the features.\n",
    "  * Details on the software you used for creating your solution\n",
    "  * The algorithms and parameters you tried\n",
    "  * The results you obtained on the locally split training/test set\n",
    "    * And a comparison to the results that you received on Kaggle - how large was the difference, did the rank of the classifiers change (i.e. the first on your training set, was it still the best on the test set on Kaggle?)\n",
    "* All the code needed to obtain your results\n",
    "* The solution files that you uploaded to Kaggle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Solution\n",
    "\n",
    "## Helper Functions for Solution and Data Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# global Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#sk learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#Data reporting\n",
    "from IPython.display import display\n",
    "\n",
    "# Global definitions:\n",
    "overall_results_vote = []\n",
    "overall_results_amazon = []\n",
    "averaging_approach = 'macro'\n",
    "zero_division_approach = 0\n",
    "number_of_folds = 2\n",
    "scoring = {'Accuracy': make_scorer(accuracy_score),\n",
    "            'Precision': make_scorer(precision_score, average=averaging_approach, zero_division=zero_division_approach),\n",
    "            'Recall': make_scorer(recall_score, average=averaging_approach, zero_division=zero_division_approach)}\n",
    "\n",
    "# Helper functions\n",
    "def parse_k_fold_results(results):\n",
    "    return \"m: \" + str(np.average(results)) + \" std: \" + str(np.std(results))\n",
    "\n",
    "def parse_argument_tuple_as_string(argumentsTuple):\n",
    "    return \"max Depth: \" + str(argumentsTuple[0])  + \\\n",
    "           \", min Samples: \" + str(argumentsTuple[1])\n",
    "\n",
    "def calculate_results_holdout(classifier_used, X_train, X_test, y_train, y_test):\n",
    "    classifier_used.fit(X_train, y_train)\n",
    "\n",
    "    # predict the test set on our trained classifier\n",
    "    y_test_predicted = classifier_used.predict(X_test)\n",
    "\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    recall=metrics.recall_score(y_test, y_test_predicted)\n",
    "    precision = metrics.precision_score(y_test, y_test_predicted)\n",
    "\n",
    "    return pd.Series({\n",
    "            'classifier': str(classifier_used),\n",
    "            'arguments': \"\",\n",
    "            'accuracy':acc,\n",
    "            'precision':precision,\n",
    "            'recall':recall\n",
    "        })\n",
    "\n",
    "def calculate_results_cross_validate(classifier_used, description_used, data, target):\n",
    "   scores = cross_validate(classifier_used, data, target,\n",
    "                                scoring = scoring,\n",
    "                                cv = number_of_folds,\n",
    "                                error_score = 0)\n",
    "\n",
    "   return pd.Series({\n",
    "            'classifier': str(classifier_used),\n",
    "            'arguments': description_used,\n",
    "            'mean_accuracy': np.average(scores.get('test_Accuracy')),\n",
    "            'mean_precision': np.average(scores.get('test_Precision')),\n",
    "            'mean_recall': np.average(scores.get('test_Recall')),\n",
    "            'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "            'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "            'recall':parse_k_fold_results(scores.get('test_Recall'))\n",
    "        })\n",
    "\n",
    "def print_results(array, column_for_max, ascending=False):\n",
    "    df = pd.DataFrame(array)\n",
    "    df = df.sort_values(by=[column_for_max], ascending=False)\n",
    "    display('Results', df)\n",
    "\n",
    "    best = df.iloc[df[column_for_max].argmax()]\n",
    "    display(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculation Functions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### k-NN Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "def calculate_knn(data, target):\n",
    "    knn_results = []\n",
    "\n",
    "    n_neighbors = range(1,10,1)\n",
    "\n",
    "    for n in n_neighbors:\n",
    "        knn_classifier = neighbors.KNeighborsClassifier(n)\n",
    "        description = \"N = \" + str(n)\n",
    "        result = calculate_results_cross_validate(knn_classifier,\n",
    "                                                  description,\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        knn_results.append(result)\n",
    "    return knn_results\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bayes Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "def calculate_bayes(data, target):\n",
    "    bayes_results = []\n",
    "\n",
    "    alphas = np.arange(0.1,5,1)\n",
    "\n",
    "    for alpha in alphas:\n",
    "        classifier = naive_bayes.CategoricalNB(alpha = alpha)\n",
    "        description = \"Alpha = \" + str(alpha)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  description,\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        bayes_results.append(result)\n",
    "\n",
    "    return bayes_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Perceptron Calculation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def calculate_perceptron(data, target):\n",
    "    perceptron_results=[]\n",
    "    classifier = linear_model.Perceptron()\n",
    "    description = \"No additional args.\"\n",
    "    result = calculate_results_cross_validate(classifier,\n",
    "                                              description,\n",
    "                                              data,\n",
    "                                              target)\n",
    "    perceptron_results.append(result)\n",
    "    return perceptron_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Decision Tree Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import itertools\n",
    "\n",
    "def calculate_decision_tree(data, target):\n",
    "    # Parameters for the decision tree\n",
    "    max_depth_arguments = range(1, 10, 2)\n",
    "    min_samples_leaf_arguments = [2,20,50,100]\n",
    "    argumentTuples = list(itertools.product(max_depth_arguments,\n",
    "                                            min_samples_leaf_arguments))\n",
    "    decision_tree_results = []\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        max_depth = argumentTuple[0]\n",
    "        min_samples_leaf = argumentTuple[1]\n",
    "\n",
    "        classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                 max_depth = max_depth,\n",
    "                                                 min_samples_leaf = min_samples_leaf,\n",
    "                                                 splitter = 'best')\n",
    "        #result = calculate_results_holdout(classifier, X_train, X_test, y_train, y_test)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  parse_argument_tuple_as_string(argumentTuple),\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        decision_tree_results.append(result)\n",
    "    return decision_tree_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import itertools\n",
    "\n",
    "def calculate_svm(data, target):\n",
    "    kernels = [\"poly\", \"rbf\"]#{\"linear\", \"poly\", \"sigmoid\", \"rbf\"}\n",
    "    gamma = [0.001, \"scale\", \"auto\"]\n",
    "    c = [100]\n",
    "    degree = range(1, 10, 1)\n",
    "\n",
    "    argumentTuples = list(itertools.product(kernels,\n",
    "                                            gamma,\n",
    "                                            c,\n",
    "                                            degree))\n",
    "    svm_results = []\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        kernel = argumentTuple[0]\n",
    "        gamma = argumentTuple[1]\n",
    "        c = argumentTuple[2]\n",
    "        degree = argumentTuple[3]\n",
    "\n",
    "        classifier = svm.SVC(kernel = kernel, gamma = gamma, C = c, degree = degree)\n",
    "\n",
    "        #result = calculate_results_holdout(classifier, X_train, X_test, y_train, y_test)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  \"Kernel: \" + kernel + \", Degree: \" + str(degree),\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        svm_results.append(result)\n",
    "    return svm_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congressional Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Original Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID       class handicapped-infants water-project-cost-sharing  \\\n0    213    democrat                   n                          n   \n1     94    democrat                   y                          n   \n2    188    democrat                   y                          n   \n3     61    democrat                   y                          y   \n4    184    democrat                 NaN                        NaN   \n..   ...         ...                 ...                        ...   \n213  250    democrat                   y                          n   \n214   26    democrat                   y                          n   \n215  110    democrat                   y                        NaN   \n216   34  republican                   n                          y   \n217  314  republican                   n                          y   \n\n    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n0                                   y                    n               n   \n1                                   y                    n               n   \n2                                   y                    n               n   \n3                                   y                    n               n   \n4                                 NaN                  NaN             NaN   \n..                                ...                  ...             ...   \n213                                 y                    n               n   \n214                                 y                    n               n   \n215                                 y                    n               n   \n216                                 n                    y               y   \n217                                 y                    y               y   \n\n    religious-groups-in-schools anti-satellite-test-ban  \\\n0                             n                       y   \n1                             n                       y   \n2                             n                       y   \n3                           NaN                       y   \n4                           NaN                     NaN   \n..                          ...                     ...   \n213                           n                       y   \n214                           n                       y   \n215                           n                       y   \n216                           y                       n   \n217                           y                       n   \n\n    aid-to-nicaraguan-contras mx-missile immigration  \\\n0                           y          y           n   \n1                           n          y           y   \n2                           y          y           n   \n3                           y          y           y   \n4                         NaN          y         NaN   \n..                        ...        ...         ...   \n213                         y        NaN           n   \n214                         y          y           y   \n215                         y          y           n   \n216                         n          n           n   \n217                         n          n           y   \n\n    synfuels-crporation-cutback education-spending superfund-right-to-sue  \\\n0                             y                  n                      n   \n1                             y                  n                      n   \n2                             n                  n                      n   \n3                             n                  n                      n   \n4                           NaN                NaN                    NaN   \n..                          ...                ...                    ...   \n213                           y                  n                      n   \n214                           n                  n                      n   \n215                           n                  n                      n   \n216                           n                  y                      y   \n217                           n                  y                      y   \n\n    crime duty-free-exports export-administration-act-south-africa  \n0       n                 y                                      y  \n1       n                 y                                      y  \n2       n                 y                                    NaN  \n3       n                 y                                    NaN  \n4     NaN               NaN                                    NaN  \n..    ...               ...                                    ...  \n213     n                 y                                      y  \n214     n                 y                                      y  \n215     n                 y                                    NaN  \n216     y                 n                                      y  \n217     y                 n                                      y  \n\n[218 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>213</td>\n      <td>democrat</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>94</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>188</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>184</td>\n      <td>democrat</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>250</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>26</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>110</td>\n      <td>democrat</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>34</td>\n      <td>republican</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>314</td>\n      <td>republican</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>y</td>\n    </tr>\n  </tbody>\n</table>\n<p>218 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\sklearn\\impute\\_iterative.py:670: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Recoded Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID class handicapped-infants water-project-cost-sharing  \\\n0    213     2                   0                          0   \n1     94     2                   1                          0   \n2    188     2                   1                          0   \n3     61     2                   1                          1   \n4    184     2                   1                          0   \n..   ...   ...                 ...                        ...   \n213  250     2                   1                          0   \n214   26     2                   1                          0   \n215  110     2                   1                          0   \n216   34     3                   0                          1   \n217  314     3                   0                          1   \n\n    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n0                                   1                    0               0   \n1                                   1                    0               0   \n2                                   1                    0               0   \n3                                   1                    0               0   \n4                                   1                    0               0   \n..                                ...                  ...             ...   \n213                                 1                    0               0   \n214                                 1                    0               0   \n215                                 1                    0               0   \n216                                 0                    1               1   \n217                                 1                    1               1   \n\n    religious-groups-in-schools anti-satellite-test-ban  \\\n0                             0                       1   \n1                             0                       1   \n2                             0                       1   \n3                             0                       1   \n4                             0                       1   \n..                          ...                     ...   \n213                           0                       1   \n214                           0                       1   \n215                           0                       1   \n216                           1                       0   \n217                           1                       0   \n\n    aid-to-nicaraguan-contras mx-missile immigration  \\\n0                           1          1           0   \n1                           0          1           1   \n2                           1          1           0   \n3                           1          1           1   \n4                           1          1           1   \n..                        ...        ...         ...   \n213                         1          1           0   \n214                         1          1           1   \n215                         1          1           0   \n216                         0          0           0   \n217                         0          0           1   \n\n    synfuels-crporation-cutback education-spending superfund-right-to-sue  \\\n0                             1                  0                      0   \n1                             1                  0                      0   \n2                             0                  0                      0   \n3                             0                  0                      0   \n4                             0                  0                      0   \n..                          ...                ...                    ...   \n213                           1                  0                      0   \n214                           0                  0                      0   \n215                           0                  0                      0   \n216                           0                  1                      1   \n217                           0                  1                      1   \n\n    crime duty-free-exports export-administration-act-south-africa  \n0       0                 1                                      1  \n1       0                 1                                      1  \n2       0                 1                                      1  \n3       0                 1                                      1  \n4       0                 1                                      1  \n..    ...               ...                                    ...  \n213     0                 1                                      1  \n214     0                 1                                      1  \n215     0                 1                                      1  \n216     1                 0                                      1  \n217     1                 0                                      1  \n\n[218 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>213</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>94</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>188</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>184</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>250</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>26</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>110</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>34</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>314</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>218 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Data: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "    handicapped-infants water-project-cost-sharing  \\\n0                     0                          0   \n1                     1                          0   \n2                     1                          0   \n3                     1                          1   \n4                     1                          0   \n..                  ...                        ...   \n213                   1                          0   \n214                   1                          0   \n215                   1                          0   \n216                   0                          1   \n217                   0                          1   \n\n    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n0                                   1                    0               0   \n1                                   1                    0               0   \n2                                   1                    0               0   \n3                                   1                    0               0   \n4                                   1                    0               0   \n..                                ...                  ...             ...   \n213                                 1                    0               0   \n214                                 1                    0               0   \n215                                 1                    0               0   \n216                                 0                    1               1   \n217                                 1                    1               1   \n\n    religious-groups-in-schools anti-satellite-test-ban  \\\n0                             0                       1   \n1                             0                       1   \n2                             0                       1   \n3                             0                       1   \n4                             0                       1   \n..                          ...                     ...   \n213                           0                       1   \n214                           0                       1   \n215                           0                       1   \n216                           1                       0   \n217                           1                       0   \n\n    aid-to-nicaraguan-contras mx-missile immigration  \\\n0                           1          1           0   \n1                           0          1           1   \n2                           1          1           0   \n3                           1          1           1   \n4                           1          1           1   \n..                        ...        ...         ...   \n213                         1          1           0   \n214                         1          1           1   \n215                         1          1           0   \n216                         0          0           0   \n217                         0          0           1   \n\n    synfuels-crporation-cutback education-spending superfund-right-to-sue  \\\n0                             1                  0                      0   \n1                             1                  0                      0   \n2                             0                  0                      0   \n3                             0                  0                      0   \n4                             0                  0                      0   \n..                          ...                ...                    ...   \n213                           1                  0                      0   \n214                           0                  0                      0   \n215                           0                  0                      0   \n216                           0                  1                      1   \n217                           0                  1                      1   \n\n    crime duty-free-exports export-administration-act-south-africa  \n0       0                 1                                      1  \n1       0                 1                                      1  \n2       0                 1                                      1  \n3       0                 1                                      1  \n4       0                 1                                      1  \n..    ...               ...                                    ...  \n213     0                 1                                      1  \n214     0                 1                                      1  \n215     0                 1                                      1  \n216     1                 0                                      1  \n217     1                 0                                      1  \n\n[218 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>handicapped-infants</th>\n      <th>water-project-cost-sharing</th>\n      <th>adoption-of-the-budget-resolution</th>\n      <th>physician-fee-freeze</th>\n      <th>el-salvador-aid</th>\n      <th>religious-groups-in-schools</th>\n      <th>anti-satellite-test-ban</th>\n      <th>aid-to-nicaraguan-contras</th>\n      <th>mx-missile</th>\n      <th>immigration</th>\n      <th>synfuels-crporation-cutback</th>\n      <th>education-spending</th>\n      <th>superfund-right-to-sue</th>\n      <th>crime</th>\n      <th>duty-free-exports</th>\n      <th>export-administration-act-south-africa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>218 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Target: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0      2\n1      2\n2      2\n3      2\n4      2\n      ..\n213    2\n214    2\n215    2\n216    3\n217    3\nName: class, Length: 218, dtype: category\nCategories (2, int64): [2, 3]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Recode values for predicting variables\n",
    "def recode_voting_data(dataset):\n",
    "    dataset = dataset.replace('y', 1)\\\n",
    "        .replace('n', 0)\\\n",
    "        .replace('democrat', 2)\\\n",
    "        .replace('republican', 3)\n",
    "    dataset.loc[:, dataset.columns != \"ID\"] = dataset.loc[:, dataset.columns != \"ID\"].astype('category')\n",
    "    return pd.DataFrame(dataset, columns=dataset.columns)\n",
    "\n",
    "#Imput missing values\n",
    "def input_missing_values(data):\n",
    "    columns = data.columns\n",
    "    imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "    imp.fit(data.loc[:, data.columns != \"ID\"])\n",
    "    data.loc[:, data.columns != \"ID\"] = np.round(imp.transform(data.loc[:, data.columns != \"ID\"]))\n",
    "    data.loc[:, data.columns != \"ID\"] = data.loc[:, data.columns != \"ID\"].apply(lambda x: x.astype('int'))\n",
    "    data.loc[:, data.columns != \"ID\"] = data.loc[:, data.columns != \"ID\"].astype('category')\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "#Read Data\n",
    "votingDataLearn = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.lrn.csv\", na_values='unknown')\n",
    "votingDataSolutionExample = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.sol.ex.csv\", na_values='unknown')\n",
    "votingDataTest = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.tes.csv\", na_values='unknown')\n",
    "display(\"Original Data\", votingDataLearn)\n",
    "\n",
    "#Recode values\n",
    "votingDataLearn = recode_voting_data(votingDataLearn)\n",
    "votingDataLearn = input_missing_values(votingDataLearn)\n",
    "\n",
    "display(\"Recoded Data\", votingDataLearn)\n",
    "\n",
    "display(\"Data: \", votingDataLearn[votingDataLearn.columns[2:18]])\n",
    "display(\"Target: \", votingDataLearn[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### k-NN - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                            classifier arguments  mean_accuracy  \\\n1  KNeighborsClassifier(n_neighbors=2)     N = 2       0.958716   \n6  KNeighborsClassifier(n_neighbors=7)     N = 7       0.949541   \n8  KNeighborsClassifier(n_neighbors=9)     N = 9       0.944954   \n0  KNeighborsClassifier(n_neighbors=1)     N = 1       0.944954   \n3  KNeighborsClassifier(n_neighbors=4)     N = 4       0.944954   \n2  KNeighborsClassifier(n_neighbors=3)     N = 3       0.940367   \n4               KNeighborsClassifier()     N = 5       0.940367   \n5  KNeighborsClassifier(n_neighbors=6)     N = 6       0.940367   \n7  KNeighborsClassifier(n_neighbors=8)     N = 8       0.940367   \n\n   mean_precision  mean_recall  \\\n1        0.955407     0.959755   \n6        0.943333     0.958955   \n8        0.939216     0.955224   \n0        0.940633     0.950782   \n3        0.940076     0.948561   \n2        0.934982     0.947050   \n4        0.935650     0.944829   \n5        0.935650     0.944829   \n7        0.934982     0.947050   \n\n                                          accuracy  \\\n1  m: 0.9587155963302753 std: 0.013761467889908285   \n6   m: 0.9495412844036697 std: 0.02293577981651379   \n8  m: 0.9449541284403671 std: 0.027522935779816515   \n0    m: 0.944954128440367 std: 0.01834862385321101   \n3    m: 0.944954128440367 std: 0.01834862385321101   \n2  m: 0.9403669724770642 std: 0.013761467889908285   \n4  m: 0.9403669724770642 std: 0.022935779816513735   \n5  m: 0.9403669724770642 std: 0.022935779816513735   \n7  m: 0.9403669724770642 std: 0.013761467889908285   \n\n                                         precision  \\\n1    m: 0.9554073308361875 std: 0.0176916648596519   \n6  m: 0.9433333333333334 std: 0.023333333333333373   \n8  m: 0.9392156862745098 std: 0.027450980392156876   \n0  m: 0.9406325515280739 std: 0.020632551528073972   \n3   m: 0.9400758575390029 std: 0.02118924551714496   \n2  m: 0.9349823819591261 std: 0.014982381959126156   \n4    m: 0.935649558330795 std: 0.02561554472535288   \n5    m: 0.935649558330795 std: 0.02561554472535288   \n7  m: 0.9349823819591261 std: 0.014982381959126156   \n\n                                            recall  \n1  m: 0.9597547974413646 std: 0.008972992181947359  \n6  m: 0.9589552238805971 std: 0.018656716417910446  \n8  m: 0.9552238805970149 std: 0.022388059701492602  \n0  m: 0.9507818052594172 std: 0.010483297796730628  \n3  m: 0.9485607675906184 std: 0.012704335465529515  \n2  m: 0.9470504619758351 std: 0.006751954513148473  \n4  m: 0.9448294243070363 std: 0.016435678749111615  \n5  m: 0.9448294243070363 std: 0.016435678749111615  \n7  m: 0.9470504619758351 std: 0.006751954513148473  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>KNeighborsClassifier(n_neighbors=2)</td>\n      <td>N = 2</td>\n      <td>0.958716</td>\n      <td>0.955407</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.013761467889908285</td>\n      <td>m: 0.9554073308361875 std: 0.0176916648596519</td>\n      <td>m: 0.9597547974413646 std: 0.008972992181947359</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>KNeighborsClassifier(n_neighbors=7)</td>\n      <td>N = 7</td>\n      <td>0.949541</td>\n      <td>0.943333</td>\n      <td>0.958955</td>\n      <td>m: 0.9495412844036697 std: 0.02293577981651379</td>\n      <td>m: 0.9433333333333334 std: 0.023333333333333373</td>\n      <td>m: 0.9589552238805971 std: 0.018656716417910446</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>KNeighborsClassifier(n_neighbors=9)</td>\n      <td>N = 9</td>\n      <td>0.944954</td>\n      <td>0.939216</td>\n      <td>0.955224</td>\n      <td>m: 0.9449541284403671 std: 0.027522935779816515</td>\n      <td>m: 0.9392156862745098 std: 0.027450980392156876</td>\n      <td>m: 0.9552238805970149 std: 0.022388059701492602</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>KNeighborsClassifier(n_neighbors=1)</td>\n      <td>N = 1</td>\n      <td>0.944954</td>\n      <td>0.940633</td>\n      <td>0.950782</td>\n      <td>m: 0.944954128440367 std: 0.01834862385321101</td>\n      <td>m: 0.9406325515280739 std: 0.020632551528073972</td>\n      <td>m: 0.9507818052594172 std: 0.010483297796730628</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KNeighborsClassifier(n_neighbors=4)</td>\n      <td>N = 4</td>\n      <td>0.944954</td>\n      <td>0.940076</td>\n      <td>0.948561</td>\n      <td>m: 0.944954128440367 std: 0.01834862385321101</td>\n      <td>m: 0.9400758575390029 std: 0.02118924551714496</td>\n      <td>m: 0.9485607675906184 std: 0.012704335465529515</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KNeighborsClassifier(n_neighbors=3)</td>\n      <td>N = 3</td>\n      <td>0.940367</td>\n      <td>0.934982</td>\n      <td>0.947050</td>\n      <td>m: 0.9403669724770642 std: 0.013761467889908285</td>\n      <td>m: 0.9349823819591261 std: 0.014982381959126156</td>\n      <td>m: 0.9470504619758351 std: 0.006751954513148473</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNeighborsClassifier()</td>\n      <td>N = 5</td>\n      <td>0.940367</td>\n      <td>0.935650</td>\n      <td>0.944829</td>\n      <td>m: 0.9403669724770642 std: 0.022935779816513735</td>\n      <td>m: 0.935649558330795 std: 0.02561554472535288</td>\n      <td>m: 0.9448294243070363 std: 0.016435678749111615</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNeighborsClassifier(n_neighbors=6)</td>\n      <td>N = 6</td>\n      <td>0.940367</td>\n      <td>0.935650</td>\n      <td>0.944829</td>\n      <td>m: 0.9403669724770642 std: 0.022935779816513735</td>\n      <td>m: 0.935649558330795 std: 0.02561554472535288</td>\n      <td>m: 0.9448294243070363 std: 0.016435678749111615</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>KNeighborsClassifier(n_neighbors=8)</td>\n      <td>N = 8</td>\n      <td>0.940367</td>\n      <td>0.934982</td>\n      <td>0.947050</td>\n      <td>m: 0.9403669724770642 std: 0.013761467889908285</td>\n      <td>m: 0.9349823819591261 std: 0.014982381959126156</td>\n      <td>m: 0.9470504619758351 std: 0.006751954513148473</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                    KNeighborsClassifier(n_neighbors=2)\narguments                                                   N = 2\nmean_accuracy                                            0.958716\nmean_precision                                           0.955407\nmean_recall                                              0.959755\naccuracy          m: 0.9587155963302753 std: 0.013761467889908285\nprecision           m: 0.9554073308361875 std: 0.0176916648596519\nrecall            m: 0.9597547974413646 std: 0.008972992181947359\nName: 1, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_results_vote = calculate_knn(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                 votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(knn_results_vote)\n",
    "\n",
    "print_results(knn_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bayes - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                 classifier    arguments  mean_accuracy  mean_precision  \\\n1  CategoricalNB(alpha=1.1)  Alpha = 1.1       0.922018        0.917619   \n2  CategoricalNB(alpha=2.1)  Alpha = 2.1       0.922018        0.916250   \n3  CategoricalNB(alpha=3.1)  Alpha = 3.1       0.922018        0.916250   \n4  CategoricalNB(alpha=4.1)  Alpha = 4.1       0.922018        0.916250   \n0  CategoricalNB(alpha=0.1)  Alpha = 0.1       0.912844        0.908527   \n\n   mean_recall                                         accuracy  \\\n1     0.927683  m: 0.9220183486238532 std: 0.022935779816513735   \n2     0.929904  m: 0.9220183486238532 std: 0.022935779816513735   \n3     0.929904  m: 0.9220183486238532 std: 0.022935779816513735   \n4     0.929904  m: 0.9220183486238532 std: 0.022935779816513735   \n0     0.915778   m: 0.9128440366972477 std: 0.02293577981651379   \n\n                                         precision  \\\n1   m: 0.9176188746213874 std: 0.02427877996283434   \n2   m: 0.916250466909696 std: 0.022910372251143063   \n3   m: 0.916250466909696 std: 0.022910372251143063   \n4   m: 0.916250466909696 std: 0.022910372251143063   \n0  m: 0.9085268584490431 std: 0.025476010991416054   \n\n                                           recall  \n1  m: 0.927683013503909 std: 0.014214641080312673  \n2  m: 0.9299040511727079 std: 0.01643567874911156  \n3  m: 0.9299040511727079 std: 0.01643567874911156  \n4  m: 0.9299040511727079 std: 0.01643567874911156  \n0  m: 0.915778251599147 std: 0.014214641080312729  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>CategoricalNB(alpha=1.1)</td>\n      <td>Alpha = 1.1</td>\n      <td>0.922018</td>\n      <td>0.917619</td>\n      <td>0.927683</td>\n      <td>m: 0.9220183486238532 std: 0.022935779816513735</td>\n      <td>m: 0.9176188746213874 std: 0.02427877996283434</td>\n      <td>m: 0.927683013503909 std: 0.014214641080312673</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CategoricalNB(alpha=2.1)</td>\n      <td>Alpha = 2.1</td>\n      <td>0.922018</td>\n      <td>0.916250</td>\n      <td>0.929904</td>\n      <td>m: 0.9220183486238532 std: 0.022935779816513735</td>\n      <td>m: 0.916250466909696 std: 0.022910372251143063</td>\n      <td>m: 0.9299040511727079 std: 0.01643567874911156</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CategoricalNB(alpha=3.1)</td>\n      <td>Alpha = 3.1</td>\n      <td>0.922018</td>\n      <td>0.916250</td>\n      <td>0.929904</td>\n      <td>m: 0.9220183486238532 std: 0.022935779816513735</td>\n      <td>m: 0.916250466909696 std: 0.022910372251143063</td>\n      <td>m: 0.9299040511727079 std: 0.01643567874911156</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CategoricalNB(alpha=4.1)</td>\n      <td>Alpha = 4.1</td>\n      <td>0.922018</td>\n      <td>0.916250</td>\n      <td>0.929904</td>\n      <td>m: 0.9220183486238532 std: 0.022935779816513735</td>\n      <td>m: 0.916250466909696 std: 0.022910372251143063</td>\n      <td>m: 0.9299040511727079 std: 0.01643567874911156</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>CategoricalNB(alpha=0.1)</td>\n      <td>Alpha = 0.1</td>\n      <td>0.912844</td>\n      <td>0.908527</td>\n      <td>0.915778</td>\n      <td>m: 0.9128440366972477 std: 0.02293577981651379</td>\n      <td>m: 0.9085268584490431 std: 0.025476010991416054</td>\n      <td>m: 0.915778251599147 std: 0.014214641080312729</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                               CategoricalNB(alpha=1.1)\narguments                                             Alpha = 1.1\nmean_accuracy                                            0.922018\nmean_precision                                           0.917619\nmean_recall                                              0.927683\naccuracy          m: 0.9220183486238532 std: 0.022935779816513735\nprecision          m: 0.9176188746213874 std: 0.02427877996283434\nrecall             m: 0.927683013503909 std: 0.014214641080312673\nName: 1, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bayes_results_vote = calculate_bayes(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                     votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(bayes_results_vote)\n",
    "\n",
    "print_results(bayes_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     classifier            arguments  mean_accuracy  mean_precision  \\\n0  Perceptron()  No additional args.       0.926606        0.928189   \n\n   mean_recall                                        accuracy  \\\n0     0.918088  m: 0.926605504587156 std: 0.009174311926605505   \n\n                                        precision  \\\n0  m: 0.9281886273165343 std: 0.01663119250328554   \n\n                                            recall  \n0  m: 0.9180881307746979 std: 0.003020611229566428  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Perceptron()</td>\n      <td>No additional args.</td>\n      <td>0.926606</td>\n      <td>0.928189</td>\n      <td>0.918088</td>\n      <td>m: 0.926605504587156 std: 0.009174311926605505</td>\n      <td>m: 0.9281886273165343 std: 0.01663119250328554</td>\n      <td>m: 0.9180881307746979 std: 0.003020611229566428</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                                           Perceptron()\narguments                                     No additional args.\nmean_accuracy                                            0.926606\nmean_precision                                           0.928189\nmean_recall                                              0.918088\naccuracy           m: 0.926605504587156 std: 0.009174311926605505\nprecision          m: 0.9281886273165343 std: 0.01663119250328554\nrecall            m: 0.9180881307746979 std: 0.003020611229566428\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perceptron_results_vote = calculate_perceptron(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                               votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(perceptron_results_vote)\n",
    "\n",
    "print_results(perceptron_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n0   DecisionTreeClassifier(max_depth=1, min_sample...   \n17  DecisionTreeClassifier(max_depth=9, min_sample...   \n5   DecisionTreeClassifier(max_depth=3, min_sample...   \n9   DecisionTreeClassifier(max_depth=5, min_sample...   \n1   DecisionTreeClassifier(max_depth=1, min_sample...   \n13  DecisionTreeClassifier(max_depth=7, min_sample...   \n12  DecisionTreeClassifier(max_depth=7, min_sample...   \n16  DecisionTreeClassifier(max_depth=9, min_sample...   \n8   DecisionTreeClassifier(max_depth=5, min_sample...   \n4   DecisionTreeClassifier(max_depth=3, min_sample...   \n18  DecisionTreeClassifier(max_depth=9, min_sample...   \n14  DecisionTreeClassifier(max_depth=7, min_sample...   \n10  DecisionTreeClassifier(max_depth=5, min_sample...   \n6   DecisionTreeClassifier(max_depth=3, min_sample...   \n2   DecisionTreeClassifier(max_depth=1, min_sample...   \n11  DecisionTreeClassifier(max_depth=5, min_sample...   \n7   DecisionTreeClassifier(max_depth=3, min_sample...   \n15  DecisionTreeClassifier(max_depth=7, min_sample...   \n3   DecisionTreeClassifier(max_depth=1, min_sample...   \n19  DecisionTreeClassifier(max_depth=9, min_sample...   \n\n                         arguments  mean_accuracy  mean_precision  \\\n0     max Depth: 1, min Samples: 2       0.967890        0.962041   \n17   max Depth: 9, min Samples: 20       0.967890        0.962041   \n5    max Depth: 3, min Samples: 20       0.967890        0.962041   \n9    max Depth: 5, min Samples: 20       0.967890        0.962041   \n1    max Depth: 1, min Samples: 20       0.967890        0.962041   \n13   max Depth: 7, min Samples: 20       0.967890        0.962041   \n12    max Depth: 7, min Samples: 2       0.958716        0.955036   \n16    max Depth: 9, min Samples: 2       0.958716        0.955036   \n8     max Depth: 5, min Samples: 2       0.958716        0.955036   \n4     max Depth: 3, min Samples: 2       0.954128        0.950180   \n18   max Depth: 9, min Samples: 50       0.834862        0.837574   \n14   max Depth: 7, min Samples: 50       0.834862        0.837574   \n10   max Depth: 5, min Samples: 50       0.834862        0.837574   \n6    max Depth: 3, min Samples: 50       0.834862        0.837574   \n2    max Depth: 1, min Samples: 50       0.834862        0.837574   \n11  max Depth: 5, min Samples: 100       0.614679        0.307339   \n7   max Depth: 3, min Samples: 100       0.614679        0.307339   \n15  max Depth: 7, min Samples: 100       0.614679        0.307339   \n3   max Depth: 1, min Samples: 100       0.614679        0.307339   \n19  max Depth: 9, min Samples: 100       0.614679        0.307339   \n\n    mean_recall                                         accuracy  \\\n0      0.973881   m: 0.9678899082568808 std: 0.01376146788990823   \n17     0.973881   m: 0.9678899082568808 std: 0.01376146788990823   \n5      0.973881   m: 0.9678899082568808 std: 0.01376146788990823   \n9      0.973881   m: 0.9678899082568808 std: 0.01376146788990823   \n1      0.973881   m: 0.9678899082568808 std: 0.01376146788990823   \n13     0.973881   m: 0.9678899082568808 std: 0.01376146788990823   \n12     0.959755  m: 0.9587155963302753 std: 0.004587155963302725   \n16     0.959755  m: 0.9587155963302753 std: 0.004587155963302725   \n8      0.959755  m: 0.9587155963302753 std: 0.004587155963302725   \n4      0.956023                   m: 0.9541284403669725 std: 0.0   \n18     0.850124   m: 0.8348623853211009 std: 0.01834862385321101   \n14     0.850124   m: 0.8348623853211009 std: 0.01834862385321101   \n10     0.850124   m: 0.8348623853211009 std: 0.01834862385321101   \n6      0.850124   m: 0.8348623853211009 std: 0.01834862385321101   \n2      0.850124   m: 0.8348623853211009 std: 0.01834862385321101   \n11     0.500000                   m: 0.6146788990825688 std: 0.0   \n7      0.500000                   m: 0.6146788990825688 std: 0.0   \n15     0.500000                   m: 0.6146788990825688 std: 0.0   \n3      0.500000                   m: 0.6146788990825688 std: 0.0   \n19     0.500000                   m: 0.6146788990825688 std: 0.0   \n\n                                           precision  \\\n0    m: 0.9620406189555126 std: 0.015232108317214721   \n17   m: 0.9620406189555126 std: 0.015232108317214721   \n5    m: 0.9620406189555126 std: 0.015232108317214721   \n9    m: 0.9620406189555126 std: 0.015232108317214721   \n1    m: 0.9620406189555126 std: 0.015232108317214721   \n13   m: 0.9620406189555126 std: 0.015232108317214721   \n12    m: 0.955036335849292 std: 0.001485403281142772   \n16    m: 0.955036335849292 std: 0.001485403281142772   \n8     m: 0.955036335849292 std: 0.001485403281142772   \n4   m: 0.9501797216032235 std: 0.0033712109649257083   \n18   m: 0.8375739426205264 std: 0.006111357586512878   \n14   m: 0.8375739426205264 std: 0.006111357586512878   \n10   m: 0.8375739426205264 std: 0.006111357586512878   \n6    m: 0.8375739426205264 std: 0.006111357586512878   \n2    m: 0.8375739426205264 std: 0.006111357586512878   \n11                    m: 0.3073394495412844 std: 0.0   \n7                     m: 0.3073394495412844 std: 0.0   \n15                    m: 0.3073394495412844 std: 0.0   \n3                     m: 0.3073394495412844 std: 0.0   \n19                    m: 0.3073394495412844 std: 0.0   \n\n                                             recall  \n0   m: 0.9738805970149254 std: 0.011194029850746245  \n17  m: 0.9738805970149254 std: 0.011194029850746245  \n5   m: 0.9738805970149254 std: 0.011194029850746245  \n9   m: 0.9738805970149254 std: 0.011194029850746245  \n1   m: 0.9738805970149254 std: 0.011194029850746245  \n13  m: 0.9738805970149254 std: 0.011194029850746245  \n12  m: 0.9597547974413647 std: 0.010394456289978649  \n16  m: 0.9597547974413647 std: 0.010394456289978649  \n8   m: 0.9597547974413647 std: 0.010394456289978649  \n4   m: 0.9560234541577826 std: 0.006663113006396548  \n18   m: 0.8501243781094527 std: 0.00382018479033408  \n14   m: 0.8501243781094527 std: 0.00382018479033408  \n10   m: 0.8501243781094527 std: 0.00382018479033408  \n6    m: 0.8501243781094527 std: 0.00382018479033408  \n2    m: 0.8501243781094527 std: 0.00382018479033408  \n11                                  m: 0.5 std: 0.0  \n7                                   m: 0.5 std: 0.0  \n15                                  m: 0.5 std: 0.0  \n3                                   m: 0.5 std: 0.0  \n19                                  m: 0.5 std: 0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 2</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 20</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 20</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 20</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 20</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 20</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 2</td>\n      <td>0.958716</td>\n      <td>0.955036</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.004587155963302725</td>\n      <td>m: 0.955036335849292 std: 0.001485403281142772</td>\n      <td>m: 0.9597547974413647 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 2</td>\n      <td>0.958716</td>\n      <td>0.955036</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.004587155963302725</td>\n      <td>m: 0.955036335849292 std: 0.001485403281142772</td>\n      <td>m: 0.9597547974413647 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 2</td>\n      <td>0.958716</td>\n      <td>0.955036</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.004587155963302725</td>\n      <td>m: 0.955036335849292 std: 0.001485403281142772</td>\n      <td>m: 0.9597547974413647 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 2</td>\n      <td>0.954128</td>\n      <td>0.950180</td>\n      <td>0.956023</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9501797216032235 std: 0.0033712109649257083</td>\n      <td>m: 0.9560234541577826 std: 0.006663113006396548</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 50</td>\n      <td>0.834862</td>\n      <td>0.837574</td>\n      <td>0.850124</td>\n      <td>m: 0.8348623853211009 std: 0.01834862385321101</td>\n      <td>m: 0.8375739426205264 std: 0.006111357586512878</td>\n      <td>m: 0.8501243781094527 std: 0.00382018479033408</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 50</td>\n      <td>0.834862</td>\n      <td>0.837574</td>\n      <td>0.850124</td>\n      <td>m: 0.8348623853211009 std: 0.01834862385321101</td>\n      <td>m: 0.8375739426205264 std: 0.006111357586512878</td>\n      <td>m: 0.8501243781094527 std: 0.00382018479033408</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 50</td>\n      <td>0.834862</td>\n      <td>0.837574</td>\n      <td>0.850124</td>\n      <td>m: 0.8348623853211009 std: 0.01834862385321101</td>\n      <td>m: 0.8375739426205264 std: 0.006111357586512878</td>\n      <td>m: 0.8501243781094527 std: 0.00382018479033408</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 50</td>\n      <td>0.834862</td>\n      <td>0.837574</td>\n      <td>0.850124</td>\n      <td>m: 0.8348623853211009 std: 0.01834862385321101</td>\n      <td>m: 0.8375739426205264 std: 0.006111357586512878</td>\n      <td>m: 0.8501243781094527 std: 0.00382018479033408</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 50</td>\n      <td>0.834862</td>\n      <td>0.837574</td>\n      <td>0.850124</td>\n      <td>m: 0.8348623853211009 std: 0.01834862385321101</td>\n      <td>m: 0.8375739426205264 std: 0.006111357586512878</td>\n      <td>m: 0.8501243781094527 std: 0.00382018479033408</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 100</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 100</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 100</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 100</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 100</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        DecisionTreeClassifier(max_depth=1, min_sample...\narguments                              max Depth: 1, min Samples: 2\nmean_accuracy                                               0.96789\nmean_precision                                             0.962041\nmean_recall                                                0.973881\naccuracy             m: 0.9678899082568808 std: 0.01376146788990823\nprecision           m: 0.9620406189555126 std: 0.015232108317214721\nrecall              m: 0.9738805970149254 std: 0.011194029850746245\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_results_vote = calculate_decision_tree(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                                     votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(decision_tree_results_vote)\n",
    "\n",
    "print_results(decision_tree_results_vote, \"mean_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM - Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n0    SVC(C=100, degree=1, gamma=0.001, kernel='poly')   \n28                  SVC(C=100, degree=2, gamma=0.001)   \n35                  SVC(C=100, degree=9, gamma=0.001)   \n34                  SVC(C=100, degree=8, gamma=0.001)   \n33                  SVC(C=100, degree=7, gamma=0.001)   \n32                  SVC(C=100, degree=6, gamma=0.001)   \n31                  SVC(C=100, degree=5, gamma=0.001)   \n30                  SVC(C=100, degree=4, gamma=0.001)   \n29                            SVC(C=100, gamma=0.001)   \n27                  SVC(C=100, degree=1, gamma=0.001)   \n36                               SVC(C=100, degree=1)   \n44                               SVC(C=100, degree=9)   \n37                               SVC(C=100, degree=2)   \n38                                         SVC(C=100)   \n39                               SVC(C=100, degree=4)   \n40                               SVC(C=100, degree=5)   \n41                               SVC(C=100, degree=6)   \n42                               SVC(C=100, degree=7)   \n43                               SVC(C=100, degree=8)   \n10                SVC(C=100, degree=2, kernel='poly')   \n11                          SVC(C=100, kernel='poly')   \n46                 SVC(C=100, degree=2, gamma='auto')   \n47                           SVC(C=100, gamma='auto')   \n48                 SVC(C=100, degree=4, gamma='auto')   \n49                 SVC(C=100, degree=5, gamma='auto')   \n50                 SVC(C=100, degree=6, gamma='auto')   \n51                 SVC(C=100, degree=7, gamma='auto')   \n52                 SVC(C=100, degree=8, gamma='auto')   \n45                 SVC(C=100, degree=1, gamma='auto')   \n53                 SVC(C=100, degree=9, gamma='auto')   \n22  SVC(C=100, degree=5, gamma='auto', kernel='poly')   \n13                SVC(C=100, degree=5, kernel='poly')   \n20            SVC(C=100, gamma='auto', kernel='poly')   \n19  SVC(C=100, degree=2, gamma='auto', kernel='poly')   \n12                SVC(C=100, degree=4, kernel='poly')   \n14                SVC(C=100, degree=6, kernel='poly')   \n23  SVC(C=100, degree=6, gamma='auto', kernel='poly')   \n21  SVC(C=100, degree=4, gamma='auto', kernel='poly')   \n18  SVC(C=100, degree=1, gamma='auto', kernel='poly')   \n15                SVC(C=100, degree=7, kernel='poly')   \n9                 SVC(C=100, degree=1, kernel='poly')   \n16                SVC(C=100, degree=8, kernel='poly')   \n24  SVC(C=100, degree=7, gamma='auto', kernel='poly')   \n17                SVC(C=100, degree=9, kernel='poly')   \n25  SVC(C=100, degree=8, gamma='auto', kernel='poly')   \n26  SVC(C=100, degree=9, gamma='auto', kernel='poly')   \n7    SVC(C=100, degree=8, gamma=0.001, kernel='poly')   \n6    SVC(C=100, degree=7, gamma=0.001, kernel='poly')   \n1    SVC(C=100, degree=2, gamma=0.001, kernel='poly')   \n2              SVC(C=100, gamma=0.001, kernel='poly')   \n3    SVC(C=100, degree=4, gamma=0.001, kernel='poly')   \n4    SVC(C=100, degree=5, gamma=0.001, kernel='poly')   \n8    SVC(C=100, degree=9, gamma=0.001, kernel='poly')   \n5    SVC(C=100, degree=6, gamma=0.001, kernel='poly')   \n\n                  arguments  mean_accuracy  mean_precision  mean_recall  \\\n0   Kernel: poly, Degree: 1       0.967890        0.962041     0.973881   \n28   Kernel: rbf, Degree: 2       0.967890        0.962041     0.973881   \n35   Kernel: rbf, Degree: 9       0.967890        0.962041     0.973881   \n34   Kernel: rbf, Degree: 8       0.967890        0.962041     0.973881   \n33   Kernel: rbf, Degree: 7       0.967890        0.962041     0.973881   \n32   Kernel: rbf, Degree: 6       0.967890        0.962041     0.973881   \n31   Kernel: rbf, Degree: 5       0.967890        0.962041     0.973881   \n30   Kernel: rbf, Degree: 4       0.967890        0.962041     0.973881   \n29   Kernel: rbf, Degree: 3       0.967890        0.962041     0.973881   \n27   Kernel: rbf, Degree: 1       0.967890        0.962041     0.973881   \n36   Kernel: rbf, Degree: 1       0.958716        0.955036     0.959755   \n44   Kernel: rbf, Degree: 9       0.958716        0.955036     0.959755   \n37   Kernel: rbf, Degree: 2       0.958716        0.955036     0.959755   \n38   Kernel: rbf, Degree: 3       0.958716        0.955036     0.959755   \n39   Kernel: rbf, Degree: 4       0.958716        0.955036     0.959755   \n40   Kernel: rbf, Degree: 5       0.958716        0.955036     0.959755   \n41   Kernel: rbf, Degree: 6       0.958716        0.955036     0.959755   \n42   Kernel: rbf, Degree: 7       0.958716        0.955036     0.959755   \n43   Kernel: rbf, Degree: 8       0.958716        0.955036     0.959755   \n10  Kernel: poly, Degree: 2       0.954128        0.950180     0.956023   \n11  Kernel: poly, Degree: 3       0.954128        0.950647     0.953802   \n46   Kernel: rbf, Degree: 2       0.954128        0.950180     0.956023   \n47   Kernel: rbf, Degree: 3       0.954128        0.950180     0.956023   \n48   Kernel: rbf, Degree: 4       0.954128        0.950180     0.956023   \n49   Kernel: rbf, Degree: 5       0.954128        0.950180     0.956023   \n50   Kernel: rbf, Degree: 6       0.954128        0.950180     0.956023   \n51   Kernel: rbf, Degree: 7       0.954128        0.950180     0.956023   \n52   Kernel: rbf, Degree: 8       0.954128        0.950180     0.956023   \n45   Kernel: rbf, Degree: 1       0.954128        0.950180     0.956023   \n53   Kernel: rbf, Degree: 9       0.954128        0.950180     0.956023   \n22  Kernel: poly, Degree: 5       0.954128        0.950647     0.953802   \n13  Kernel: poly, Degree: 5       0.954128        0.952116     0.951581   \n20  Kernel: poly, Degree: 3       0.954128        0.950647     0.953802   \n19  Kernel: poly, Degree: 2       0.954128        0.950180     0.956023   \n12  Kernel: poly, Degree: 4       0.949541        0.946879     0.947850   \n14  Kernel: poly, Degree: 6       0.949541        0.947990     0.945629   \n23  Kernel: poly, Degree: 6       0.949541        0.946879     0.947850   \n21  Kernel: poly, Degree: 4       0.949541        0.946879     0.947850   \n18  Kernel: poly, Degree: 1       0.944954        0.940828     0.946340   \n15  Kernel: poly, Degree: 7       0.944954        0.943956     0.939677   \n9   Kernel: poly, Degree: 1       0.940367        0.936230     0.940387   \n16  Kernel: poly, Degree: 8       0.931193        0.932348     0.921819   \n24  Kernel: poly, Degree: 7       0.931193        0.932348     0.921819   \n17  Kernel: poly, Degree: 9       0.931193        0.935038     0.919598   \n25  Kernel: poly, Degree: 8       0.894495        0.907595     0.871979   \n26  Kernel: poly, Degree: 9       0.876147        0.898559     0.845949   \n7   Kernel: poly, Degree: 8       0.614679        0.307339     0.500000   \n6   Kernel: poly, Degree: 7       0.614679        0.307339     0.500000   \n1   Kernel: poly, Degree: 2       0.614679        0.307339     0.500000   \n2   Kernel: poly, Degree: 3       0.614679        0.307339     0.500000   \n3   Kernel: poly, Degree: 4       0.614679        0.307339     0.500000   \n4   Kernel: poly, Degree: 5       0.614679        0.307339     0.500000   \n8   Kernel: poly, Degree: 9       0.614679        0.307339     0.500000   \n5   Kernel: poly, Degree: 6       0.614679        0.307339     0.500000   \n\n                                           accuracy  \\\n0    m: 0.9678899082568808 std: 0.01376146788990823   \n28   m: 0.9678899082568808 std: 0.01376146788990823   \n35   m: 0.9678899082568808 std: 0.01376146788990823   \n34   m: 0.9678899082568808 std: 0.01376146788990823   \n33   m: 0.9678899082568808 std: 0.01376146788990823   \n32   m: 0.9678899082568808 std: 0.01376146788990823   \n31   m: 0.9678899082568808 std: 0.01376146788990823   \n30   m: 0.9678899082568808 std: 0.01376146788990823   \n29   m: 0.9678899082568808 std: 0.01376146788990823   \n27   m: 0.9678899082568808 std: 0.01376146788990823   \n36  m: 0.9587155963302753 std: 0.004587155963302725   \n44  m: 0.9587155963302753 std: 0.004587155963302725   \n37  m: 0.9587155963302753 std: 0.004587155963302725   \n38  m: 0.9587155963302753 std: 0.004587155963302725   \n39  m: 0.9587155963302753 std: 0.004587155963302725   \n40  m: 0.9587155963302753 std: 0.004587155963302725   \n41  m: 0.9587155963302753 std: 0.004587155963302725   \n42  m: 0.9587155963302753 std: 0.004587155963302725   \n43  m: 0.9587155963302753 std: 0.004587155963302725   \n10                   m: 0.9541284403669725 std: 0.0   \n11                   m: 0.9541284403669725 std: 0.0   \n46                   m: 0.9541284403669725 std: 0.0   \n47                   m: 0.9541284403669725 std: 0.0   \n48                   m: 0.9541284403669725 std: 0.0   \n49                   m: 0.9541284403669725 std: 0.0   \n50                   m: 0.9541284403669725 std: 0.0   \n51                   m: 0.9541284403669725 std: 0.0   \n52                   m: 0.9541284403669725 std: 0.0   \n45                   m: 0.9541284403669725 std: 0.0   \n53                   m: 0.9541284403669725 std: 0.0   \n22                   m: 0.9541284403669725 std: 0.0   \n13  m: 0.9541284403669725 std: 0.009174311926605505   \n20                   m: 0.9541284403669725 std: 0.0   \n19                   m: 0.9541284403669725 std: 0.0   \n12   m: 0.9495412844036697 std: 0.00458715596330278   \n14   m: 0.9495412844036697 std: 0.00458715596330278   \n23   m: 0.9495412844036697 std: 0.00458715596330278   \n21   m: 0.9495412844036697 std: 0.00458715596330278   \n18  m: 0.9449541284403671 std: 0.009174311926605505   \n15                    m: 0.944954128440367 std: 0.0   \n9   m: 0.9403669724770642 std: 0.013761467889908285   \n16   m: 0.9311926605504588 std: 0.01376146788990823   \n24   m: 0.9311926605504588 std: 0.01376146788990823   \n17   m: 0.9311926605504588 std: 0.00458715596330278   \n25   m: 0.8944954128440368 std: 0.02293577981651379   \n26   m: 0.8761467889908257 std: 0.02293577981651379   \n7                    m: 0.6146788990825688 std: 0.0   \n6                    m: 0.6146788990825688 std: 0.0   \n1                    m: 0.6146788990825688 std: 0.0   \n2                    m: 0.6146788990825688 std: 0.0   \n3                    m: 0.6146788990825688 std: 0.0   \n4                    m: 0.6146788990825688 std: 0.0   \n8                    m: 0.6146788990825688 std: 0.0   \n5                    m: 0.6146788990825688 std: 0.0   \n\n                                           precision  \\\n0    m: 0.9620406189555126 std: 0.015232108317214721   \n28   m: 0.9620406189555126 std: 0.015232108317214721   \n35   m: 0.9620406189555126 std: 0.015232108317214721   \n34   m: 0.9620406189555126 std: 0.015232108317214721   \n33   m: 0.9620406189555126 std: 0.015232108317214721   \n32   m: 0.9620406189555126 std: 0.015232108317214721   \n31   m: 0.9620406189555126 std: 0.015232108317214721   \n30   m: 0.9620406189555126 std: 0.015232108317214721   \n29   m: 0.9620406189555126 std: 0.015232108317214721   \n27   m: 0.9620406189555126 std: 0.015232108317214721   \n36    m: 0.955036335849292 std: 0.001485403281142772   \n44    m: 0.955036335849292 std: 0.001485403281142772   \n37    m: 0.955036335849292 std: 0.001485403281142772   \n38    m: 0.955036335849292 std: 0.001485403281142772   \n39    m: 0.955036335849292 std: 0.001485403281142772   \n40    m: 0.955036335849292 std: 0.001485403281142772   \n41    m: 0.955036335849292 std: 0.001485403281142772   \n42    m: 0.955036335849292 std: 0.001485403281142772   \n43    m: 0.955036335849292 std: 0.001485403281142772   \n10  m: 0.9501797216032235 std: 0.0033712109649257083   \n11   m: 0.9506469940618524 std: 0.002903938506296888   \n46  m: 0.9501797216032235 std: 0.0033712109649257083   \n47  m: 0.9501797216032235 std: 0.0033712109649257083   \n48  m: 0.9501797216032235 std: 0.0033712109649257083   \n49  m: 0.9501797216032235 std: 0.0033712109649257083   \n50  m: 0.9501797216032235 std: 0.0033712109649257083   \n51  m: 0.9501797216032235 std: 0.0033712109649257083   \n52  m: 0.9501797216032235 std: 0.0033712109649257083   \n45  m: 0.9501797216032235 std: 0.0033712109649257083   \n53  m: 0.9501797216032235 std: 0.0033712109649257083   \n22   m: 0.9506469940618524 std: 0.002903938506296888   \n13   m: 0.9521156379852032 std: 0.006101145231580007   \n20   m: 0.9506469940618524 std: 0.002903938506296888   \n19  m: 0.9501797216032235 std: 0.0033712109649257083   \n12  m: 0.9468787741545893 std: 0.0008642814009661715   \n14  m: 0.9479896283359377 std: 0.0019751355823145467   \n23  m: 0.9468787741545893 std: 0.0008642814009661715   \n21  m: 0.9468787741545893 std: 0.0008642814009661715   \n18   m: 0.9408283146025372 std: 0.012722617965612026   \n15  m: 0.9439560736689224 std: 0.0020584190847007244   \n9     m: 0.9362302626953928 std: 0.01732066987275649   \n16      m: 0.932347905717471 std: 0.0136665870361522   \n24      m: 0.932347905717471 std: 0.0136665870361522   \n17    m: 0.9350376890221219 std: 0.00360699962256672   \n25    m: 0.907594891969892 std: 0.016766969891969907   \n26    m: 0.8985590414471161 std: 0.02049996971715823   \n7                     m: 0.3073394495412844 std: 0.0   \n6                     m: 0.3073394495412844 std: 0.0   \n1                     m: 0.3073394495412844 std: 0.0   \n2                     m: 0.3073394495412844 std: 0.0   \n3                     m: 0.3073394495412844 std: 0.0   \n4                     m: 0.3073394495412844 std: 0.0   \n8                     m: 0.3073394495412844 std: 0.0   \n5                     m: 0.3073394495412844 std: 0.0   \n\n                                             recall  \n0   m: 0.9738805970149254 std: 0.011194029850746245  \n28  m: 0.9738805970149254 std: 0.011194029850746245  \n35  m: 0.9738805970149254 std: 0.011194029850746245  \n34  m: 0.9738805970149254 std: 0.011194029850746245  \n33  m: 0.9738805970149254 std: 0.011194029850746245  \n32  m: 0.9738805970149254 std: 0.011194029850746245  \n31  m: 0.9738805970149254 std: 0.011194029850746245  \n30  m: 0.9738805970149254 std: 0.011194029850746245  \n29  m: 0.9738805970149254 std: 0.011194029850746245  \n27  m: 0.9738805970149254 std: 0.011194029850746245  \n36  m: 0.9597547974413647 std: 0.010394456289978649  \n44  m: 0.9597547974413647 std: 0.010394456289978649  \n37  m: 0.9597547974413647 std: 0.010394456289978649  \n38  m: 0.9597547974413647 std: 0.010394456289978649  \n39  m: 0.9597547974413647 std: 0.010394456289978649  \n40  m: 0.9597547974413647 std: 0.010394456289978649  \n41  m: 0.9597547974413647 std: 0.010394456289978649  \n42  m: 0.9597547974413647 std: 0.010394456289978649  \n43  m: 0.9597547974413647 std: 0.010394456289978649  \n10  m: 0.9560234541577826 std: 0.006663113006396548  \n11  m: 0.9538024164889837 std: 0.004442075337597662  \n46  m: 0.9560234541577826 std: 0.006663113006396548  \n47  m: 0.9560234541577826 std: 0.006663113006396548  \n48  m: 0.9560234541577826 std: 0.006663113006396548  \n49  m: 0.9560234541577826 std: 0.006663113006396548  \n50  m: 0.9560234541577826 std: 0.006663113006396548  \n51  m: 0.9560234541577826 std: 0.006663113006396548  \n52  m: 0.9560234541577826 std: 0.006663113006396548  \n45  m: 0.9560234541577826 std: 0.006663113006396548  \n53  m: 0.9560234541577826 std: 0.006663113006396548  \n22  m: 0.9538024164889837 std: 0.004442075337597662  \n13  m: 0.9515813788201848 std: 0.014125799573560749  \n20  m: 0.9538024164889837 std: 0.004442075337597662  \n19  m: 0.9560234541577826 std: 0.006663113006396548  \n12  m: 0.9478500355366026 std: 0.010394456289978649  \n14  m: 0.9456289978678039 std: 0.008173418621179762  \n23  m: 0.9478500355366026 std: 0.010394456289978649  \n21  m: 0.9478500355366026 std: 0.010394456289978649  \n18  m: 0.9463397299218195 std: 0.003020611229566539  \n15  m: 0.9396766169154229 std: 0.002221037668798831  \n9    m: 0.9403873489694385 std: 0.00897299218194747  \n16     m: 0.92181947405828 std: 0.01563610518834402  \n24     m: 0.92181947405828 std: 0.01563610518834402  \n17  m: 0.9195984363894811 std: 0.005952380952380931  \n25  m: 0.8719793887704336 std: 0.029761904761904767  \n26   m: 0.8459488272921108 std: 0.02754086709310588  \n7                                   m: 0.5 std: 0.0  \n6                                   m: 0.5 std: 0.0  \n1                                   m: 0.5 std: 0.0  \n2                                   m: 0.5 std: 0.0  \n3                                   m: 0.5 std: 0.0  \n4                                   m: 0.5 std: 0.0  \n8                                   m: 0.5 std: 0.0  \n5                                   m: 0.5 std: 0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SVC(C=100, degree=1, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>SVC(C=100, degree=2, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 2</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>SVC(C=100, degree=9, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 9</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>SVC(C=100, degree=8, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 8</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>SVC(C=100, degree=7, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 7</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>SVC(C=100, degree=6, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 6</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>SVC(C=100, degree=5, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 5</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>SVC(C=100, degree=4, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 4</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>SVC(C=100, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 3</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>SVC(C=100, degree=1, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>SVC(C=100, degree=1)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.958716</td>\n      <td>0.955036</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.004587155963302725</td>\n      <td>m: 0.955036335849292 std: 0.001485403281142772</td>\n      <td>m: 0.9597547974413647 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>SVC(C=100, degree=9)</td>\n      <td>Kernel: rbf, Degree: 9</td>\n      <td>0.958716</td>\n      <td>0.955036</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.004587155963302725</td>\n      <td>m: 0.955036335849292 std: 0.001485403281142772</td>\n      <td>m: 0.9597547974413647 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>SVC(C=100, degree=2)</td>\n      <td>Kernel: rbf, Degree: 2</td>\n      <td>0.958716</td>\n      <td>0.955036</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.004587155963302725</td>\n      <td>m: 0.955036335849292 std: 0.001485403281142772</td>\n      <td>m: 0.9597547974413647 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>SVC(C=100)</td>\n      <td>Kernel: rbf, Degree: 3</td>\n      <td>0.958716</td>\n      <td>0.955036</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.004587155963302725</td>\n      <td>m: 0.955036335849292 std: 0.001485403281142772</td>\n      <td>m: 0.9597547974413647 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>SVC(C=100, degree=4)</td>\n      <td>Kernel: rbf, Degree: 4</td>\n      <td>0.958716</td>\n      <td>0.955036</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.004587155963302725</td>\n      <td>m: 0.955036335849292 std: 0.001485403281142772</td>\n      <td>m: 0.9597547974413647 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>SVC(C=100, degree=5)</td>\n      <td>Kernel: rbf, Degree: 5</td>\n      <td>0.958716</td>\n      <td>0.955036</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.004587155963302725</td>\n      <td>m: 0.955036335849292 std: 0.001485403281142772</td>\n      <td>m: 0.9597547974413647 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>SVC(C=100, degree=6)</td>\n      <td>Kernel: rbf, Degree: 6</td>\n      <td>0.958716</td>\n      <td>0.955036</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.004587155963302725</td>\n      <td>m: 0.955036335849292 std: 0.001485403281142772</td>\n      <td>m: 0.9597547974413647 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>SVC(C=100, degree=7)</td>\n      <td>Kernel: rbf, Degree: 7</td>\n      <td>0.958716</td>\n      <td>0.955036</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.004587155963302725</td>\n      <td>m: 0.955036335849292 std: 0.001485403281142772</td>\n      <td>m: 0.9597547974413647 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>SVC(C=100, degree=8)</td>\n      <td>Kernel: rbf, Degree: 8</td>\n      <td>0.958716</td>\n      <td>0.955036</td>\n      <td>0.959755</td>\n      <td>m: 0.9587155963302753 std: 0.004587155963302725</td>\n      <td>m: 0.955036335849292 std: 0.001485403281142772</td>\n      <td>m: 0.9597547974413647 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>SVC(C=100, degree=2, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 2</td>\n      <td>0.954128</td>\n      <td>0.950180</td>\n      <td>0.956023</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9501797216032235 std: 0.0033712109649257083</td>\n      <td>m: 0.9560234541577826 std: 0.006663113006396548</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>SVC(C=100, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 3</td>\n      <td>0.954128</td>\n      <td>0.950647</td>\n      <td>0.953802</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9506469940618524 std: 0.002903938506296888</td>\n      <td>m: 0.9538024164889837 std: 0.004442075337597662</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>SVC(C=100, degree=2, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 2</td>\n      <td>0.954128</td>\n      <td>0.950180</td>\n      <td>0.956023</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9501797216032235 std: 0.0033712109649257083</td>\n      <td>m: 0.9560234541577826 std: 0.006663113006396548</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>SVC(C=100, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 3</td>\n      <td>0.954128</td>\n      <td>0.950180</td>\n      <td>0.956023</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9501797216032235 std: 0.0033712109649257083</td>\n      <td>m: 0.9560234541577826 std: 0.006663113006396548</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>SVC(C=100, degree=4, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 4</td>\n      <td>0.954128</td>\n      <td>0.950180</td>\n      <td>0.956023</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9501797216032235 std: 0.0033712109649257083</td>\n      <td>m: 0.9560234541577826 std: 0.006663113006396548</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>SVC(C=100, degree=5, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 5</td>\n      <td>0.954128</td>\n      <td>0.950180</td>\n      <td>0.956023</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9501797216032235 std: 0.0033712109649257083</td>\n      <td>m: 0.9560234541577826 std: 0.006663113006396548</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>SVC(C=100, degree=6, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 6</td>\n      <td>0.954128</td>\n      <td>0.950180</td>\n      <td>0.956023</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9501797216032235 std: 0.0033712109649257083</td>\n      <td>m: 0.9560234541577826 std: 0.006663113006396548</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>SVC(C=100, degree=7, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 7</td>\n      <td>0.954128</td>\n      <td>0.950180</td>\n      <td>0.956023</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9501797216032235 std: 0.0033712109649257083</td>\n      <td>m: 0.9560234541577826 std: 0.006663113006396548</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>SVC(C=100, degree=8, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 8</td>\n      <td>0.954128</td>\n      <td>0.950180</td>\n      <td>0.956023</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9501797216032235 std: 0.0033712109649257083</td>\n      <td>m: 0.9560234541577826 std: 0.006663113006396548</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>SVC(C=100, degree=1, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.954128</td>\n      <td>0.950180</td>\n      <td>0.956023</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9501797216032235 std: 0.0033712109649257083</td>\n      <td>m: 0.9560234541577826 std: 0.006663113006396548</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>SVC(C=100, degree=9, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 9</td>\n      <td>0.954128</td>\n      <td>0.950180</td>\n      <td>0.956023</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9501797216032235 std: 0.0033712109649257083</td>\n      <td>m: 0.9560234541577826 std: 0.006663113006396548</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>SVC(C=100, degree=5, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 5</td>\n      <td>0.954128</td>\n      <td>0.950647</td>\n      <td>0.953802</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9506469940618524 std: 0.002903938506296888</td>\n      <td>m: 0.9538024164889837 std: 0.004442075337597662</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>SVC(C=100, degree=5, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 5</td>\n      <td>0.954128</td>\n      <td>0.952116</td>\n      <td>0.951581</td>\n      <td>m: 0.9541284403669725 std: 0.009174311926605505</td>\n      <td>m: 0.9521156379852032 std: 0.006101145231580007</td>\n      <td>m: 0.9515813788201848 std: 0.014125799573560749</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>SVC(C=100, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 3</td>\n      <td>0.954128</td>\n      <td>0.950647</td>\n      <td>0.953802</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9506469940618524 std: 0.002903938506296888</td>\n      <td>m: 0.9538024164889837 std: 0.004442075337597662</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>SVC(C=100, degree=2, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 2</td>\n      <td>0.954128</td>\n      <td>0.950180</td>\n      <td>0.956023</td>\n      <td>m: 0.9541284403669725 std: 0.0</td>\n      <td>m: 0.9501797216032235 std: 0.0033712109649257083</td>\n      <td>m: 0.9560234541577826 std: 0.006663113006396548</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>SVC(C=100, degree=4, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 4</td>\n      <td>0.949541</td>\n      <td>0.946879</td>\n      <td>0.947850</td>\n      <td>m: 0.9495412844036697 std: 0.00458715596330278</td>\n      <td>m: 0.9468787741545893 std: 0.0008642814009661715</td>\n      <td>m: 0.9478500355366026 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>SVC(C=100, degree=6, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 6</td>\n      <td>0.949541</td>\n      <td>0.947990</td>\n      <td>0.945629</td>\n      <td>m: 0.9495412844036697 std: 0.00458715596330278</td>\n      <td>m: 0.9479896283359377 std: 0.0019751355823145467</td>\n      <td>m: 0.9456289978678039 std: 0.008173418621179762</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>SVC(C=100, degree=6, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 6</td>\n      <td>0.949541</td>\n      <td>0.946879</td>\n      <td>0.947850</td>\n      <td>m: 0.9495412844036697 std: 0.00458715596330278</td>\n      <td>m: 0.9468787741545893 std: 0.0008642814009661715</td>\n      <td>m: 0.9478500355366026 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>SVC(C=100, degree=4, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 4</td>\n      <td>0.949541</td>\n      <td>0.946879</td>\n      <td>0.947850</td>\n      <td>m: 0.9495412844036697 std: 0.00458715596330278</td>\n      <td>m: 0.9468787741545893 std: 0.0008642814009661715</td>\n      <td>m: 0.9478500355366026 std: 0.010394456289978649</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>SVC(C=100, degree=1, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.944954</td>\n      <td>0.940828</td>\n      <td>0.946340</td>\n      <td>m: 0.9449541284403671 std: 0.009174311926605505</td>\n      <td>m: 0.9408283146025372 std: 0.012722617965612026</td>\n      <td>m: 0.9463397299218195 std: 0.003020611229566539</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>SVC(C=100, degree=7, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 7</td>\n      <td>0.944954</td>\n      <td>0.943956</td>\n      <td>0.939677</td>\n      <td>m: 0.944954128440367 std: 0.0</td>\n      <td>m: 0.9439560736689224 std: 0.0020584190847007244</td>\n      <td>m: 0.9396766169154229 std: 0.002221037668798831</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SVC(C=100, degree=1, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.940367</td>\n      <td>0.936230</td>\n      <td>0.940387</td>\n      <td>m: 0.9403669724770642 std: 0.013761467889908285</td>\n      <td>m: 0.9362302626953928 std: 0.01732066987275649</td>\n      <td>m: 0.9403873489694385 std: 0.00897299218194747</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SVC(C=100, degree=8, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 8</td>\n      <td>0.931193</td>\n      <td>0.932348</td>\n      <td>0.921819</td>\n      <td>m: 0.9311926605504588 std: 0.01376146788990823</td>\n      <td>m: 0.932347905717471 std: 0.0136665870361522</td>\n      <td>m: 0.92181947405828 std: 0.01563610518834402</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>SVC(C=100, degree=7, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 7</td>\n      <td>0.931193</td>\n      <td>0.932348</td>\n      <td>0.921819</td>\n      <td>m: 0.9311926605504588 std: 0.01376146788990823</td>\n      <td>m: 0.932347905717471 std: 0.0136665870361522</td>\n      <td>m: 0.92181947405828 std: 0.01563610518834402</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>SVC(C=100, degree=9, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 9</td>\n      <td>0.931193</td>\n      <td>0.935038</td>\n      <td>0.919598</td>\n      <td>m: 0.9311926605504588 std: 0.00458715596330278</td>\n      <td>m: 0.9350376890221219 std: 0.00360699962256672</td>\n      <td>m: 0.9195984363894811 std: 0.005952380952380931</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>SVC(C=100, degree=8, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 8</td>\n      <td>0.894495</td>\n      <td>0.907595</td>\n      <td>0.871979</td>\n      <td>m: 0.8944954128440368 std: 0.02293577981651379</td>\n      <td>m: 0.907594891969892 std: 0.016766969891969907</td>\n      <td>m: 0.8719793887704336 std: 0.029761904761904767</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>SVC(C=100, degree=9, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 9</td>\n      <td>0.876147</td>\n      <td>0.898559</td>\n      <td>0.845949</td>\n      <td>m: 0.8761467889908257 std: 0.02293577981651379</td>\n      <td>m: 0.8985590414471161 std: 0.02049996971715823</td>\n      <td>m: 0.8459488272921108 std: 0.02754086709310588</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SVC(C=100, degree=8, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 8</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>SVC(C=100, degree=7, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 7</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVC(C=100, degree=2, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 2</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVC(C=100, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 3</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SVC(C=100, degree=4, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 4</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SVC(C=100, degree=5, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 5</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>SVC(C=100, degree=9, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 9</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>SVC(C=100, degree=6, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 6</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        SVC(C=100, degree=1, gamma=0.001, kernel='poly')\narguments                                  Kernel: poly, Degree: 1\nmean_accuracy                                              0.96789\nmean_precision                                            0.962041\nmean_recall                                               0.973881\naccuracy            m: 0.9678899082568808 std: 0.01376146788990823\nprecision          m: 0.9620406189555126 std: 0.015232108317214721\nrecall             m: 0.9738805970149254 std: 0.011194029850746245\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_results_vote = calculate_svm(votingDataLearn[votingDataLearn.columns[2:18]],\n",
    "                                 votingDataLearn[\"class\"])\n",
    "overall_results_vote.extend(svm_results_vote)\n",
    "\n",
    "print_results(svm_results_vote, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overall Results for Congressional Vote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n68                  SVC(C=100, degree=7, gamma=0.001)   \n63                  SVC(C=100, degree=2, gamma=0.001)   \n66                  SVC(C=100, degree=5, gamma=0.001)   \n67                  SVC(C=100, degree=6, gamma=0.001)   \n16  DecisionTreeClassifier(max_depth=1, min_sample...   \n..                                                ...   \n34  DecisionTreeClassifier(max_depth=9, min_sample...   \n36   SVC(C=100, degree=2, gamma=0.001, kernel='poly')   \n37             SVC(C=100, gamma=0.001, kernel='poly')   \n38   SVC(C=100, degree=4, gamma=0.001, kernel='poly')   \n26  DecisionTreeClassifier(max_depth=5, min_sample...   \n\n                         arguments  mean_accuracy  mean_precision  \\\n68          Kernel: rbf, Degree: 7       0.967890        0.962041   \n63          Kernel: rbf, Degree: 2       0.967890        0.962041   \n66          Kernel: rbf, Degree: 5       0.967890        0.962041   \n67          Kernel: rbf, Degree: 6       0.967890        0.962041   \n16   max Depth: 1, min Samples: 20       0.967890        0.962041   \n..                             ...            ...             ...   \n34  max Depth: 9, min Samples: 100       0.614679        0.307339   \n36         Kernel: poly, Degree: 2       0.614679        0.307339   \n37         Kernel: poly, Degree: 3       0.614679        0.307339   \n38         Kernel: poly, Degree: 4       0.614679        0.307339   \n26  max Depth: 5, min Samples: 100       0.614679        0.307339   \n\n    mean_recall                                        accuracy  \\\n68     0.973881  m: 0.9678899082568808 std: 0.01376146788990823   \n63     0.973881  m: 0.9678899082568808 std: 0.01376146788990823   \n66     0.973881  m: 0.9678899082568808 std: 0.01376146788990823   \n67     0.973881  m: 0.9678899082568808 std: 0.01376146788990823   \n16     0.973881  m: 0.9678899082568808 std: 0.01376146788990823   \n..          ...                                             ...   \n34     0.500000                  m: 0.6146788990825688 std: 0.0   \n36     0.500000                  m: 0.6146788990825688 std: 0.0   \n37     0.500000                  m: 0.6146788990825688 std: 0.0   \n38     0.500000                  m: 0.6146788990825688 std: 0.0   \n26     0.500000                  m: 0.6146788990825688 std: 0.0   \n\n                                          precision  \\\n68  m: 0.9620406189555126 std: 0.015232108317214721   \n63  m: 0.9620406189555126 std: 0.015232108317214721   \n66  m: 0.9620406189555126 std: 0.015232108317214721   \n67  m: 0.9620406189555126 std: 0.015232108317214721   \n16  m: 0.9620406189555126 std: 0.015232108317214721   \n..                                              ...   \n34                   m: 0.3073394495412844 std: 0.0   \n36                   m: 0.3073394495412844 std: 0.0   \n37                   m: 0.3073394495412844 std: 0.0   \n38                   m: 0.3073394495412844 std: 0.0   \n26                   m: 0.3073394495412844 std: 0.0   \n\n                                             recall  \n68  m: 0.9738805970149254 std: 0.011194029850746245  \n63  m: 0.9738805970149254 std: 0.011194029850746245  \n66  m: 0.9738805970149254 std: 0.011194029850746245  \n67  m: 0.9738805970149254 std: 0.011194029850746245  \n16  m: 0.9738805970149254 std: 0.011194029850746245  \n..                                              ...  \n34                                  m: 0.5 std: 0.0  \n36                                  m: 0.5 std: 0.0  \n37                                  m: 0.5 std: 0.0  \n38                                  m: 0.5 std: 0.0  \n26                                  m: 0.5 std: 0.0  \n\n[89 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>68</th>\n      <td>SVC(C=100, degree=7, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 7</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>SVC(C=100, degree=2, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 2</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>SVC(C=100, degree=5, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 5</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>SVC(C=100, degree=6, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 6</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 20</td>\n      <td>0.967890</td>\n      <td>0.962041</td>\n      <td>0.973881</td>\n      <td>m: 0.9678899082568808 std: 0.01376146788990823</td>\n      <td>m: 0.9620406189555126 std: 0.015232108317214721</td>\n      <td>m: 0.9738805970149254 std: 0.011194029850746245</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 100</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>SVC(C=100, degree=2, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 2</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>SVC(C=100, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 3</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>SVC(C=100, degree=4, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 4</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 100</td>\n      <td>0.614679</td>\n      <td>0.307339</td>\n      <td>0.500000</td>\n      <td>m: 0.6146788990825688 std: 0.0</td>\n      <td>m: 0.3073394495412844 std: 0.0</td>\n      <td>m: 0.5 std: 0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>89 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                      SVC(C=100, degree=7, gamma=0.001)\narguments                                  Kernel: rbf, Degree: 7\nmean_accuracy                                             0.96789\nmean_precision                                           0.962041\nmean_recall                                              0.973881\naccuracy           m: 0.9678899082568808 std: 0.01376146788990823\nprecision         m: 0.9620406189555126 std: 0.015232108317214721\nrecall            m: 0.9738805970149254 std: 0.011194029850746245\nName: 68, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_results(overall_results_vote, \"mean_accuracy\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train submission file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\informatik\\tw_mle_exercise3\\venv\\lib\\site-packages\\sklearn\\impute\\_iterative.py:670: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Finally recoded: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID       class\n0     13    democrat\n1    393  republican\n2    163    democrat\n3     57  republican\n4    148    democrat\n..   ...         ...\n212  359    democrat\n213  128    democrat\n214   27    democrat\n215  119    democrat\n216  133  republican\n\n[217 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>393</td>\n      <td>republican</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>163</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>57</td>\n      <td>republican</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>148</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>359</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>128</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>27</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>119</td>\n      <td>democrat</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>133</td>\n      <td>republican</td>\n    </tr>\n  </tbody>\n</table>\n<p>217 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Required Imports\n",
    "from sklearn import svm\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Recode values for predicting variables\n",
    "def recode_voting_data(dataset):\n",
    "    dataset = dataset.replace('y', 1)\\\n",
    "        .replace('n', 0)\n",
    "    dataset[dataset.columns[1:18]] = dataset[dataset.columns[1:18]].astype('category')\n",
    "    return pd.DataFrame(dataset, columns=dataset.columns)\n",
    "\n",
    "#Imput missing values\n",
    "def input_missing_values(data):\n",
    "    columns = data.columns\n",
    "    imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "    imp.fit(data.loc[:, data.columns != \"ID\"])\n",
    "    data.loc[:, data.columns != \"ID\"] = np.round(imp.transform(data.loc[:, data.columns != \"ID\"]))\n",
    "    data.loc[:, data.columns != \"ID\"] = data.loc[:, data.columns != \"ID\"].apply(lambda x: x.astype('int'))\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "#Read Data\n",
    "votingDataLearn = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.lrn.csv\", na_values='unknown')\n",
    "votingDataTest = pd.read_csv(\"data/voting/CongressionalVotingID.shuf.tes.csv\", na_values='unknown')\n",
    "\n",
    "#Extract target variable\n",
    "votingDataLearn = votingDataLearn.replace('democrat', 2)\\\n",
    "    .replace('republican', 3)\n",
    "\n",
    "y = votingDataLearn[\"class\"]\n",
    "X = pd.DataFrame(votingDataLearn.drop([\"ID\", \"class\"], axis=1))\n",
    "\n",
    "X = recode_voting_data(X)\n",
    "X = input_missing_values(X)\n",
    "votingDataTest = recode_voting_data(votingDataTest)\n",
    "votingDataTest = input_missing_values(votingDataTest)\n",
    "\n",
    "#Calculate Model\n",
    "classifier = svm.SVC(kernel = \"rbf\", gamma=0.001, C=100)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "#Predict the Test Data\n",
    "votingDataTest[\"class\"] = classifier.predict(votingDataTest[votingDataTest.columns[1:18]])\n",
    "\n",
    "#Recode to required output\n",
    "votingDataTest[\"class\"].replace({2: \"democrat\", 3: \"republican\"}, inplace=True)\n",
    "display(\"Finally recoded: \", votingDataTest[[\"ID\", \"class\"]])\n",
    "votingDataTest[[\"ID\", \"class\"]].to_csv(\"solution_voting.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "'Original Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9992  V9993  V9994  V9995  \\\n0      0   9   5   5   9   7   0   8   7   1  ...      0      1      0      1   \n1      1  11   9  15  15   5  11  10   1   5  ...      0      0      0      0   \n2      2  11  10  13  12   6   5   0   3   1  ...      0      0      0      0   \n3      3  18   9   7   8   8   7  12   6   7  ...      0      1      0      0   \n4      4  11   7  10  11   4   5   1   8   4  ...      0      0      0      0   \n..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...    ...    ...    ...   \n745  745   5   5   8   2   8   0   5   1   2  ...      1      0      0      0   \n746  746  22  13   8  14   8  11   3   6   7  ...      6      0      2      0   \n747  747  10   3   5   5   7   1  14   2   6  ...      0      0      4      1   \n748  748   9  13   8   5  11   9   9   3   3  ...      0      0      0      1   \n749  749  12   5   8   4   7   5   0   3   4  ...      0      0      4      0   \n\n     V9996  V9997  V9998  V9999  V10000        Class  \n0        0      0      0      0       2        Power  \n1        0      0      0      0       0       Goonan  \n2        0      0      0      1       0      Merritt  \n3        0      1      0      0       1       Goonan  \n4        0      1      0      0       3         Corn  \n..     ...    ...    ...    ...     ...          ...  \n745      0      0      0      0       0      Chachra  \n746      0      2      0      0       0     Morrison  \n747      0      0      2      0       0      Sherwin  \n748      0      0      0      0       0  Blankenship  \n749      1      0      0      0       0     Davisson  \n\n[750 rows x 10002 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>9</td>\n      <td>7</td>\n      <td>0</td>\n      <td>8</td>\n      <td>7</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Power</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11</td>\n      <td>9</td>\n      <td>15</td>\n      <td>15</td>\n      <td>5</td>\n      <td>11</td>\n      <td>10</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>11</td>\n      <td>10</td>\n      <td>13</td>\n      <td>12</td>\n      <td>6</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Merritt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>18</td>\n      <td>9</td>\n      <td>7</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>12</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>11</td>\n      <td>7</td>\n      <td>10</td>\n      <td>11</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>8</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Corn</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>745</td>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Chachra</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>746</td>\n      <td>22</td>\n      <td>13</td>\n      <td>8</td>\n      <td>14</td>\n      <td>8</td>\n      <td>11</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Morrison</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>747</td>\n      <td>10</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1</td>\n      <td>14</td>\n      <td>2</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sherwin</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>748</td>\n      <td>9</td>\n      <td>13</td>\n      <td>8</td>\n      <td>5</td>\n      <td>11</td>\n      <td>9</td>\n      <td>9</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Blankenship</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>749</td>\n      <td>12</td>\n      <td>5</td>\n      <td>8</td>\n      <td>4</td>\n      <td>7</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Davisson</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10002 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Recoded Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9992  V9993  V9994  V9995  \\\n0      0   9   5   5   9   7   0   8   7   1  ...      0      1      0      1   \n1      1  11   9  15  15   5  11  10   1   5  ...      0      0      0      0   \n2      2  11  10  13  12   6   5   0   3   1  ...      0      0      0      0   \n3      3  18   9   7   8   8   7  12   6   7  ...      0      1      0      0   \n4      4  11   7  10  11   4   5   1   8   4  ...      0      0      0      0   \n..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...    ...    ...    ...   \n745  745   5   5   8   2   8   0   5   1   2  ...      1      0      0      0   \n746  746  22  13   8  14   8  11   3   6   7  ...      6      0      2      0   \n747  747  10   3   5   5   7   1  14   2   6  ...      0      0      4      1   \n748  748   9  13   8   5  11   9   9   3   3  ...      0      0      0      1   \n749  749  12   5   8   4   7   5   0   3   4  ...      0      0      4      0   \n\n     V9996  V9997  V9998  V9999  V10000        Class  \n0        0      0      0      0       2        Power  \n1        0      0      0      0       0       Goonan  \n2        0      0      0      1       0      Merritt  \n3        0      1      0      0       1       Goonan  \n4        0      1      0      0       3         Corn  \n..     ...    ...    ...    ...     ...          ...  \n745      0      0      0      0       0      Chachra  \n746      0      2      0      0       0     Morrison  \n747      0      0      2      0       0      Sherwin  \n748      0      0      0      0       0  Blankenship  \n749      1      0      0      0       0     Davisson  \n\n[750 rows x 10002 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>9</td>\n      <td>7</td>\n      <td>0</td>\n      <td>8</td>\n      <td>7</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Power</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11</td>\n      <td>9</td>\n      <td>15</td>\n      <td>15</td>\n      <td>5</td>\n      <td>11</td>\n      <td>10</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>11</td>\n      <td>10</td>\n      <td>13</td>\n      <td>12</td>\n      <td>6</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Merritt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>18</td>\n      <td>9</td>\n      <td>7</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>12</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>11</td>\n      <td>7</td>\n      <td>10</td>\n      <td>11</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>8</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Corn</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>745</td>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Chachra</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>746</td>\n      <td>22</td>\n      <td>13</td>\n      <td>8</td>\n      <td>14</td>\n      <td>8</td>\n      <td>11</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Morrison</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>747</td>\n      <td>10</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1</td>\n      <td>14</td>\n      <td>2</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sherwin</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>748</td>\n      <td>9</td>\n      <td>13</td>\n      <td>8</td>\n      <td>5</td>\n      <td>11</td>\n      <td>9</td>\n      <td>9</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Blankenship</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>749</td>\n      <td>12</td>\n      <td>5</td>\n      <td>8</td>\n      <td>4</td>\n      <td>7</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Davisson</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10002 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Data: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "           V1        V2        V3        V4        V5        V6        V7  \\\n0    0.022849  0.012694  0.012694  0.022849  0.017771  0.000000  0.020310   \n1    0.030256  0.024755  0.041258  0.041258  0.013753  0.030256  0.027505   \n2    0.028761  0.026146  0.033990  0.031376  0.015688  0.013073  0.000000   \n3    0.041891  0.020946  0.016291  0.018618  0.018618  0.016291  0.027927   \n4    0.028918  0.018402  0.026289  0.028918  0.010516  0.013145  0.002629   \n..        ...       ...       ...       ...       ...       ...       ...   \n745  0.026867  0.026867  0.042987  0.010747  0.042987  0.000000  0.026867   \n746  0.048706  0.028781  0.017711  0.030995  0.017711  0.024353  0.006642   \n747  0.026260  0.007878  0.013130  0.013130  0.018382  0.002626  0.036764   \n748  0.025152  0.036330  0.022357  0.013973  0.030741  0.025152  0.025152   \n749  0.036478  0.015199  0.024319  0.012159  0.021279  0.015199  0.000000   \n\n           V8        V9       V10  ...     V9991     V9992     V9993  \\\n0    0.017771  0.002539  0.012694  ...  0.000000  0.000000  0.002539   \n1    0.002751  0.013753  0.019254  ...  0.000000  0.000000  0.000000   \n2    0.007844  0.002615  0.002615  ...  0.002615  0.000000  0.000000   \n3    0.013964  0.016291  0.002327  ...  0.000000  0.000000  0.002327   \n4    0.021031  0.010516  0.010516  ...  0.000000  0.000000  0.000000   \n..        ...       ...       ...  ...       ...       ...       ...   \n745  0.005373  0.010747  0.016120  ...  0.000000  0.005373  0.000000   \n746  0.013284  0.015497  0.013284  ...  0.000000  0.013284  0.000000   \n747  0.005252  0.015756  0.002626  ...  0.000000  0.000000  0.000000   \n748  0.008384  0.008384  0.016768  ...  0.000000  0.000000  0.000000   \n749  0.009120  0.012159  0.012159  ...  0.000000  0.000000  0.000000   \n\n        V9994     V9995    V9996     V9997     V9998     V9999    V10000  \n0    0.000000  0.002539  0.00000  0.000000  0.000000  0.000000  0.005077  \n1    0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n2    0.000000  0.000000  0.00000  0.000000  0.000000  0.002615  0.000000  \n3    0.000000  0.000000  0.00000  0.002327  0.000000  0.000000  0.002327  \n4    0.000000  0.000000  0.00000  0.002629  0.000000  0.000000  0.007887  \n..        ...       ...      ...       ...       ...       ...       ...  \n745  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n746  0.004428  0.000000  0.00000  0.004428  0.000000  0.000000  0.000000  \n747  0.010504  0.002626  0.00000  0.000000  0.005252  0.000000  0.000000  \n748  0.000000  0.002795  0.00000  0.000000  0.000000  0.000000  0.000000  \n749  0.012159  0.000000  0.00304  0.000000  0.000000  0.000000  0.000000  \n\n[750 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.022849</td>\n      <td>0.012694</td>\n      <td>0.012694</td>\n      <td>0.022849</td>\n      <td>0.017771</td>\n      <td>0.000000</td>\n      <td>0.020310</td>\n      <td>0.017771</td>\n      <td>0.002539</td>\n      <td>0.012694</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002539</td>\n      <td>0.000000</td>\n      <td>0.002539</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005077</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.030256</td>\n      <td>0.024755</td>\n      <td>0.041258</td>\n      <td>0.041258</td>\n      <td>0.013753</td>\n      <td>0.030256</td>\n      <td>0.027505</td>\n      <td>0.002751</td>\n      <td>0.013753</td>\n      <td>0.019254</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.028761</td>\n      <td>0.026146</td>\n      <td>0.033990</td>\n      <td>0.031376</td>\n      <td>0.015688</td>\n      <td>0.013073</td>\n      <td>0.000000</td>\n      <td>0.007844</td>\n      <td>0.002615</td>\n      <td>0.002615</td>\n      <td>...</td>\n      <td>0.002615</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002615</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.041891</td>\n      <td>0.020946</td>\n      <td>0.016291</td>\n      <td>0.018618</td>\n      <td>0.018618</td>\n      <td>0.016291</td>\n      <td>0.027927</td>\n      <td>0.013964</td>\n      <td>0.016291</td>\n      <td>0.002327</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002327</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.002327</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002327</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.028918</td>\n      <td>0.018402</td>\n      <td>0.026289</td>\n      <td>0.028918</td>\n      <td>0.010516</td>\n      <td>0.013145</td>\n      <td>0.002629</td>\n      <td>0.021031</td>\n      <td>0.010516</td>\n      <td>0.010516</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.002629</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.007887</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>0.026867</td>\n      <td>0.026867</td>\n      <td>0.042987</td>\n      <td>0.010747</td>\n      <td>0.042987</td>\n      <td>0.000000</td>\n      <td>0.026867</td>\n      <td>0.005373</td>\n      <td>0.010747</td>\n      <td>0.016120</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.005373</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>0.048706</td>\n      <td>0.028781</td>\n      <td>0.017711</td>\n      <td>0.030995</td>\n      <td>0.017711</td>\n      <td>0.024353</td>\n      <td>0.006642</td>\n      <td>0.013284</td>\n      <td>0.015497</td>\n      <td>0.013284</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.013284</td>\n      <td>0.000000</td>\n      <td>0.004428</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.004428</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>0.026260</td>\n      <td>0.007878</td>\n      <td>0.013130</td>\n      <td>0.013130</td>\n      <td>0.018382</td>\n      <td>0.002626</td>\n      <td>0.036764</td>\n      <td>0.005252</td>\n      <td>0.015756</td>\n      <td>0.002626</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010504</td>\n      <td>0.002626</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.005252</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>0.025152</td>\n      <td>0.036330</td>\n      <td>0.022357</td>\n      <td>0.013973</td>\n      <td>0.030741</td>\n      <td>0.025152</td>\n      <td>0.025152</td>\n      <td>0.008384</td>\n      <td>0.008384</td>\n      <td>0.016768</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002795</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>0.036478</td>\n      <td>0.015199</td>\n      <td>0.024319</td>\n      <td>0.012159</td>\n      <td>0.021279</td>\n      <td>0.015199</td>\n      <td>0.000000</td>\n      <td>0.009120</td>\n      <td>0.012159</td>\n      <td>0.012159</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012159</td>\n      <td>0.000000</td>\n      <td>0.00304</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Target: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0            Power\n1           Goonan\n2          Merritt\n3           Goonan\n4             Corn\n          ...     \n745        Chachra\n746       Morrison\n747        Sherwin\n748    Blankenship\n749       Davisson\nName: Class, Length: 750, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "#Read Data\n",
    "amazonDataLearn = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.lrn.csv\")\n",
    "amazonDataSolutionExample = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.sol.ex.csv\")\n",
    "amazonDataTest = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.tes.csv\")\n",
    "display(\"Original Data\", amazonDataLearn)\n",
    "\n",
    "#Recode values\n",
    "#For One Hot Encoding of Class\n",
    "#amazonDataLearn = pd.concat([amazonDataLearn, pd.get_dummies(amazonDataLearn[\"Class\"], prefix='author_',drop_first=False)], axis=1)\n",
    "#amazonDataLearn.drop(['Class'],axis=1, inplace=True)\n",
    "#names_target = amazonDataLearn.loc[:, amazonDataLearn.columns.str.startswith('author_')]\n",
    "#amazonDataLearn[names_target.columns] = amazonDataLearn[names_target.columns].apply(lambda x: x.astype('category'))\n",
    "\n",
    "# For Label Encoding\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#le.fit(amazonDataLearn['Class'])\n",
    "#amazonDataLearn['Class'] = le.transform(amazonDataLearn['Class'])\n",
    "#amazonDataLearn['Class'] = amazonDataLearn['Class'].astype('category')\n",
    "\n",
    "names_data = amazonDataLearn.loc[:, amazonDataLearn.columns.str.startswith('V')]\n",
    "#amazonDataLearn[0:10000] = amazonDataLearn[0:10000].apply(lambda x: x.astype('int'))\n",
    "\n",
    "# Normalize data\n",
    "def normalize_values(data):\n",
    "    columns = data.columns\n",
    "    data = preprocessing.Normalizer().fit_transform(data)\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "display(\"Recoded Data\", amazonDataLearn)\n",
    "\n",
    "X_amazon = normalize_values(amazonDataLearn[names_data.columns])\n",
    "y_amazon = amazonDataLearn[\"Class\"]\n",
    "\n",
    "display(\"Data: \", X_amazon)\n",
    "display(\"Target: \", y_amazon)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### k-NN Calculation - Amazon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                            classifier arguments  mean_accuracy  \\\n0  KNeighborsClassifier(n_neighbors=1)     N = 1       0.217333   \n6  KNeighborsClassifier(n_neighbors=7)     N = 7       0.201333   \n4               KNeighborsClassifier()     N = 5       0.196000   \n7  KNeighborsClassifier(n_neighbors=8)     N = 8       0.192000   \n2  KNeighborsClassifier(n_neighbors=3)     N = 3       0.186667   \n8  KNeighborsClassifier(n_neighbors=9)     N = 9       0.186667   \n5  KNeighborsClassifier(n_neighbors=6)     N = 6       0.184000   \n1  KNeighborsClassifier(n_neighbors=2)     N = 2       0.181333   \n3  KNeighborsClassifier(n_neighbors=4)     N = 4       0.180000   \n\n   mean_precision  mean_recall  \\\n0        0.269663     0.213175   \n6        0.300936     0.195698   \n4        0.291129     0.195845   \n7        0.261385     0.185873   \n2        0.276623     0.188579   \n8        0.239957     0.180512   \n5        0.245926     0.180817   \n1        0.237999     0.182520   \n3        0.251769     0.178675   \n\n                                            accuracy  \\\n0   m: 0.21733333333333332 std: 0.009333333333333332   \n6    m: 0.2013333333333333 std: 0.025333333333333333   \n4                m: 0.196 std: 0.0040000000000000036   \n7                 m: 0.192 std: 0.026666666666666672   \n2  m: 0.18666666666666665 std: 0.0026666666666666644   \n8   m: 0.18666666666666665 std: 0.024000000000000007   \n5                 m: 0.184 std: 0.005333333333333329   \n1   m: 0.18133333333333335 std: 0.013333333333333322   \n3                  m: 0.18 std: 0.011999999999999997   \n\n                                          precision  \\\n0   m: 0.2696625644505507 std: 0.020481226845872155   \n6    m: 0.3009359955461926 std: 0.05788954817545304   \n4   m: 0.2911289372651379 std: 0.004014736670988839   \n7    m: 0.2613846367265696 std: 0.03556916600664496   \n2  m: 0.27662335266991456 std: 0.004006194104617361   \n8  m: 0.23995687630346438 std: 0.027838393842211456   \n5  m: 0.24592593293881482 std: 0.018142273364685588   \n1  m: 0.23799941938395774 std: 0.013408418616183526   \n3   m: 0.2517694421882424 std: 0.008939613408469882   \n\n                                             recall  \n0  m: 0.21317460317460316 std: 0.009952380952380935  \n6   m: 0.1956984126984127 std: 0.028539682539682545  \n4  m: 0.19584523809523807 std: 0.004146825396825385  \n7  m: 0.18587301587301586 std: 0.029031746031746034  \n2   m: 0.1885793650793651 std: 0.004230158730158723  \n8  m: 0.18051190476190476 std: 0.025615079365079355  \n5  m: 0.18081746031746032 std: 0.008349206349206342  \n1   m: 0.18251984126984128 std: 0.01686904761904763  \n3   m: 0.17867460317460318 std: 0.01111904761904764  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KNeighborsClassifier(n_neighbors=1)</td>\n      <td>N = 1</td>\n      <td>0.217333</td>\n      <td>0.269663</td>\n      <td>0.213175</td>\n      <td>m: 0.21733333333333332 std: 0.009333333333333332</td>\n      <td>m: 0.2696625644505507 std: 0.020481226845872155</td>\n      <td>m: 0.21317460317460316 std: 0.009952380952380935</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>KNeighborsClassifier(n_neighbors=7)</td>\n      <td>N = 7</td>\n      <td>0.201333</td>\n      <td>0.300936</td>\n      <td>0.195698</td>\n      <td>m: 0.2013333333333333 std: 0.025333333333333333</td>\n      <td>m: 0.3009359955461926 std: 0.05788954817545304</td>\n      <td>m: 0.1956984126984127 std: 0.028539682539682545</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNeighborsClassifier()</td>\n      <td>N = 5</td>\n      <td>0.196000</td>\n      <td>0.291129</td>\n      <td>0.195845</td>\n      <td>m: 0.196 std: 0.0040000000000000036</td>\n      <td>m: 0.2911289372651379 std: 0.004014736670988839</td>\n      <td>m: 0.19584523809523807 std: 0.004146825396825385</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>KNeighborsClassifier(n_neighbors=8)</td>\n      <td>N = 8</td>\n      <td>0.192000</td>\n      <td>0.261385</td>\n      <td>0.185873</td>\n      <td>m: 0.192 std: 0.026666666666666672</td>\n      <td>m: 0.2613846367265696 std: 0.03556916600664496</td>\n      <td>m: 0.18587301587301586 std: 0.029031746031746034</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KNeighborsClassifier(n_neighbors=3)</td>\n      <td>N = 3</td>\n      <td>0.186667</td>\n      <td>0.276623</td>\n      <td>0.188579</td>\n      <td>m: 0.18666666666666665 std: 0.0026666666666666644</td>\n      <td>m: 0.27662335266991456 std: 0.004006194104617361</td>\n      <td>m: 0.1885793650793651 std: 0.004230158730158723</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>KNeighborsClassifier(n_neighbors=9)</td>\n      <td>N = 9</td>\n      <td>0.186667</td>\n      <td>0.239957</td>\n      <td>0.180512</td>\n      <td>m: 0.18666666666666665 std: 0.024000000000000007</td>\n      <td>m: 0.23995687630346438 std: 0.027838393842211456</td>\n      <td>m: 0.18051190476190476 std: 0.025615079365079355</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNeighborsClassifier(n_neighbors=6)</td>\n      <td>N = 6</td>\n      <td>0.184000</td>\n      <td>0.245926</td>\n      <td>0.180817</td>\n      <td>m: 0.184 std: 0.005333333333333329</td>\n      <td>m: 0.24592593293881482 std: 0.018142273364685588</td>\n      <td>m: 0.18081746031746032 std: 0.008349206349206342</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KNeighborsClassifier(n_neighbors=2)</td>\n      <td>N = 2</td>\n      <td>0.181333</td>\n      <td>0.237999</td>\n      <td>0.182520</td>\n      <td>m: 0.18133333333333335 std: 0.013333333333333322</td>\n      <td>m: 0.23799941938395774 std: 0.013408418616183526</td>\n      <td>m: 0.18251984126984128 std: 0.01686904761904763</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KNeighborsClassifier(n_neighbors=4)</td>\n      <td>N = 4</td>\n      <td>0.180000</td>\n      <td>0.251769</td>\n      <td>0.178675</td>\n      <td>m: 0.18 std: 0.011999999999999997</td>\n      <td>m: 0.2517694421882424 std: 0.008939613408469882</td>\n      <td>m: 0.17867460317460318 std: 0.01111904761904764</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                     KNeighborsClassifier(n_neighbors=1)\narguments                                                    N = 1\nmean_accuracy                                             0.217333\nmean_precision                                            0.269663\nmean_recall                                               0.213175\naccuracy          m: 0.21733333333333332 std: 0.009333333333333332\nprecision          m: 0.2696625644505507 std: 0.020481226845872155\nrecall            m: 0.21317460317460316 std: 0.009952380952380935\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_results_amazon = calculate_knn(X_amazon,\n",
    "                                   y_amazon)\n",
    "overall_results_amazon.extend(knn_results_amazon)\n",
    "\n",
    "print_results(knn_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     classifier            arguments  mean_accuracy  mean_precision  \\\n0  Perceptron()  No additional args.       0.113333        0.126572   \n\n   mean_recall                                          accuracy  \\\n0     0.107762  m: 0.11333333333333334 std: 0.006666666666666661   \n\n                                          precision  \\\n0  m: 0.12657218917034596 std: 0.003983440323285119   \n\n                                            recall  \n0  m: 0.10776190476190475 std: 0.00871428571428571  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Perceptron()</td>\n      <td>No additional args.</td>\n      <td>0.113333</td>\n      <td>0.126572</td>\n      <td>0.107762</td>\n      <td>m: 0.11333333333333334 std: 0.006666666666666661</td>\n      <td>m: 0.12657218917034596 std: 0.003983440323285119</td>\n      <td>m: 0.10776190476190475 std: 0.00871428571428571</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                                            Perceptron()\narguments                                      No additional args.\nmean_accuracy                                             0.113333\nmean_precision                                            0.126572\nmean_recall                                               0.107762\naccuracy          m: 0.11333333333333334 std: 0.006666666666666661\nprecision         m: 0.12657218917034596 std: 0.003983440323285119\nrecall             m: 0.10776190476190475 std: 0.00871428571428571\nName: 0, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perceptron_results_amazon = calculate_perceptron(X_amazon,\n",
    "                                                 y_amazon)\n",
    "overall_results_amazon.extend(perceptron_results_amazon)\n",
    "\n",
    "print_results(perceptron_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n16  DecisionTreeClassifier(max_depth=9, min_sample...   \n12  DecisionTreeClassifier(max_depth=7, min_sample...   \n17  DecisionTreeClassifier(max_depth=9, min_sample...   \n13  DecisionTreeClassifier(max_depth=7, min_sample...   \n9   DecisionTreeClassifier(max_depth=5, min_sample...   \n8   DecisionTreeClassifier(max_depth=5, min_sample...   \n4   DecisionTreeClassifier(max_depth=3, min_sample...   \n10  DecisionTreeClassifier(max_depth=5, min_sample...   \n18  DecisionTreeClassifier(max_depth=9, min_sample...   \n14  DecisionTreeClassifier(max_depth=7, min_sample...   \n5   DecisionTreeClassifier(max_depth=3, min_sample...   \n6   DecisionTreeClassifier(max_depth=3, min_sample...   \n15  DecisionTreeClassifier(max_depth=7, min_sample...   \n19  DecisionTreeClassifier(max_depth=9, min_sample...   \n11  DecisionTreeClassifier(max_depth=5, min_sample...   \n7   DecisionTreeClassifier(max_depth=3, min_sample...   \n0   DecisionTreeClassifier(max_depth=1, min_sample...   \n1   DecisionTreeClassifier(max_depth=1, min_sample...   \n3   DecisionTreeClassifier(max_depth=1, min_sample...   \n2   DecisionTreeClassifier(max_depth=1, min_sample...   \n\n                         arguments  mean_accuracy  mean_precision  \\\n16    max Depth: 9, min Samples: 2       0.184000        0.166816   \n12    max Depth: 7, min Samples: 2       0.157333        0.138446   \n17   max Depth: 9, min Samples: 20       0.149333        0.050988   \n13   max Depth: 7, min Samples: 20       0.138667        0.046267   \n9    max Depth: 5, min Samples: 20       0.133333        0.036094   \n8     max Depth: 5, min Samples: 2       0.130667        0.098178   \n4     max Depth: 3, min Samples: 2       0.086667        0.058152   \n10   max Depth: 5, min Samples: 50       0.085333        0.009337   \n18   max Depth: 9, min Samples: 50       0.085333        0.009337   \n14   max Depth: 7, min Samples: 50       0.085333        0.009337   \n5    max Depth: 3, min Samples: 20       0.084000        0.018251   \n6    max Depth: 3, min Samples: 50       0.072000        0.006790   \n15  max Depth: 7, min Samples: 100       0.054667        0.003419   \n19  max Depth: 9, min Samples: 100       0.054667        0.003419   \n11  max Depth: 5, min Samples: 100       0.054667        0.003419   \n7   max Depth: 3, min Samples: 100       0.054667        0.003419   \n0     max Depth: 1, min Samples: 2       0.045333        0.020490   \n1    max Depth: 1, min Samples: 20       0.040000        0.009083   \n3   max Depth: 1, min Samples: 100       0.038667        0.001815   \n2    max Depth: 1, min Samples: 50       0.038667        0.002053   \n\n    mean_recall                                           accuracy  \\\n16     0.170480                 m: 0.184 std: 0.008000000000000007   \n12     0.141512   m: 0.15733333333333333 std: 0.007999999999999993   \n17     0.138817                    m: 0.14933333333333335 std: 0.0   \n13     0.128817   m: 0.13866666666666666 std: 0.008000000000000007   \n9      0.122556  m: 0.13333333333333333 std: 0.0026666666666666783   \n8      0.117639  m: 0.13066666666666665 std: 0.0026666666666666644   \n4      0.077639  m: 0.08666666666666667 std: 0.0013333333333333322   \n10     0.075472   m: 0.08533333333333333 std: 0.013333333333333336   \n18     0.075472   m: 0.08533333333333333 std: 0.013333333333333336   \n14     0.075472   m: 0.08533333333333333 std: 0.013333333333333336   \n5      0.073833                 m: 0.084 std: 0.009333333333333332   \n6      0.062694                  m: 0.07200000000000001 std: 0.008   \n15     0.045889                  m: 0.05466666666666667 std: 0.004   \n19     0.045889                  m: 0.05466666666666667 std: 0.004   \n11     0.045889                  m: 0.05466666666666667 std: 0.004   \n7      0.045889                  m: 0.05466666666666667 std: 0.004   \n0      0.040000                    m: 0.04533333333333334 std: 0.0   \n1      0.032444                                   m: 0.04 std: 0.0   \n3      0.032444                  m: 0.03866666666666667 std: 0.004   \n2      0.035556                  m: 0.03866666666666667 std: 0.004   \n\n                                            precision  \\\n16    m: 0.1668159040067333 std: 0.012119436015563298   \n12   m: 0.13844625015164747 std: 0.007118013171236559   \n17  m: 0.050988080219772955 std: 0.002261685195509698   \n13  m: 0.04626707162461866 std: 0.0007024033448563075   \n9   m: 0.036093533583553446 std: 0.000897945951404...   \n8   m: 0.09817781104457751 std: 0.0023611111111111055   \n4    m: 0.058152442002442004 std: 0.00236037851037851   \n10  m: 0.009336784884282716 std: 0.000723376317361...   \n18  m: 0.009336784884282716 std: 0.000723376317361...   \n14  m: 0.009336784884282716 std: 0.000723376317361...   \n5   m: 0.01825082317230025 std: 0.0015268537786979324   \n6   m: 0.006789785110799179 std: 6.436419686305095...   \n15  m: 0.0034187673455698215 std: 5.21529458128403...   \n19  m: 0.0034187673455698215 std: 5.21529458128403...   \n11  m: 0.0034187673455698215 std: 5.21529458128403...   \n7   m: 0.0034187673455698215 std: 5.21529458128403...   \n0                    m: 0.020490463215258856 std: 0.0   \n1   m: 0.009082597803947276 std: 0.001413269964647...   \n3   m: 0.0018147876372591764 std: 4.93769063312042...   \n2   m: 0.0020530253453077754 std: 0.00028761461437...   \n\n                                               recall  \n16   m: 0.17048015873015873 std: 0.009932539682539682  \n12   m: 0.14151190476190476 std: 0.007789682539682541  \n17  m: 0.13881746031746034 std: 9.523809523810656e-05  \n13   m: 0.12881746031746033 std: 0.007126984126984134  \n9   m: 0.12255555555555556 std: 0.0061666666666666745  \n8   m: 0.11763888888888889 std: 0.0001388888888888...  \n4   m: 0.0776388888888889 std: 0.00013888888888888978  \n10   m: 0.07547222222222223 std: 0.014805555555555561  \n18   m: 0.07547222222222223 std: 0.014805555555555561  \n14   m: 0.07547222222222223 std: 0.014805555555555561  \n5    m: 0.07383333333333333 std: 0.008000000000000007  \n6    m: 0.06269444444444444 std: 0.010083333333333333  \n15  m: 0.04588888888888889 std: 0.0030000000000000027  \n19  m: 0.04588888888888889 std: 0.0030000000000000027  \n11  m: 0.04588888888888889 std: 0.0030000000000000027  \n7   m: 0.04588888888888889 std: 0.0030000000000000027  \n0                                    m: 0.04 std: 0.0  \n1    m: 0.03244444444444444 std: 0.000888888888888887  \n3   m: 0.03244444444444444 std: 0.0013333333333333322  \n2   m: 0.035555555555555556 std: 0.004444444444444445  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 2</td>\n      <td>0.184000</td>\n      <td>0.166816</td>\n      <td>0.170480</td>\n      <td>m: 0.184 std: 0.008000000000000007</td>\n      <td>m: 0.1668159040067333 std: 0.012119436015563298</td>\n      <td>m: 0.17048015873015873 std: 0.009932539682539682</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 2</td>\n      <td>0.157333</td>\n      <td>0.138446</td>\n      <td>0.141512</td>\n      <td>m: 0.15733333333333333 std: 0.007999999999999993</td>\n      <td>m: 0.13844625015164747 std: 0.007118013171236559</td>\n      <td>m: 0.14151190476190476 std: 0.007789682539682541</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 20</td>\n      <td>0.149333</td>\n      <td>0.050988</td>\n      <td>0.138817</td>\n      <td>m: 0.14933333333333335 std: 0.0</td>\n      <td>m: 0.050988080219772955 std: 0.002261685195509698</td>\n      <td>m: 0.13881746031746034 std: 9.523809523810656e-05</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 20</td>\n      <td>0.138667</td>\n      <td>0.046267</td>\n      <td>0.128817</td>\n      <td>m: 0.13866666666666666 std: 0.008000000000000007</td>\n      <td>m: 0.04626707162461866 std: 0.0007024033448563075</td>\n      <td>m: 0.12881746031746033 std: 0.007126984126984134</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 20</td>\n      <td>0.133333</td>\n      <td>0.036094</td>\n      <td>0.122556</td>\n      <td>m: 0.13333333333333333 std: 0.0026666666666666783</td>\n      <td>m: 0.036093533583553446 std: 0.000897945951404...</td>\n      <td>m: 0.12255555555555556 std: 0.0061666666666666745</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 2</td>\n      <td>0.130667</td>\n      <td>0.098178</td>\n      <td>0.117639</td>\n      <td>m: 0.13066666666666665 std: 0.0026666666666666644</td>\n      <td>m: 0.09817781104457751 std: 0.0023611111111111055</td>\n      <td>m: 0.11763888888888889 std: 0.0001388888888888...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 2</td>\n      <td>0.086667</td>\n      <td>0.058152</td>\n      <td>0.077639</td>\n      <td>m: 0.08666666666666667 std: 0.0013333333333333322</td>\n      <td>m: 0.058152442002442004 std: 0.00236037851037851</td>\n      <td>m: 0.0776388888888889 std: 0.00013888888888888978</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 50</td>\n      <td>0.085333</td>\n      <td>0.009337</td>\n      <td>0.075472</td>\n      <td>m: 0.08533333333333333 std: 0.013333333333333336</td>\n      <td>m: 0.009336784884282716 std: 0.000723376317361...</td>\n      <td>m: 0.07547222222222223 std: 0.014805555555555561</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 50</td>\n      <td>0.085333</td>\n      <td>0.009337</td>\n      <td>0.075472</td>\n      <td>m: 0.08533333333333333 std: 0.013333333333333336</td>\n      <td>m: 0.009336784884282716 std: 0.000723376317361...</td>\n      <td>m: 0.07547222222222223 std: 0.014805555555555561</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 50</td>\n      <td>0.085333</td>\n      <td>0.009337</td>\n      <td>0.075472</td>\n      <td>m: 0.08533333333333333 std: 0.013333333333333336</td>\n      <td>m: 0.009336784884282716 std: 0.000723376317361...</td>\n      <td>m: 0.07547222222222223 std: 0.014805555555555561</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 20</td>\n      <td>0.084000</td>\n      <td>0.018251</td>\n      <td>0.073833</td>\n      <td>m: 0.084 std: 0.009333333333333332</td>\n      <td>m: 0.01825082317230025 std: 0.0015268537786979324</td>\n      <td>m: 0.07383333333333333 std: 0.008000000000000007</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 50</td>\n      <td>0.072000</td>\n      <td>0.006790</td>\n      <td>0.062694</td>\n      <td>m: 0.07200000000000001 std: 0.008</td>\n      <td>m: 0.006789785110799179 std: 6.436419686305095...</td>\n      <td>m: 0.06269444444444444 std: 0.010083333333333333</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>DecisionTreeClassifier(max_depth=7, min_sample...</td>\n      <td>max Depth: 7, min Samples: 100</td>\n      <td>0.054667</td>\n      <td>0.003419</td>\n      <td>0.045889</td>\n      <td>m: 0.05466666666666667 std: 0.004</td>\n      <td>m: 0.0034187673455698215 std: 5.21529458128403...</td>\n      <td>m: 0.04588888888888889 std: 0.0030000000000000027</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>DecisionTreeClassifier(max_depth=9, min_sample...</td>\n      <td>max Depth: 9, min Samples: 100</td>\n      <td>0.054667</td>\n      <td>0.003419</td>\n      <td>0.045889</td>\n      <td>m: 0.05466666666666667 std: 0.004</td>\n      <td>m: 0.0034187673455698215 std: 5.21529458128403...</td>\n      <td>m: 0.04588888888888889 std: 0.0030000000000000027</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>DecisionTreeClassifier(max_depth=5, min_sample...</td>\n      <td>max Depth: 5, min Samples: 100</td>\n      <td>0.054667</td>\n      <td>0.003419</td>\n      <td>0.045889</td>\n      <td>m: 0.05466666666666667 std: 0.004</td>\n      <td>m: 0.0034187673455698215 std: 5.21529458128403...</td>\n      <td>m: 0.04588888888888889 std: 0.0030000000000000027</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n      <td>max Depth: 3, min Samples: 100</td>\n      <td>0.054667</td>\n      <td>0.003419</td>\n      <td>0.045889</td>\n      <td>m: 0.05466666666666667 std: 0.004</td>\n      <td>m: 0.0034187673455698215 std: 5.21529458128403...</td>\n      <td>m: 0.04588888888888889 std: 0.0030000000000000027</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 2</td>\n      <td>0.045333</td>\n      <td>0.020490</td>\n      <td>0.040000</td>\n      <td>m: 0.04533333333333334 std: 0.0</td>\n      <td>m: 0.020490463215258856 std: 0.0</td>\n      <td>m: 0.04 std: 0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 20</td>\n      <td>0.040000</td>\n      <td>0.009083</td>\n      <td>0.032444</td>\n      <td>m: 0.04 std: 0.0</td>\n      <td>m: 0.009082597803947276 std: 0.001413269964647...</td>\n      <td>m: 0.03244444444444444 std: 0.000888888888888887</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 100</td>\n      <td>0.038667</td>\n      <td>0.001815</td>\n      <td>0.032444</td>\n      <td>m: 0.03866666666666667 std: 0.004</td>\n      <td>m: 0.0018147876372591764 std: 4.93769063312042...</td>\n      <td>m: 0.03244444444444444 std: 0.0013333333333333322</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 50</td>\n      <td>0.038667</td>\n      <td>0.002053</td>\n      <td>0.035556</td>\n      <td>m: 0.03866666666666667 std: 0.004</td>\n      <td>m: 0.0020530253453077754 std: 0.00028761461437...</td>\n      <td>m: 0.035555555555555556 std: 0.004444444444444445</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier        DecisionTreeClassifier(max_depth=9, min_sample...\narguments                              max Depth: 9, min Samples: 2\nmean_accuracy                                                 0.184\nmean_precision                                             0.166816\nmean_recall                                                 0.17048\naccuracy                         m: 0.184 std: 0.008000000000000007\nprecision           m: 0.1668159040067333 std: 0.012119436015563298\nrecall             m: 0.17048015873015873 std: 0.009932539682539682\nName: 16, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_results_amazon = calculate_decision_tree(X_amazon,\n",
    "                                                       y_amazon)\n",
    "overall_results_amazon.extend(decision_tree_results_amazon)\n",
    "\n",
    "print_results(decision_tree_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM - Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n11                          SVC(C=100, kernel='poly')   \n10                SVC(C=100, degree=2, kernel='poly')   \n39                               SVC(C=100, degree=4)   \n42                               SVC(C=100, degree=7)   \n41                               SVC(C=100, degree=6)   \n43                               SVC(C=100, degree=8)   \n40                               SVC(C=100, degree=5)   \n44                               SVC(C=100, degree=9)   \n38                                         SVC(C=100)   \n37                               SVC(C=100, degree=2)   \n36                               SVC(C=100, degree=1)   \n12                SVC(C=100, degree=4, kernel='poly')   \n13                SVC(C=100, degree=5, kernel='poly')   \n9                 SVC(C=100, degree=1, kernel='poly')   \n14                SVC(C=100, degree=6, kernel='poly')   \n15                SVC(C=100, degree=7, kernel='poly')   \n17                SVC(C=100, degree=9, kernel='poly')   \n16                SVC(C=100, degree=8, kernel='poly')   \n35                  SVC(C=100, degree=9, gamma=0.001)   \n34                  SVC(C=100, degree=8, gamma=0.001)   \n0    SVC(C=100, degree=1, gamma=0.001, kernel='poly')   \n45                 SVC(C=100, degree=1, gamma='auto')   \n32                  SVC(C=100, degree=6, gamma=0.001)   \n46                 SVC(C=100, degree=2, gamma='auto')   \n47                           SVC(C=100, gamma='auto')   \n48                 SVC(C=100, degree=4, gamma='auto')   \n49                 SVC(C=100, degree=5, gamma='auto')   \n50                 SVC(C=100, degree=6, gamma='auto')   \n51                 SVC(C=100, degree=7, gamma='auto')   \n52                 SVC(C=100, degree=8, gamma='auto')   \n33                  SVC(C=100, degree=7, gamma=0.001)   \n27                  SVC(C=100, degree=1, gamma=0.001)   \n31                  SVC(C=100, degree=5, gamma=0.001)   \n21  SVC(C=100, degree=4, gamma='auto', kernel='poly')   \n2              SVC(C=100, gamma=0.001, kernel='poly')   \n3    SVC(C=100, degree=4, gamma=0.001, kernel='poly')   \n4    SVC(C=100, degree=5, gamma=0.001, kernel='poly')   \n18  SVC(C=100, degree=1, gamma='auto', kernel='poly')   \n19  SVC(C=100, degree=2, gamma='auto', kernel='poly')   \n30                  SVC(C=100, degree=4, gamma=0.001)   \n20            SVC(C=100, gamma='auto', kernel='poly')   \n1    SVC(C=100, degree=2, gamma=0.001, kernel='poly')   \n28                  SVC(C=100, degree=2, gamma=0.001)   \n29                            SVC(C=100, gamma=0.001)   \n53                 SVC(C=100, degree=9, gamma='auto')   \n22  SVC(C=100, degree=5, gamma='auto', kernel='poly')   \n23  SVC(C=100, degree=6, gamma='auto', kernel='poly')   \n24  SVC(C=100, degree=7, gamma='auto', kernel='poly')   \n25  SVC(C=100, degree=8, gamma='auto', kernel='poly')   \n26  SVC(C=100, degree=9, gamma='auto', kernel='poly')   \n8    SVC(C=100, degree=9, gamma=0.001, kernel='poly')   \n7    SVC(C=100, degree=8, gamma=0.001, kernel='poly')   \n6    SVC(C=100, degree=7, gamma=0.001, kernel='poly')   \n5    SVC(C=100, degree=6, gamma=0.001, kernel='poly')   \n\n                  arguments  mean_accuracy  mean_precision  mean_recall  \\\n11  Kernel: poly, Degree: 3       0.418667        0.483627     0.404425   \n10  Kernel: poly, Degree: 2       0.417333        0.482069     0.402440   \n39   Kernel: rbf, Degree: 4       0.417333        0.483697     0.402996   \n42   Kernel: rbf, Degree: 7       0.417333        0.483697     0.402996   \n41   Kernel: rbf, Degree: 6       0.417333        0.483697     0.402996   \n43   Kernel: rbf, Degree: 8       0.417333        0.483697     0.402996   \n40   Kernel: rbf, Degree: 5       0.417333        0.483697     0.402996   \n44   Kernel: rbf, Degree: 9       0.417333        0.483697     0.402996   \n38   Kernel: rbf, Degree: 3       0.417333        0.483697     0.402996   \n37   Kernel: rbf, Degree: 2       0.417333        0.483697     0.402996   \n36   Kernel: rbf, Degree: 1       0.417333        0.483697     0.402996   \n12  Kernel: poly, Degree: 4       0.416000        0.481845     0.401429   \n13  Kernel: poly, Degree: 5       0.413333        0.478494     0.397984   \n9   Kernel: poly, Degree: 1       0.412000        0.478034     0.397651   \n14  Kernel: poly, Degree: 6       0.412000        0.478126     0.396694   \n15  Kernel: poly, Degree: 7       0.412000        0.486139     0.397012   \n17  Kernel: poly, Degree: 9       0.410667        0.491669     0.395762   \n16  Kernel: poly, Degree: 8       0.409333        0.491941     0.394512   \n35   Kernel: rbf, Degree: 9       0.048000        0.004968     0.038000   \n34   Kernel: rbf, Degree: 8       0.048000        0.004968     0.038000   \n0   Kernel: poly, Degree: 1       0.048000        0.004968     0.038000   \n45   Kernel: rbf, Degree: 1       0.048000        0.005045     0.038000   \n32   Kernel: rbf, Degree: 6       0.048000        0.004968     0.038000   \n46   Kernel: rbf, Degree: 2       0.048000        0.005045     0.038000   \n47   Kernel: rbf, Degree: 3       0.048000        0.005045     0.038000   \n48   Kernel: rbf, Degree: 4       0.048000        0.005045     0.038000   \n49   Kernel: rbf, Degree: 5       0.048000        0.005045     0.038000   \n50   Kernel: rbf, Degree: 6       0.048000        0.005045     0.038000   \n51   Kernel: rbf, Degree: 7       0.048000        0.005045     0.038000   \n52   Kernel: rbf, Degree: 8       0.048000        0.005045     0.038000   \n33   Kernel: rbf, Degree: 7       0.048000        0.004968     0.038000   \n27   Kernel: rbf, Degree: 1       0.048000        0.004968     0.038000   \n31   Kernel: rbf, Degree: 5       0.048000        0.004968     0.038000   \n21  Kernel: poly, Degree: 4       0.048000        0.004626     0.038000   \n2   Kernel: poly, Degree: 3       0.048000        0.004754     0.038000   \n3   Kernel: poly, Degree: 4       0.048000        0.004754     0.038000   \n4   Kernel: poly, Degree: 5       0.048000        0.004754     0.038000   \n18  Kernel: poly, Degree: 1       0.048000        0.004968     0.038000   \n19  Kernel: poly, Degree: 2       0.048000        0.004787     0.038000   \n30   Kernel: rbf, Degree: 4       0.048000        0.004968     0.038000   \n20  Kernel: poly, Degree: 3       0.048000        0.004754     0.038000   \n1   Kernel: poly, Degree: 2       0.048000        0.004787     0.038000   \n28   Kernel: rbf, Degree: 2       0.048000        0.004968     0.038000   \n29   Kernel: rbf, Degree: 3       0.048000        0.004968     0.038000   \n53   Kernel: rbf, Degree: 9       0.048000        0.005045     0.038000   \n22  Kernel: poly, Degree: 5       0.044000        0.014574     0.034444   \n23  Kernel: poly, Degree: 6       0.044000        0.014574     0.034444   \n24  Kernel: poly, Degree: 7       0.044000        0.014574     0.034444   \n25  Kernel: poly, Degree: 8       0.044000        0.014577     0.034444   \n26  Kernel: poly, Degree: 9       0.044000        0.014577     0.034444   \n8   Kernel: poly, Degree: 9       0.044000        0.014577     0.034444   \n7   Kernel: poly, Degree: 8       0.044000        0.014577     0.034444   \n6   Kernel: poly, Degree: 7       0.044000        0.014574     0.034444   \n5   Kernel: poly, Degree: 6       0.044000        0.014574     0.034444   \n\n                                            accuracy  \\\n11  m: 0.41866666666666663 std: 0.013333333333333336   \n10   m: 0.41733333333333333 std: 0.00933333333333336   \n39   m: 0.41733333333333333 std: 0.01200000000000001   \n42   m: 0.41733333333333333 std: 0.01200000000000001   \n41   m: 0.41733333333333333 std: 0.01200000000000001   \n43   m: 0.41733333333333333 std: 0.01200000000000001   \n40   m: 0.41733333333333333 std: 0.01200000000000001   \n44   m: 0.41733333333333333 std: 0.01200000000000001   \n38   m: 0.41733333333333333 std: 0.01200000000000001   \n37   m: 0.41733333333333333 std: 0.01200000000000001   \n36   m: 0.41733333333333333 std: 0.01200000000000001   \n12  m: 0.41600000000000004 std: 0.010666666666666685   \n13  m: 0.41333333333333333 std: 0.008000000000000007   \n9   m: 0.41200000000000003 std: 0.009333333333333332   \n14  m: 0.41200000000000003 std: 0.009333333333333332   \n15               m: 0.412 std: 0.0040000000000000036   \n17   m: 0.4106666666666666 std: 0.005333333333333329   \n16   m: 0.4093333333333333 std: 0.006666666666666654   \n35               m: 0.048 std: 0.0026666666666666644   \n34               m: 0.048 std: 0.0026666666666666644   \n0                m: 0.048 std: 0.0026666666666666644   \n45               m: 0.048 std: 0.0026666666666666644   \n32               m: 0.048 std: 0.0026666666666666644   \n46               m: 0.048 std: 0.0026666666666666644   \n47               m: 0.048 std: 0.0026666666666666644   \n48               m: 0.048 std: 0.0026666666666666644   \n49               m: 0.048 std: 0.0026666666666666644   \n50               m: 0.048 std: 0.0026666666666666644   \n51               m: 0.048 std: 0.0026666666666666644   \n52               m: 0.048 std: 0.0026666666666666644   \n33               m: 0.048 std: 0.0026666666666666644   \n27               m: 0.048 std: 0.0026666666666666644   \n31               m: 0.048 std: 0.0026666666666666644   \n21               m: 0.048 std: 0.0026666666666666644   \n2                m: 0.048 std: 0.0026666666666666644   \n3                m: 0.048 std: 0.0026666666666666644   \n4                m: 0.048 std: 0.0026666666666666644   \n18               m: 0.048 std: 0.0026666666666666644   \n19               m: 0.048 std: 0.0026666666666666644   \n30               m: 0.048 std: 0.0026666666666666644   \n20               m: 0.048 std: 0.0026666666666666644   \n1                m: 0.048 std: 0.0026666666666666644   \n28               m: 0.048 std: 0.0026666666666666644   \n29               m: 0.048 std: 0.0026666666666666644   \n53               m: 0.048 std: 0.0026666666666666644   \n22               m: 0.044 std: 0.0066666666666666645   \n23               m: 0.044 std: 0.0066666666666666645   \n24               m: 0.044 std: 0.0066666666666666645   \n25               m: 0.044 std: 0.0066666666666666645   \n26               m: 0.044 std: 0.0066666666666666645   \n8                m: 0.044 std: 0.0066666666666666645   \n7                m: 0.044 std: 0.0066666666666666645   \n6                m: 0.044 std: 0.0066666666666666645   \n5                m: 0.044 std: 0.0066666666666666645   \n\n                                            precision  \\\n11    m: 0.48362695634707353 std: 0.03974960098829397   \n10     m: 0.4820687265950423 std: 0.03974360726992307   \n39     m: 0.4836967850690761 std: 0.03981942971029659   \n42     m: 0.4836967850690761 std: 0.03981942971029659   \n41     m: 0.4836967850690761 std: 0.03981942971029659   \n43     m: 0.4836967850690761 std: 0.03981942971029659   \n40     m: 0.4836967850690761 std: 0.03981942971029659   \n44     m: 0.4836967850690761 std: 0.03981942971029659   \n38     m: 0.4836967850690761 std: 0.03981942971029659   \n37     m: 0.4836967850690761 std: 0.03981942971029659   \n36     m: 0.4836967850690761 std: 0.03981942971029659   \n12    m: 0.48184537100326574 std: 0.03584039644565962   \n13    m: 0.47849419059201664 std: 0.03292276202058814   \n9       m: 0.4780344275607433 std: 0.0358839669102827   \n14   m: 0.47812576953938507 std: 0.035026202439817966   \n15     m: 0.4861388675524831 std: 0.02237962679324229   \n17     m: 0.4916692130240051 std: 0.02510261295740504   \n16    m: 0.4919414407962328 std: 0.025774829629621715   \n35   m: 0.004967729707035586 std: 0.00094235637546429   \n34   m: 0.004967729707035586 std: 0.00094235637546429   \n0    m: 0.004967729707035586 std: 0.00094235637546429   \n45  m: 0.005045128182694597 std: 0.000864957899805...   \n32   m: 0.004967729707035586 std: 0.00094235637546429   \n46  m: 0.005045128182694597 std: 0.000864957899805...   \n47  m: 0.005045128182694597 std: 0.000864957899805...   \n48  m: 0.005045128182694597 std: 0.000864957899805...   \n49  m: 0.005045128182694597 std: 0.000864957899805...   \n50  m: 0.005045128182694597 std: 0.000864957899805...   \n51  m: 0.005045128182694597 std: 0.000864957899805...   \n52  m: 0.005045128182694597 std: 0.000864957899805...   \n33   m: 0.004967729707035586 std: 0.00094235637546429   \n27   m: 0.004967729707035586 std: 0.00094235637546429   \n31   m: 0.004967729707035586 std: 0.00094235637546429   \n21  m: 0.00462556568311918 std: 0.0008717195292730264   \n2   m: 0.004753610427907947 std: 0.000936157066195...   \n3   m: 0.004753610427907947 std: 0.000936157066195...   \n4   m: 0.004753610427907947 std: 0.000936157066195...   \n18   m: 0.004967729707035586 std: 0.00094235637546429   \n19  m: 0.004786779771516388 std: 0.000902987722586...   \n30   m: 0.004967729707035586 std: 0.00094235637546429   \n20  m: 0.004753610427907947 std: 0.000936157066195...   \n1   m: 0.004786779771516388 std: 0.000902987722586...   \n28   m: 0.004967729707035586 std: 0.00094235637546429   \n29   m: 0.004967729707035586 std: 0.00094235637546429   \n53  m: 0.005045128182694597 std: 0.000864957899805...   \n22   m: 0.01457434070069862 std: 0.007356709846704132   \n23   m: 0.01457434070069862 std: 0.007356709846704132   \n24   m: 0.01457434070069862 std: 0.007356709846704132   \n25  m: 0.014577076360155063 std: 0.007359445506160574   \n26  m: 0.014577076360155063 std: 0.007359445506160574   \n8   m: 0.014577076360155063 std: 0.007359445506160574   \n7   m: 0.014577076360155063 std: 0.007359445506160574   \n6    m: 0.01457434070069862 std: 0.007356709846704132   \n5    m: 0.01457434070069862 std: 0.007356709846704132   \n\n                                               recall  \n11   m: 0.40442460317460316 std: 0.016067460317460258  \n10      m: 0.4024404761904761 std: 0.0118611111111111  \n39     m: 0.4029960317460317 std: 0.01463888888888884  \n42     m: 0.4029960317460317 std: 0.01463888888888884  \n41     m: 0.4029960317460317 std: 0.01463888888888884  \n43     m: 0.4029960317460317 std: 0.01463888888888884  \n40     m: 0.4029960317460317 std: 0.01463888888888884  \n44     m: 0.4029960317460317 std: 0.01463888888888884  \n38     m: 0.4029960317460317 std: 0.01463888888888884  \n37     m: 0.4029960317460317 std: 0.01463888888888884  \n36     m: 0.4029960317460317 std: 0.01463888888888884  \n12    m: 0.40142857142857147 std: 0.01307142857142854  \n13     m: 0.397984126984127 std: 0.009626984126984067  \n9     m: 0.3976507936507937 std: 0.011793650793650773  \n14   m: 0.39669444444444446 std: 0.010559523809523824  \n15  m: 0.39701190476190473 std: 0.0057976190476190514  \n17  m: 0.39576190476190476 std: 0.0070476190476190526  \n16   m: 0.39451190476190473 std: 0.008297619047619054  \n35                m: 0.038 std: 0.0022222222222222227  \n34                m: 0.038 std: 0.0022222222222222227  \n0                 m: 0.038 std: 0.0022222222222222227  \n45                m: 0.038 std: 0.0022222222222222227  \n32                m: 0.038 std: 0.0022222222222222227  \n46                m: 0.038 std: 0.0022222222222222227  \n47                m: 0.038 std: 0.0022222222222222227  \n48                m: 0.038 std: 0.0022222222222222227  \n49                m: 0.038 std: 0.0022222222222222227  \n50                m: 0.038 std: 0.0022222222222222227  \n51                m: 0.038 std: 0.0022222222222222227  \n52                m: 0.038 std: 0.0022222222222222227  \n33                m: 0.038 std: 0.0022222222222222227  \n27                m: 0.038 std: 0.0022222222222222227  \n31                m: 0.038 std: 0.0022222222222222227  \n21                m: 0.038 std: 0.0022222222222222227  \n2                 m: 0.038 std: 0.0022222222222222227  \n3                 m: 0.038 std: 0.0022222222222222227  \n4                 m: 0.038 std: 0.0022222222222222227  \n18                m: 0.038 std: 0.0022222222222222227  \n19                m: 0.038 std: 0.0022222222222222227  \n30                m: 0.038 std: 0.0022222222222222227  \n20                m: 0.038 std: 0.0022222222222222227  \n1                 m: 0.038 std: 0.0022222222222222227  \n28                m: 0.038 std: 0.0022222222222222227  \n29                m: 0.038 std: 0.0022222222222222227  \n53                m: 0.038 std: 0.0022222222222222227  \n22  m: 0.034444444444444444 std: 0.005555555555555557  \n23  m: 0.034444444444444444 std: 0.005555555555555557  \n24  m: 0.034444444444444444 std: 0.005555555555555557  \n25  m: 0.034444444444444444 std: 0.005555555555555557  \n26  m: 0.034444444444444444 std: 0.005555555555555557  \n8   m: 0.034444444444444444 std: 0.005555555555555557  \n7   m: 0.034444444444444444 std: 0.005555555555555557  \n6   m: 0.034444444444444444 std: 0.005555555555555557  \n5   m: 0.034444444444444444 std: 0.005555555555555557  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>SVC(C=100, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 3</td>\n      <td>0.418667</td>\n      <td>0.483627</td>\n      <td>0.404425</td>\n      <td>m: 0.41866666666666663 std: 0.013333333333333336</td>\n      <td>m: 0.48362695634707353 std: 0.03974960098829397</td>\n      <td>m: 0.40442460317460316 std: 0.016067460317460258</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>SVC(C=100, degree=2, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 2</td>\n      <td>0.417333</td>\n      <td>0.482069</td>\n      <td>0.402440</td>\n      <td>m: 0.41733333333333333 std: 0.00933333333333336</td>\n      <td>m: 0.4820687265950423 std: 0.03974360726992307</td>\n      <td>m: 0.4024404761904761 std: 0.0118611111111111</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>SVC(C=100, degree=4)</td>\n      <td>Kernel: rbf, Degree: 4</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>SVC(C=100, degree=7)</td>\n      <td>Kernel: rbf, Degree: 7</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>SVC(C=100, degree=6)</td>\n      <td>Kernel: rbf, Degree: 6</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>SVC(C=100, degree=8)</td>\n      <td>Kernel: rbf, Degree: 8</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>SVC(C=100, degree=5)</td>\n      <td>Kernel: rbf, Degree: 5</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>SVC(C=100, degree=9)</td>\n      <td>Kernel: rbf, Degree: 9</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>SVC(C=100)</td>\n      <td>Kernel: rbf, Degree: 3</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>SVC(C=100, degree=2)</td>\n      <td>Kernel: rbf, Degree: 2</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>SVC(C=100, degree=1)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>SVC(C=100, degree=4, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 4</td>\n      <td>0.416000</td>\n      <td>0.481845</td>\n      <td>0.401429</td>\n      <td>m: 0.41600000000000004 std: 0.010666666666666685</td>\n      <td>m: 0.48184537100326574 std: 0.03584039644565962</td>\n      <td>m: 0.40142857142857147 std: 0.01307142857142854</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>SVC(C=100, degree=5, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 5</td>\n      <td>0.413333</td>\n      <td>0.478494</td>\n      <td>0.397984</td>\n      <td>m: 0.41333333333333333 std: 0.008000000000000007</td>\n      <td>m: 0.47849419059201664 std: 0.03292276202058814</td>\n      <td>m: 0.397984126984127 std: 0.009626984126984067</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SVC(C=100, degree=1, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.412000</td>\n      <td>0.478034</td>\n      <td>0.397651</td>\n      <td>m: 0.41200000000000003 std: 0.009333333333333332</td>\n      <td>m: 0.4780344275607433 std: 0.0358839669102827</td>\n      <td>m: 0.3976507936507937 std: 0.011793650793650773</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>SVC(C=100, degree=6, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 6</td>\n      <td>0.412000</td>\n      <td>0.478126</td>\n      <td>0.396694</td>\n      <td>m: 0.41200000000000003 std: 0.009333333333333332</td>\n      <td>m: 0.47812576953938507 std: 0.035026202439817966</td>\n      <td>m: 0.39669444444444446 std: 0.010559523809523824</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>SVC(C=100, degree=7, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 7</td>\n      <td>0.412000</td>\n      <td>0.486139</td>\n      <td>0.397012</td>\n      <td>m: 0.412 std: 0.0040000000000000036</td>\n      <td>m: 0.4861388675524831 std: 0.02237962679324229</td>\n      <td>m: 0.39701190476190473 std: 0.0057976190476190514</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>SVC(C=100, degree=9, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 9</td>\n      <td>0.410667</td>\n      <td>0.491669</td>\n      <td>0.395762</td>\n      <td>m: 0.4106666666666666 std: 0.005333333333333329</td>\n      <td>m: 0.4916692130240051 std: 0.02510261295740504</td>\n      <td>m: 0.39576190476190476 std: 0.0070476190476190526</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SVC(C=100, degree=8, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 8</td>\n      <td>0.409333</td>\n      <td>0.491941</td>\n      <td>0.394512</td>\n      <td>m: 0.4093333333333333 std: 0.006666666666666654</td>\n      <td>m: 0.4919414407962328 std: 0.025774829629621715</td>\n      <td>m: 0.39451190476190473 std: 0.008297619047619054</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>SVC(C=100, degree=9, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 9</td>\n      <td>0.048000</td>\n      <td>0.004968</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004967729707035586 std: 0.00094235637546429</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>SVC(C=100, degree=8, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 8</td>\n      <td>0.048000</td>\n      <td>0.004968</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004967729707035586 std: 0.00094235637546429</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>SVC(C=100, degree=1, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.048000</td>\n      <td>0.004968</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004967729707035586 std: 0.00094235637546429</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>SVC(C=100, degree=1, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.048000</td>\n      <td>0.005045</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.005045128182694597 std: 0.000864957899805...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>SVC(C=100, degree=6, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 6</td>\n      <td>0.048000</td>\n      <td>0.004968</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004967729707035586 std: 0.00094235637546429</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>SVC(C=100, degree=2, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 2</td>\n      <td>0.048000</td>\n      <td>0.005045</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.005045128182694597 std: 0.000864957899805...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>SVC(C=100, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 3</td>\n      <td>0.048000</td>\n      <td>0.005045</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.005045128182694597 std: 0.000864957899805...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>SVC(C=100, degree=4, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 4</td>\n      <td>0.048000</td>\n      <td>0.005045</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.005045128182694597 std: 0.000864957899805...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>SVC(C=100, degree=5, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 5</td>\n      <td>0.048000</td>\n      <td>0.005045</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.005045128182694597 std: 0.000864957899805...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>SVC(C=100, degree=6, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 6</td>\n      <td>0.048000</td>\n      <td>0.005045</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.005045128182694597 std: 0.000864957899805...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>SVC(C=100, degree=7, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 7</td>\n      <td>0.048000</td>\n      <td>0.005045</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.005045128182694597 std: 0.000864957899805...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>SVC(C=100, degree=8, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 8</td>\n      <td>0.048000</td>\n      <td>0.005045</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.005045128182694597 std: 0.000864957899805...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>SVC(C=100, degree=7, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 7</td>\n      <td>0.048000</td>\n      <td>0.004968</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004967729707035586 std: 0.00094235637546429</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>SVC(C=100, degree=1, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.048000</td>\n      <td>0.004968</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004967729707035586 std: 0.00094235637546429</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>SVC(C=100, degree=5, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 5</td>\n      <td>0.048000</td>\n      <td>0.004968</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004967729707035586 std: 0.00094235637546429</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>SVC(C=100, degree=4, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 4</td>\n      <td>0.048000</td>\n      <td>0.004626</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.00462556568311918 std: 0.0008717195292730264</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVC(C=100, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 3</td>\n      <td>0.048000</td>\n      <td>0.004754</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004753610427907947 std: 0.000936157066195...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SVC(C=100, degree=4, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 4</td>\n      <td>0.048000</td>\n      <td>0.004754</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004753610427907947 std: 0.000936157066195...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SVC(C=100, degree=5, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 5</td>\n      <td>0.048000</td>\n      <td>0.004754</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004753610427907947 std: 0.000936157066195...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>SVC(C=100, degree=1, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 1</td>\n      <td>0.048000</td>\n      <td>0.004968</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004967729707035586 std: 0.00094235637546429</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>SVC(C=100, degree=2, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 2</td>\n      <td>0.048000</td>\n      <td>0.004787</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004786779771516388 std: 0.000902987722586...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>SVC(C=100, degree=4, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 4</td>\n      <td>0.048000</td>\n      <td>0.004968</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004967729707035586 std: 0.00094235637546429</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>SVC(C=100, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 3</td>\n      <td>0.048000</td>\n      <td>0.004754</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004753610427907947 std: 0.000936157066195...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVC(C=100, degree=2, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 2</td>\n      <td>0.048000</td>\n      <td>0.004787</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004786779771516388 std: 0.000902987722586...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>SVC(C=100, degree=2, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 2</td>\n      <td>0.048000</td>\n      <td>0.004968</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004967729707035586 std: 0.00094235637546429</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>SVC(C=100, gamma=0.001)</td>\n      <td>Kernel: rbf, Degree: 3</td>\n      <td>0.048000</td>\n      <td>0.004968</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.004967729707035586 std: 0.00094235637546429</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>SVC(C=100, degree=9, gamma='auto')</td>\n      <td>Kernel: rbf, Degree: 9</td>\n      <td>0.048000</td>\n      <td>0.005045</td>\n      <td>0.038000</td>\n      <td>m: 0.048 std: 0.0026666666666666644</td>\n      <td>m: 0.005045128182694597 std: 0.000864957899805...</td>\n      <td>m: 0.038 std: 0.0022222222222222227</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>SVC(C=100, degree=5, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 5</td>\n      <td>0.044000</td>\n      <td>0.014574</td>\n      <td>0.034444</td>\n      <td>m: 0.044 std: 0.0066666666666666645</td>\n      <td>m: 0.01457434070069862 std: 0.007356709846704132</td>\n      <td>m: 0.034444444444444444 std: 0.005555555555555557</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>SVC(C=100, degree=6, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 6</td>\n      <td>0.044000</td>\n      <td>0.014574</td>\n      <td>0.034444</td>\n      <td>m: 0.044 std: 0.0066666666666666645</td>\n      <td>m: 0.01457434070069862 std: 0.007356709846704132</td>\n      <td>m: 0.034444444444444444 std: 0.005555555555555557</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>SVC(C=100, degree=7, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 7</td>\n      <td>0.044000</td>\n      <td>0.014574</td>\n      <td>0.034444</td>\n      <td>m: 0.044 std: 0.0066666666666666645</td>\n      <td>m: 0.01457434070069862 std: 0.007356709846704132</td>\n      <td>m: 0.034444444444444444 std: 0.005555555555555557</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>SVC(C=100, degree=8, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 8</td>\n      <td>0.044000</td>\n      <td>0.014577</td>\n      <td>0.034444</td>\n      <td>m: 0.044 std: 0.0066666666666666645</td>\n      <td>m: 0.014577076360155063 std: 0.007359445506160574</td>\n      <td>m: 0.034444444444444444 std: 0.005555555555555557</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>SVC(C=100, degree=9, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 9</td>\n      <td>0.044000</td>\n      <td>0.014577</td>\n      <td>0.034444</td>\n      <td>m: 0.044 std: 0.0066666666666666645</td>\n      <td>m: 0.014577076360155063 std: 0.007359445506160574</td>\n      <td>m: 0.034444444444444444 std: 0.005555555555555557</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>SVC(C=100, degree=9, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 9</td>\n      <td>0.044000</td>\n      <td>0.014577</td>\n      <td>0.034444</td>\n      <td>m: 0.044 std: 0.0066666666666666645</td>\n      <td>m: 0.014577076360155063 std: 0.007359445506160574</td>\n      <td>m: 0.034444444444444444 std: 0.005555555555555557</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SVC(C=100, degree=8, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 8</td>\n      <td>0.044000</td>\n      <td>0.014577</td>\n      <td>0.034444</td>\n      <td>m: 0.044 std: 0.0066666666666666645</td>\n      <td>m: 0.014577076360155063 std: 0.007359445506160574</td>\n      <td>m: 0.034444444444444444 std: 0.005555555555555557</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>SVC(C=100, degree=7, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 7</td>\n      <td>0.044000</td>\n      <td>0.014574</td>\n      <td>0.034444</td>\n      <td>m: 0.044 std: 0.0066666666666666645</td>\n      <td>m: 0.01457434070069862 std: 0.007356709846704132</td>\n      <td>m: 0.034444444444444444 std: 0.005555555555555557</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>SVC(C=100, degree=6, gamma=0.001, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 6</td>\n      <td>0.044000</td>\n      <td>0.014574</td>\n      <td>0.034444</td>\n      <td>m: 0.044 std: 0.0066666666666666645</td>\n      <td>m: 0.01457434070069862 std: 0.007356709846704132</td>\n      <td>m: 0.034444444444444444 std: 0.005555555555555557</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                               SVC(C=100, kernel='poly')\narguments                                  Kernel: poly, Degree: 3\nmean_accuracy                                             0.418667\nmean_precision                                            0.483627\nmean_recall                                               0.404425\naccuracy          m: 0.41866666666666663 std: 0.013333333333333336\nprecision          m: 0.48362695634707353 std: 0.03974960098829397\nrecall            m: 0.40442460317460316 std: 0.016067460317460258\nName: 11, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_results_amazon = calculate_svm(X_amazon,\n",
    "                                   y_amazon)\n",
    "overall_results_amazon.extend(svm_results_amazon)\n",
    "\n",
    "print_results(svm_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overall Results for Amazon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'Results'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           classifier  \\\n41                          SVC(C=100, kernel='poly')   \n67                               SVC(C=100, degree=2)   \n70                               SVC(C=100, degree=5)   \n66                               SVC(C=100, degree=1)   \n68                                         SVC(C=100)   \n..                                                ...   \n55  SVC(C=100, degree=8, gamma='auto', kernel='poly')   \n56  SVC(C=100, degree=9, gamma='auto', kernel='poly')   \n11  DecisionTreeClassifier(max_depth=1, min_sample...   \n13  DecisionTreeClassifier(max_depth=1, min_sample...   \n12  DecisionTreeClassifier(max_depth=1, min_sample...   \n\n                         arguments  mean_accuracy  mean_precision  \\\n41         Kernel: poly, Degree: 3       0.418667        0.483627   \n67          Kernel: rbf, Degree: 2       0.417333        0.483697   \n70          Kernel: rbf, Degree: 5       0.417333        0.483697   \n66          Kernel: rbf, Degree: 1       0.417333        0.483697   \n68          Kernel: rbf, Degree: 3       0.417333        0.483697   \n..                             ...            ...             ...   \n55         Kernel: poly, Degree: 8       0.044000        0.014577   \n56         Kernel: poly, Degree: 9       0.044000        0.014577   \n11   max Depth: 1, min Samples: 20       0.040000        0.009083   \n13  max Depth: 1, min Samples: 100       0.038667        0.001815   \n12   max Depth: 1, min Samples: 50       0.038667        0.002053   \n\n    mean_recall                                          accuracy  \\\n41     0.404425  m: 0.41866666666666663 std: 0.013333333333333336   \n67     0.402996   m: 0.41733333333333333 std: 0.01200000000000001   \n70     0.402996   m: 0.41733333333333333 std: 0.01200000000000001   \n66     0.402996   m: 0.41733333333333333 std: 0.01200000000000001   \n68     0.402996   m: 0.41733333333333333 std: 0.01200000000000001   \n..          ...                                               ...   \n55     0.034444               m: 0.044 std: 0.0066666666666666645   \n56     0.034444               m: 0.044 std: 0.0066666666666666645   \n11     0.032444                                  m: 0.04 std: 0.0   \n13     0.032444                 m: 0.03866666666666667 std: 0.004   \n12     0.035556                 m: 0.03866666666666667 std: 0.004   \n\n                                            precision  \\\n41    m: 0.48362695634707353 std: 0.03974960098829397   \n67     m: 0.4836967850690761 std: 0.03981942971029659   \n70     m: 0.4836967850690761 std: 0.03981942971029659   \n66     m: 0.4836967850690761 std: 0.03981942971029659   \n68     m: 0.4836967850690761 std: 0.03981942971029659   \n..                                                ...   \n55  m: 0.014577076360155063 std: 0.007359445506160574   \n56  m: 0.014577076360155063 std: 0.007359445506160574   \n11  m: 0.009082597803947276 std: 0.001413269964647...   \n13  m: 0.0018147876372591764 std: 4.93769063312042...   \n12  m: 0.0020530253453077754 std: 0.00028761461437...   \n\n                                               recall  \n41   m: 0.40442460317460316 std: 0.016067460317460258  \n67     m: 0.4029960317460317 std: 0.01463888888888884  \n70     m: 0.4029960317460317 std: 0.01463888888888884  \n66     m: 0.4029960317460317 std: 0.01463888888888884  \n68     m: 0.4029960317460317 std: 0.01463888888888884  \n..                                                ...  \n55  m: 0.034444444444444444 std: 0.005555555555555557  \n56  m: 0.034444444444444444 std: 0.005555555555555557  \n11   m: 0.03244444444444444 std: 0.000888888888888887  \n13  m: 0.03244444444444444 std: 0.0013333333333333322  \n12  m: 0.035555555555555556 std: 0.004444444444444445  \n\n[84 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>arguments</th>\n      <th>mean_accuracy</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>41</th>\n      <td>SVC(C=100, kernel='poly')</td>\n      <td>Kernel: poly, Degree: 3</td>\n      <td>0.418667</td>\n      <td>0.483627</td>\n      <td>0.404425</td>\n      <td>m: 0.41866666666666663 std: 0.013333333333333336</td>\n      <td>m: 0.48362695634707353 std: 0.03974960098829397</td>\n      <td>m: 0.40442460317460316 std: 0.016067460317460258</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>SVC(C=100, degree=2)</td>\n      <td>Kernel: rbf, Degree: 2</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>SVC(C=100, degree=5)</td>\n      <td>Kernel: rbf, Degree: 5</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>SVC(C=100, degree=1)</td>\n      <td>Kernel: rbf, Degree: 1</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>SVC(C=100)</td>\n      <td>Kernel: rbf, Degree: 3</td>\n      <td>0.417333</td>\n      <td>0.483697</td>\n      <td>0.402996</td>\n      <td>m: 0.41733333333333333 std: 0.01200000000000001</td>\n      <td>m: 0.4836967850690761 std: 0.03981942971029659</td>\n      <td>m: 0.4029960317460317 std: 0.01463888888888884</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>SVC(C=100, degree=8, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 8</td>\n      <td>0.044000</td>\n      <td>0.014577</td>\n      <td>0.034444</td>\n      <td>m: 0.044 std: 0.0066666666666666645</td>\n      <td>m: 0.014577076360155063 std: 0.007359445506160574</td>\n      <td>m: 0.034444444444444444 std: 0.005555555555555557</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>SVC(C=100, degree=9, gamma='auto', kernel='poly')</td>\n      <td>Kernel: poly, Degree: 9</td>\n      <td>0.044000</td>\n      <td>0.014577</td>\n      <td>0.034444</td>\n      <td>m: 0.044 std: 0.0066666666666666645</td>\n      <td>m: 0.014577076360155063 std: 0.007359445506160574</td>\n      <td>m: 0.034444444444444444 std: 0.005555555555555557</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 20</td>\n      <td>0.040000</td>\n      <td>0.009083</td>\n      <td>0.032444</td>\n      <td>m: 0.04 std: 0.0</td>\n      <td>m: 0.009082597803947276 std: 0.001413269964647...</td>\n      <td>m: 0.03244444444444444 std: 0.000888888888888887</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 100</td>\n      <td>0.038667</td>\n      <td>0.001815</td>\n      <td>0.032444</td>\n      <td>m: 0.03866666666666667 std: 0.004</td>\n      <td>m: 0.0018147876372591764 std: 4.93769063312042...</td>\n      <td>m: 0.03244444444444444 std: 0.0013333333333333322</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>DecisionTreeClassifier(max_depth=1, min_sample...</td>\n      <td>max Depth: 1, min Samples: 50</td>\n      <td>0.038667</td>\n      <td>0.002053</td>\n      <td>0.035556</td>\n      <td>m: 0.03866666666666667 std: 0.004</td>\n      <td>m: 0.0020530253453077754 std: 0.00028761461437...</td>\n      <td>m: 0.035555555555555556 std: 0.004444444444444445</td>\n    </tr>\n  </tbody>\n</table>\n<p>84 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classifier                               SVC(C=100, kernel='poly')\narguments                                  Kernel: poly, Degree: 3\nmean_accuracy                                             0.418667\nmean_precision                                            0.483627\nmean_recall                                               0.404425\naccuracy          m: 0.41866666666666663 std: 0.013333333333333336\nprecision          m: 0.48362695634707353 std: 0.03974960098829397\nrecall            m: 0.40442460317460316 std: 0.016067460317460258\nName: 41, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_results(overall_results_amazon, \"mean_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "'Recoded Data'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9992  V9993  V9994  V9995  \\\n0      0   9   5   5   9   7   0   8   7   1  ...      0      1      0      1   \n1      1  11   9  15  15   5  11  10   1   5  ...      0      0      0      0   \n2      2  11  10  13  12   6   5   0   3   1  ...      0      0      0      0   \n3      3  18   9   7   8   8   7  12   6   7  ...      0      1      0      0   \n4      4  11   7  10  11   4   5   1   8   4  ...      0      0      0      0   \n..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...    ...    ...    ...   \n745  745   5   5   8   2   8   0   5   1   2  ...      1      0      0      0   \n746  746  22  13   8  14   8  11   3   6   7  ...      6      0      2      0   \n747  747  10   3   5   5   7   1  14   2   6  ...      0      0      4      1   \n748  748   9  13   8   5  11   9   9   3   3  ...      0      0      0      1   \n749  749  12   5   8   4   7   5   0   3   4  ...      0      0      4      0   \n\n     V9996  V9997  V9998  V9999  V10000        Class  \n0        0      0      0      0       2        Power  \n1        0      0      0      0       0       Goonan  \n2        0      0      0      1       0      Merritt  \n3        0      1      0      0       1       Goonan  \n4        0      1      0      0       3         Corn  \n..     ...    ...    ...    ...     ...          ...  \n745      0      0      0      0       0      Chachra  \n746      0      2      0      0       0     Morrison  \n747      0      0      2      0       0      Sherwin  \n748      0      0      0      0       0  Blankenship  \n749      1      0      0      0       0     Davisson  \n\n[750 rows x 10002 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>9</td>\n      <td>7</td>\n      <td>0</td>\n      <td>8</td>\n      <td>7</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Power</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11</td>\n      <td>9</td>\n      <td>15</td>\n      <td>15</td>\n      <td>5</td>\n      <td>11</td>\n      <td>10</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>11</td>\n      <td>10</td>\n      <td>13</td>\n      <td>12</td>\n      <td>6</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Merritt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>18</td>\n      <td>9</td>\n      <td>7</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>12</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Goonan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>11</td>\n      <td>7</td>\n      <td>10</td>\n      <td>11</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>8</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Corn</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>745</td>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Chachra</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>746</td>\n      <td>22</td>\n      <td>13</td>\n      <td>8</td>\n      <td>14</td>\n      <td>8</td>\n      <td>11</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Morrison</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>747</td>\n      <td>10</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1</td>\n      <td>14</td>\n      <td>2</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sherwin</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>748</td>\n      <td>9</td>\n      <td>13</td>\n      <td>8</td>\n      <td>5</td>\n      <td>11</td>\n      <td>9</td>\n      <td>9</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Blankenship</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>749</td>\n      <td>12</td>\n      <td>5</td>\n      <td>8</td>\n      <td>4</td>\n      <td>7</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Davisson</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10002 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Data Normalized: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "           V1        V2        V3        V4        V5        V6        V7  \\\n0    0.022849  0.012694  0.012694  0.022849  0.017771  0.000000  0.020310   \n1    0.030256  0.024755  0.041258  0.041258  0.013753  0.030256  0.027505   \n2    0.028761  0.026146  0.033990  0.031376  0.015688  0.013073  0.000000   \n3    0.041891  0.020946  0.016291  0.018618  0.018618  0.016291  0.027927   \n4    0.028918  0.018402  0.026289  0.028918  0.010516  0.013145  0.002629   \n..        ...       ...       ...       ...       ...       ...       ...   \n745  0.026867  0.026867  0.042987  0.010747  0.042987  0.000000  0.026867   \n746  0.048706  0.028781  0.017711  0.030995  0.017711  0.024353  0.006642   \n747  0.026260  0.007878  0.013130  0.013130  0.018382  0.002626  0.036764   \n748  0.025152  0.036330  0.022357  0.013973  0.030741  0.025152  0.025152   \n749  0.036478  0.015199  0.024319  0.012159  0.021279  0.015199  0.000000   \n\n           V8        V9       V10  ...     V9991     V9992     V9993  \\\n0    0.017771  0.002539  0.012694  ...  0.000000  0.000000  0.002539   \n1    0.002751  0.013753  0.019254  ...  0.000000  0.000000  0.000000   \n2    0.007844  0.002615  0.002615  ...  0.002615  0.000000  0.000000   \n3    0.013964  0.016291  0.002327  ...  0.000000  0.000000  0.002327   \n4    0.021031  0.010516  0.010516  ...  0.000000  0.000000  0.000000   \n..        ...       ...       ...  ...       ...       ...       ...   \n745  0.005373  0.010747  0.016120  ...  0.000000  0.005373  0.000000   \n746  0.013284  0.015497  0.013284  ...  0.000000  0.013284  0.000000   \n747  0.005252  0.015756  0.002626  ...  0.000000  0.000000  0.000000   \n748  0.008384  0.008384  0.016768  ...  0.000000  0.000000  0.000000   \n749  0.009120  0.012159  0.012159  ...  0.000000  0.000000  0.000000   \n\n        V9994     V9995    V9996     V9997     V9998     V9999    V10000  \n0    0.000000  0.002539  0.00000  0.000000  0.000000  0.000000  0.005077  \n1    0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n2    0.000000  0.000000  0.00000  0.000000  0.000000  0.002615  0.000000  \n3    0.000000  0.000000  0.00000  0.002327  0.000000  0.000000  0.002327  \n4    0.000000  0.000000  0.00000  0.002629  0.000000  0.000000  0.007887  \n..        ...       ...      ...       ...       ...       ...       ...  \n745  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n746  0.004428  0.000000  0.00000  0.004428  0.000000  0.000000  0.000000  \n747  0.010504  0.002626  0.00000  0.000000  0.005252  0.000000  0.000000  \n748  0.000000  0.002795  0.00000  0.000000  0.000000  0.000000  0.000000  \n749  0.012159  0.000000  0.00304  0.000000  0.000000  0.000000  0.000000  \n\n[750 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.022849</td>\n      <td>0.012694</td>\n      <td>0.012694</td>\n      <td>0.022849</td>\n      <td>0.017771</td>\n      <td>0.000000</td>\n      <td>0.020310</td>\n      <td>0.017771</td>\n      <td>0.002539</td>\n      <td>0.012694</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002539</td>\n      <td>0.000000</td>\n      <td>0.002539</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005077</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.030256</td>\n      <td>0.024755</td>\n      <td>0.041258</td>\n      <td>0.041258</td>\n      <td>0.013753</td>\n      <td>0.030256</td>\n      <td>0.027505</td>\n      <td>0.002751</td>\n      <td>0.013753</td>\n      <td>0.019254</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.028761</td>\n      <td>0.026146</td>\n      <td>0.033990</td>\n      <td>0.031376</td>\n      <td>0.015688</td>\n      <td>0.013073</td>\n      <td>0.000000</td>\n      <td>0.007844</td>\n      <td>0.002615</td>\n      <td>0.002615</td>\n      <td>...</td>\n      <td>0.002615</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002615</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.041891</td>\n      <td>0.020946</td>\n      <td>0.016291</td>\n      <td>0.018618</td>\n      <td>0.018618</td>\n      <td>0.016291</td>\n      <td>0.027927</td>\n      <td>0.013964</td>\n      <td>0.016291</td>\n      <td>0.002327</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002327</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.002327</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002327</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.028918</td>\n      <td>0.018402</td>\n      <td>0.026289</td>\n      <td>0.028918</td>\n      <td>0.010516</td>\n      <td>0.013145</td>\n      <td>0.002629</td>\n      <td>0.021031</td>\n      <td>0.010516</td>\n      <td>0.010516</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.002629</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.007887</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>0.026867</td>\n      <td>0.026867</td>\n      <td>0.042987</td>\n      <td>0.010747</td>\n      <td>0.042987</td>\n      <td>0.000000</td>\n      <td>0.026867</td>\n      <td>0.005373</td>\n      <td>0.010747</td>\n      <td>0.016120</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.005373</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>0.048706</td>\n      <td>0.028781</td>\n      <td>0.017711</td>\n      <td>0.030995</td>\n      <td>0.017711</td>\n      <td>0.024353</td>\n      <td>0.006642</td>\n      <td>0.013284</td>\n      <td>0.015497</td>\n      <td>0.013284</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.013284</td>\n      <td>0.000000</td>\n      <td>0.004428</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.004428</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>0.026260</td>\n      <td>0.007878</td>\n      <td>0.013130</td>\n      <td>0.013130</td>\n      <td>0.018382</td>\n      <td>0.002626</td>\n      <td>0.036764</td>\n      <td>0.005252</td>\n      <td>0.015756</td>\n      <td>0.002626</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010504</td>\n      <td>0.002626</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.005252</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>0.025152</td>\n      <td>0.036330</td>\n      <td>0.022357</td>\n      <td>0.013973</td>\n      <td>0.030741</td>\n      <td>0.025152</td>\n      <td>0.025152</td>\n      <td>0.008384</td>\n      <td>0.008384</td>\n      <td>0.016768</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002795</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>0.036478</td>\n      <td>0.015199</td>\n      <td>0.024319</td>\n      <td>0.012159</td>\n      <td>0.021279</td>\n      <td>0.015199</td>\n      <td>0.000000</td>\n      <td>0.009120</td>\n      <td>0.012159</td>\n      <td>0.012159</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012159</td>\n      <td>0.000000</td>\n      <td>0.00304</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Target: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0            Power\n1           Goonan\n2          Merritt\n3           Goonan\n4             Corn\n          ...     \n745        Chachra\n746       Morrison\n747        Sherwin\n748    Blankenship\n749       Davisson\nName: Class, Length: 750, dtype: category\nCategories (50, object): [Agresti, Ashbacher, Auken, Blankenship, ..., Vernon, Vision, Walters, Wilson]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Test Dataset: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "       ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9991  V9992  V9993  \\\n0     750   3   2   5   1   3   4   9   4   9  ...      0      0      0   \n1     751   9   4   3   4   6   7   2   1   0  ...      0      1      1   \n2     752  18  16   6  13   0   7   0   6   3  ...      1      0      0   \n3     753   5   2   6   2  12   7   1   2   3  ...      0      0      1   \n4     754  14   9   9   5   5   8  10   2   0  ...      0      0      0   \n..    ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...    ...    ...   \n745  1495  10   2   2   5   4   2   6   3   4  ...      0      1      0   \n746  1496  19   8   6  11   6   4   3   8   2  ...      0      0      1   \n747  1497  15   4   8   6  10   6  11   5   9  ...      0      0      3   \n748  1498  13   7  11  14   4   3   0   3   0  ...      0      0      0   \n749  1499   4   3   4   1   4   2   2   1   1  ...      0      0      0   \n\n     V9994  V9995  V9996  V9997  V9998  V9999  V10000  \n0        0      0      1      0      0      0       0  \n1        1      2      0      0      0      0       0  \n2        0      1      0      2      0      0       0  \n3        0      0      0      0      0      0       0  \n4        0      2      1      0      2      0       0  \n..     ...    ...    ...    ...    ...    ...     ...  \n745      0      0      1      0      0      0       0  \n746      0      0      0      3      0      0       0  \n747      0      0      1      0      0      0       0  \n748      0      0      0      0      0      0       0  \n749      0      0      1      0      0      0       0  \n\n[750 rows x 10001 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>750</td>\n      <td>3</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>9</td>\n      <td>4</td>\n      <td>9</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>751</td>\n      <td>9</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>6</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>752</td>\n      <td>18</td>\n      <td>16</td>\n      <td>6</td>\n      <td>13</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>753</td>\n      <td>5</td>\n      <td>2</td>\n      <td>6</td>\n      <td>2</td>\n      <td>12</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>754</td>\n      <td>14</td>\n      <td>9</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>10</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>1495</td>\n      <td>10</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>1496</td>\n      <td>19</td>\n      <td>8</td>\n      <td>6</td>\n      <td>11</td>\n      <td>6</td>\n      <td>4</td>\n      <td>3</td>\n      <td>8</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>1497</td>\n      <td>15</td>\n      <td>4</td>\n      <td>8</td>\n      <td>6</td>\n      <td>10</td>\n      <td>6</td>\n      <td>11</td>\n      <td>5</td>\n      <td>9</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>1498</td>\n      <td>13</td>\n      <td>7</td>\n      <td>11</td>\n      <td>14</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>1499</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10001 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Test Dataset, Predictors: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  ...  V9991  V9992  V9993  V9994  \\\n0     3   2   5   1   3   4   9   4   9    4  ...      0      0      0      0   \n1     9   4   3   4   6   7   2   1   0    1  ...      0      1      1      1   \n2    18  16   6  13   0   7   0   6   3    0  ...      1      0      0      0   \n3     5   2   6   2  12   7   1   2   3    5  ...      0      0      1      0   \n4    14   9   9   5   5   8  10   2   0    5  ...      0      0      0      0   \n..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...    ...    ...    ...    ...   \n745  10   2   2   5   4   2   6   3   4    1  ...      0      1      0      0   \n746  19   8   6  11   6   4   3   8   2    3  ...      0      0      1      0   \n747  15   4   8   6  10   6  11   5   9    2  ...      0      0      3      0   \n748  13   7  11  14   4   3   0   3   0    0  ...      0      0      0      0   \n749   4   3   4   1   4   2   2   1   1    2  ...      0      0      0      0   \n\n     V9995  V9996  V9997  V9998  V9999  V10000  \n0        0      1      0      0      0       0  \n1        2      0      0      0      0       0  \n2        1      0      2      0      0       0  \n3        0      0      0      0      0       0  \n4        2      1      0      2      0       0  \n..     ...    ...    ...    ...    ...     ...  \n745      0      1      0      0      0       0  \n746      0      0      3      0      0       0  \n747      0      1      0      0      0       0  \n748      0      0      0      0      0       0  \n749      0      1      0      0      0       0  \n\n[750 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>9</td>\n      <td>4</td>\n      <td>9</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>6</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18</td>\n      <td>16</td>\n      <td>6</td>\n      <td>13</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>2</td>\n      <td>6</td>\n      <td>2</td>\n      <td>12</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14</td>\n      <td>9</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>10</td>\n      <td>2</td>\n      <td>0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>10</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>19</td>\n      <td>8</td>\n      <td>6</td>\n      <td>11</td>\n      <td>6</td>\n      <td>4</td>\n      <td>3</td>\n      <td>8</td>\n      <td>2</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>15</td>\n      <td>4</td>\n      <td>8</td>\n      <td>6</td>\n      <td>10</td>\n      <td>6</td>\n      <td>11</td>\n      <td>5</td>\n      <td>9</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>13</td>\n      <td>7</td>\n      <td>11</td>\n      <td>14</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Test Dataset, Normalized: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "           V1        V2        V3        V4        V5        V6        V7  \\\n0    0.009978  0.006652  0.016630  0.003326  0.009978  0.013304  0.029935   \n1    0.026896  0.011954  0.008965  0.011954  0.017930  0.020919  0.005977   \n2    0.046578  0.041402  0.015526  0.033639  0.000000  0.018114  0.000000   \n3    0.014007  0.005603  0.016809  0.005603  0.033617  0.019610  0.002801   \n4    0.035705  0.022953  0.022953  0.012752  0.012752  0.020403  0.025503   \n..        ...       ...       ...       ...       ...       ...       ...   \n745  0.033729  0.006746  0.006746  0.016865  0.013492  0.006746  0.020237   \n746  0.057413  0.024174  0.018131  0.033239  0.018131  0.012087  0.009065   \n747  0.035489  0.009464  0.018928  0.014196  0.023659  0.014196  0.026025   \n748  0.036754  0.019790  0.031099  0.039581  0.011309  0.008482  0.000000   \n749  0.027758  0.020818  0.027758  0.006939  0.027758  0.013879  0.013879   \n\n           V8        V9       V10  ...     V9991     V9992     V9993  \\\n0    0.013304  0.029935  0.013304  ...  0.000000  0.000000  0.000000   \n1    0.002988  0.000000  0.002988  ...  0.000000  0.002988  0.002988   \n2    0.015526  0.007763  0.000000  ...  0.002588  0.000000  0.000000   \n3    0.005603  0.008404  0.014007  ...  0.000000  0.000000  0.002801   \n4    0.005101  0.000000  0.012752  ...  0.000000  0.000000  0.000000   \n..        ...       ...       ...  ...       ...       ...       ...   \n745  0.010119  0.013492  0.003373  ...  0.000000  0.003373  0.000000   \n746  0.024174  0.006044  0.009065  ...  0.000000  0.000000  0.003022   \n747  0.011830  0.021293  0.004732  ...  0.000000  0.000000  0.007098   \n748  0.008482  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n749  0.006939  0.006939  0.013879  ...  0.000000  0.000000  0.000000   \n\n        V9994     V9995     V9996     V9997     V9998  V9999  V10000  \n0    0.000000  0.000000  0.003326  0.000000  0.000000    0.0     0.0  \n1    0.002988  0.005977  0.000000  0.000000  0.000000    0.0     0.0  \n2    0.000000  0.002588  0.000000  0.005175  0.000000    0.0     0.0  \n3    0.000000  0.000000  0.000000  0.000000  0.000000    0.0     0.0  \n4    0.000000  0.005101  0.002550  0.000000  0.005101    0.0     0.0  \n..        ...       ...       ...       ...       ...    ...     ...  \n745  0.000000  0.000000  0.003373  0.000000  0.000000    0.0     0.0  \n746  0.000000  0.000000  0.000000  0.009065  0.000000    0.0     0.0  \n747  0.000000  0.000000  0.002366  0.000000  0.000000    0.0     0.0  \n748  0.000000  0.000000  0.000000  0.000000  0.000000    0.0     0.0  \n749  0.000000  0.000000  0.006939  0.000000  0.000000    0.0     0.0  \n\n[750 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.009978</td>\n      <td>0.006652</td>\n      <td>0.016630</td>\n      <td>0.003326</td>\n      <td>0.009978</td>\n      <td>0.013304</td>\n      <td>0.029935</td>\n      <td>0.013304</td>\n      <td>0.029935</td>\n      <td>0.013304</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003326</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.026896</td>\n      <td>0.011954</td>\n      <td>0.008965</td>\n      <td>0.011954</td>\n      <td>0.017930</td>\n      <td>0.020919</td>\n      <td>0.005977</td>\n      <td>0.002988</td>\n      <td>0.000000</td>\n      <td>0.002988</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.002988</td>\n      <td>0.002988</td>\n      <td>0.002988</td>\n      <td>0.005977</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.046578</td>\n      <td>0.041402</td>\n      <td>0.015526</td>\n      <td>0.033639</td>\n      <td>0.000000</td>\n      <td>0.018114</td>\n      <td>0.000000</td>\n      <td>0.015526</td>\n      <td>0.007763</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.002588</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002588</td>\n      <td>0.000000</td>\n      <td>0.005175</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.014007</td>\n      <td>0.005603</td>\n      <td>0.016809</td>\n      <td>0.005603</td>\n      <td>0.033617</td>\n      <td>0.019610</td>\n      <td>0.002801</td>\n      <td>0.005603</td>\n      <td>0.008404</td>\n      <td>0.014007</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002801</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.035705</td>\n      <td>0.022953</td>\n      <td>0.022953</td>\n      <td>0.012752</td>\n      <td>0.012752</td>\n      <td>0.020403</td>\n      <td>0.025503</td>\n      <td>0.005101</td>\n      <td>0.000000</td>\n      <td>0.012752</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005101</td>\n      <td>0.002550</td>\n      <td>0.000000</td>\n      <td>0.005101</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>0.033729</td>\n      <td>0.006746</td>\n      <td>0.006746</td>\n      <td>0.016865</td>\n      <td>0.013492</td>\n      <td>0.006746</td>\n      <td>0.020237</td>\n      <td>0.010119</td>\n      <td>0.013492</td>\n      <td>0.003373</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.003373</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003373</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>0.057413</td>\n      <td>0.024174</td>\n      <td>0.018131</td>\n      <td>0.033239</td>\n      <td>0.018131</td>\n      <td>0.012087</td>\n      <td>0.009065</td>\n      <td>0.024174</td>\n      <td>0.006044</td>\n      <td>0.009065</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003022</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.009065</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>0.035489</td>\n      <td>0.009464</td>\n      <td>0.018928</td>\n      <td>0.014196</td>\n      <td>0.023659</td>\n      <td>0.014196</td>\n      <td>0.026025</td>\n      <td>0.011830</td>\n      <td>0.021293</td>\n      <td>0.004732</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.007098</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002366</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>0.036754</td>\n      <td>0.019790</td>\n      <td>0.031099</td>\n      <td>0.039581</td>\n      <td>0.011309</td>\n      <td>0.008482</td>\n      <td>0.000000</td>\n      <td>0.008482</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>0.027758</td>\n      <td>0.020818</td>\n      <td>0.027758</td>\n      <td>0.006939</td>\n      <td>0.027758</td>\n      <td>0.013879</td>\n      <td>0.013879</td>\n      <td>0.006939</td>\n      <td>0.006939</td>\n      <td>0.013879</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.006939</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Finally recoded: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "       ID      Class\n0     750    Sherwin\n1     751   Engineer\n2     752       Harp\n3     753       Shea\n4     754    Agresti\n..    ...        ...\n745  1495   Cholette\n746  1496  Ashbacher\n747  1497   Cholette\n748  1498      Kolln\n749  1499    Chachra\n\n[750 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>750</td>\n      <td>Sherwin</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>751</td>\n      <td>Engineer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>752</td>\n      <td>Harp</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>753</td>\n      <td>Shea</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>754</td>\n      <td>Agresti</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>1495</td>\n      <td>Cholette</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>1496</td>\n      <td>Ashbacher</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>1497</td>\n      <td>Cholette</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>1498</td>\n      <td>Kolln</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>1499</td>\n      <td>Chachra</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Read Data\n",
    "amazon_data_learn = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.lrn.csv\")\n",
    "amazon_data_test = pd.read_csv(\"data/amazon/amazon_review_ID.shuf.tes.csv\")\n",
    "\n",
    "# Label Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(amazon_data_learn[\"Class\"])\n",
    "#amazon_data_learn[\"Class\"] = le.transform(amazon_data_learn[\"Class\"])\n",
    "amazon_data_learn[\"Class\"] = amazon_data_learn[\"Class\"].astype(\"category\")\n",
    "\n",
    "names_data = amazon_data_learn.loc[:, amazon_data_learn.columns.str.startswith(\"V\")]\n",
    "\n",
    "display(\"Recoded Data\", amazon_data_learn)\n",
    "y = amazon_data_learn[\"Class\"]\n",
    "X = pd.DataFrame(amazon_data_learn.drop([\"ID\", \"Class\"], axis=1))\n",
    "X = X[names_data.columns]\n",
    "\n",
    "#Normalize data\n",
    "def normalize_values(data):\n",
    "    columns = data.columns\n",
    "    data = preprocessing.Normalizer().fit_transform(data)\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "X_norm = normalize_values(X)\n",
    "test_X = normalize_values(amazon_data_test[names_data.columns])\n",
    "\n",
    "display(\"Data Normalized: \", X_norm)\n",
    "display(\"Target: \", y)\n",
    "display(\"Test Dataset: \", amazon_data_test)\n",
    "display(\"Test Dataset, Predictors: \", amazon_data_test[names_data.columns])\n",
    "display(\"Test Dataset, Normalized: \", test_X)\n",
    "\n",
    "#Calculate Model\n",
    "classifier = svm.SVC(C=101, kernel='poly')\n",
    "classifier.fit(X_norm, y)\n",
    "\n",
    "#Predict the Test Data\n",
    "amazon_data_test[\"Class\"] = classifier.predict(test_X)\n",
    "\n",
    "display(\"Finally recoded: \", amazon_data_test[[\"ID\", \"Class\"]])\n",
    "amazon_data_test[[\"ID\", \"Class\"]].to_csv(\"solution_amazon.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}